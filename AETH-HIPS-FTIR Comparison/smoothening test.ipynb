{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f10c5f5d",
   "metadata": {},
   "source": [
    "# Black Carbon Cross-Method Analysis with Smoothing Techniques\n",
    " \n",
    "This notebook extends the original cross-method analysis by applying three different smoothing techniques to the Aethalometer data before comparison with FTIR and HIPS measurements:\n",
    " \n",
    "1. **Optimized Noise-reduction Algorithm (ONA)**: Adaptive time-averaging based on incremental light attenuation (Î”ATN)\n",
    "2. **Centered Moving Average (CMA)**: Fixed window smoothing that incorporates data points before and after each measurement\n",
    "3. **Double Exponentially Weighted Moving Average (DEMA)**: Weighted smoothing that reduces noise while limiting lag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94800157",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7422f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import os\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from datetime import timedelta\n",
    "from scipy.stats import pearsonr\n",
    "import numba  # Required for ONA algorithm\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc58a69",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading Functions\n",
    " \n",
    "These functions handle loading and preparing data from the Aethalometer, HIPS, and FTIR sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50d39c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aethalometer_data(file_path):\n",
    "    \"\"\"Load and prepare Aethalometer data.\"\"\"\n",
    "    print(f\"Loading Aethalometer data from: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Try to use polars for faster loading if available\n",
    "        try:\n",
    "            import polars as pl\n",
    "            print(\"Using Polars for data loading (faster)\")\n",
    "            pl_data = pl.read_csv(file_path)\n",
    "            df = pl_data.to_pandas()\n",
    "        except ImportError:\n",
    "            print(\"Polars not available, using pandas\")\n",
    "            df = pd.read_csv(file_path)\n",
    "    \n",
    "        # Parse date and time columns if they exist\n",
    "        datetime_col = None\n",
    "        if 'Date local (yyyy/MM/dd)' in df.columns and 'Time local (hh:mm:ss)' in df.columns:\n",
    "            # Try multiple formats to handle different date formats\n",
    "            try:\n",
    "                formats_to_try = [\n",
    "                    '%Y-%m-%d %I:%M:%S %p',  # 2022-04-12 9:46:01 AM\n",
    "                    '%Y/%m/%d %H:%M:%S',     # 2022/04/12 09:46:01\n",
    "                    '%Y-%m-%d %H:%M:%S'      # 2022-04-12 09:46:01\n",
    "                ]\n",
    "                \n",
    "                for fmt in formats_to_try:\n",
    "                    try:\n",
    "                        df['datetime_local'] = pd.to_datetime(\n",
    "                            df['Date local (yyyy/MM/dd)'] + ' ' + df['Time local (hh:mm:ss)'],\n",
    "                            format=fmt\n",
    "                        )\n",
    "                        datetime_col = 'datetime_local'\n",
    "                        print(f\"Successfully parsed dates with format: {fmt}\")\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                \n",
    "                if datetime_col is None:\n",
    "                    # If all specific formats fail, try the flexible approach\n",
    "                    df['datetime_local'] = pd.to_datetime(\n",
    "                        df['Date local (yyyy/MM/dd)'] + ' ' + df['Time local (hh:mm:ss)'],\n",
    "                        format='mixed'\n",
    "                    )\n",
    "                    datetime_col = 'datetime_local'\n",
    "                    print(\"Parsed dates using flexible 'mixed' format\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing date/time: {e}\")\n",
    "                print(\"Sample date values:\", df['Date local (yyyy/MM/dd)'].iloc[:5].tolist())\n",
    "                print(\"Sample time values:\", df['Time local (hh:mm:ss)'].iloc[:5].tolist())\n",
    "                return None\n",
    "        elif 'datetime_local' in df.columns:\n",
    "            # Column already exists\n",
    "            df['datetime_local'] = pd.to_datetime(df['datetime_local'])\n",
    "            datetime_col = 'datetime_local'\n",
    "        \n",
    "        # Set index if datetime column is found\n",
    "        if datetime_col:\n",
    "            df.set_index(datetime_col, inplace=True)\n",
    "            df.index = df.index.floor('min')  # Ensure clean 1-min resolution\n",
    "            df.sort_index(inplace=True)\n",
    "        else:\n",
    "            print(\"ERROR: No valid datetime column found\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Loaded {len(df):,} Aethalometer records spanning {df.index.min()} to {df.index.max()}\")\n",
    "        \n",
    "        # Check if Red BCc column exists\n",
    "        if 'Red BCc' in df.columns:\n",
    "            print(f\"Red BCc data available: {df['Red BCc'].describe().round(2)}\")\n",
    "        else:\n",
    "            print(\"WARNING: 'Red BCc' column not found in the dataset!\")\n",
    "            print(\"Available columns:\", df.columns.tolist())\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Aethalometer data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c0727ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filter_sample_data(db_path):\n",
    "    \"\"\"Load ETAD (HIPS) and FTIR data from SQLite database.\"\"\"\n",
    "    print(f\"Loading ETAD (HIPS) and FTIR filter sample data from: {db_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Connect to the database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        \n",
    "        # Load HIPS/FTIR data for the ETAD site\n",
    "        query = \"\"\"\n",
    "        SELECT f.filter_id, \n",
    "               f.sample_date AS SampleDate, \n",
    "               m.ec_ftir AS EC_FTIR,\n",
    "               m.oc_ftir AS OC_FTIR,\n",
    "               m.fabs AS Fabs,\n",
    "               f.site_code AS Site\n",
    "        FROM filters f\n",
    "        JOIN ftir_sample_measurements m USING(filter_id)\n",
    "        WHERE f.site_code = 'ETAD'\n",
    "        ORDER BY f.sample_date;\n",
    "        \"\"\"\n",
    "        \n",
    "        # Execute the query and load into a DataFrame\n",
    "        combined_data = pd.read_sql_query(query, conn)\n",
    "        \n",
    "        # Convert date column to datetime\n",
    "        combined_data['SampleDate'] = pd.to_datetime(combined_data['SampleDate'])\n",
    "        \n",
    "        # For compatibility with existing code, create separate dataframes for HIPS and FTIR\n",
    "        # Both dataframes contain the same data since they're joined in the database\n",
    "        etad_data = combined_data.copy()\n",
    "        ftir_data = combined_data.copy()\n",
    "        ftir_data.rename(columns={'SampleDate': 'date'}, inplace=True)\n",
    "        \n",
    "        # Display summary\n",
    "        valid_samples_count = etad_data['SampleDate'].notna().sum()\n",
    "        \n",
    "        print(f\"Loaded {len(etad_data)} ETAD samples from database ({valid_samples_count} with valid dates)\")\n",
    "        print(f\"  - All samples have both HIPS and FTIR measurements\")\n",
    "        \n",
    "        # Close the connection\n",
    "        conn.close()\n",
    "        \n",
    "        return etad_data, ftir_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading filter sample data: {e}\")\n",
    "        print(\"Will attempt to create empty dataframes as fallback...\")\n",
    "        etad_data = pd.DataFrame(columns=['filter_id', 'SampleDate', 'Fabs', 'Site'])\n",
    "        ftir_data = pd.DataFrame(columns=['filter_id', 'date', 'EC_FTIR', 'OC_FTIR'])\n",
    "        return etad_data, ftir_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1256dc1a",
   "metadata": {},
   "source": [
    "## Step 2: Data Processing Functions\n",
    " \n",
    "These functions identify 'excellent' data quality periods and extract the overlapping measurements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "760892cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_excellent_periods(aethalometer_df, quality_df=None):\n",
    "    \"\"\"\n",
    "    Identify excellent 9am-to-9am periods directly from Aethalometer data\n",
    "    or from a pre-computed quality classification DataFrame.\n",
    "    \"\"\"\n",
    "    if quality_df is not None and 'aethalometer_quality' in quality_df.columns:\n",
    "        print(\"Using pre-computed quality classifications\")\n",
    "        \n",
    "        # Extract excellent periods\n",
    "        excellent_periods = quality_df[quality_df['aethalometer_quality'] == 'Excellent']\n",
    "        print(f\"Found {len(excellent_periods)} excellent periods in quality classifications\")\n",
    "        \n",
    "        return excellent_periods\n",
    "    \n",
    "    print(\"Computing excellent periods from scratch\")\n",
    "    \n",
    "    # Start and end timestamps\n",
    "    start, end = aethalometer_df.index.min(), aethalometer_df.index.max()\n",
    "    \n",
    "    # Create expected full timeline\n",
    "    expected_idx = pd.date_range(start, end, freq='min')\n",
    "    \n",
    "    # Identify missing timestamps\n",
    "    actual_idx = aethalometer_df.index.unique().sort_values()\n",
    "    missing_idx = expected_idx.difference(actual_idx)\n",
    "    \n",
    "    # Create 9am-to-9am periods (matching filter sampling)\n",
    "    # Shift each timestamp to the previous 9am boundary\n",
    "    nine_am_periods = missing_idx.map(lambda ts: \n",
    "        ts.normalize() + pd.Timedelta(hours=9) if ts.hour < 9 \n",
    "        else ts.normalize() + pd.Timedelta(hours=9) + pd.Timedelta(days=1)\n",
    "    )\n",
    "    \n",
    "    # Count missing minutes per 9am-to-9am period\n",
    "    missing_per_period = pd.Series(1, index=nine_am_periods).groupby(level=0).count()\n",
    "    \n",
    "    # Classify excellent periods (â‰¤10 minutes missing)\n",
    "    excellent_periods_idx = missing_per_period[missing_per_period <= 10].index\n",
    "    \n",
    "    # Create a DataFrame with the excellent periods\n",
    "    excellent_periods = pd.DataFrame(index=excellent_periods_idx)\n",
    "    excellent_periods['start_time'] = excellent_periods.index\n",
    "    excellent_periods['end_time'] = excellent_periods['start_time'] + pd.Timedelta(days=1)\n",
    "    excellent_periods['aethalometer_quality'] = 'Excellent'\n",
    "    \n",
    "    print(f\"Computed {len(excellent_periods)} excellent periods from scratch\")\n",
    "    \n",
    "    return excellent_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1246cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_daily_aethalometer_data(aethalometer_df, period_start, period_end, column='Red BCc'):\n",
    "    \"\"\"\n",
    "    Extract and process Aethalometer data for a specific 24-hour period.\n",
    "    Returns summary statistics for the period.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract data for the specific period\n",
    "        period_data = aethalometer_df.loc[period_start:period_end, column].dropna()\n",
    "        \n",
    "        if len(period_data) == 0:\n",
    "            return None\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats = {\n",
    "            'period_start': period_start,\n",
    "            'period_end': period_end,\n",
    "            'count': len(period_data),\n",
    "            'mean': period_data.mean(),\n",
    "            'median': period_data.median(),\n",
    "            'min': period_data.min(),\n",
    "            'max': period_data.max(),\n",
    "            'std': period_data.std(),\n",
    "            '25th': period_data.quantile(0.25),\n",
    "            '75th': period_data.quantile(0.75),\n",
    "            'negative_count': (period_data < 0).sum(),\n",
    "            'negative_percent': (period_data < 0).mean() * 100\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data for period {period_start} to {period_end}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98f5c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlapping_excellent_data(aethalometer_df, filter_df, excellent_periods):\n",
    "    \"\"\"\n",
    "    Find days with overlapping excellent Aethalometer data and filter samples.\n",
    "    Returns a DataFrame with the overlapping periods.\n",
    "    \"\"\"\n",
    "    print(\"\\nFinding overlapping excellent periods with filter samples...\")\n",
    "    \n",
    "    # Print debug info\n",
    "    print(f\"Filter DataFrame columns: {filter_df.columns.tolist()}\")\n",
    "    print(f\"Excellent periods columns: {excellent_periods.columns.tolist()}\")\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    if 'SampleDate' not in filter_df.columns:\n",
    "        print(\"ERROR: SampleDate column not found in filter_df\")\n",
    "        return None\n",
    "    \n",
    "    if 'start_time' not in excellent_periods.columns:\n",
    "        print(\"ERROR: start_time column not found in excellent_periods\")\n",
    "        return None\n",
    "    \n",
    "    # Convert filter sample dates to 9am start time format (24h earlier than collection)\n",
    "    filter_dates = filter_df['SampleDate'].dropna()\n",
    "    print(f\"Filter dates range: {filter_dates.min()} to {filter_dates.max()}\")\n",
    "    print(f\"Total filter dates: {len(filter_dates)}\")\n",
    "    \n",
    "    # Print a few sample filter dates to debug\n",
    "    print(\"Sample filter dates (first 5):\")\n",
    "    for date in filter_dates.head(5):\n",
    "        print(f\"  - {date}\")\n",
    "    \n",
    "    # Convert to 9am start time (24h earlier than collection)\n",
    "    filter_periods = pd.DatetimeIndex([\n",
    "        d.normalize() + pd.Timedelta(hours=9) \n",
    "        for d in filter_dates\n",
    "    ])\n",
    "    \n",
    "    # Get excellent period start times\n",
    "    excellent_starts = excellent_periods['start_time']\n",
    "    print(f\"Excellent periods range: {excellent_starts.min()} to {excellent_starts.max()}\")\n",
    "    print(f\"Total excellent periods: {len(excellent_starts)}\")\n",
    "    \n",
    "    # Print a few sample excellent periods to debug\n",
    "    print(\"Sample excellent period start times (first 5):\")\n",
    "    for date in excellent_starts.head(5):\n",
    "        print(f\"  - {date}\")\n",
    "    \n",
    "    # Find overlap\n",
    "    overlap_periods = pd.DatetimeIndex(filter_periods).intersection(excellent_starts)\n",
    "    \n",
    "    print(f\"Found {len(overlap_periods)} overlapping excellent periods with filter samples\")\n",
    "    \n",
    "    if len(overlap_periods) == 0:\n",
    "        print(\"No overlapping periods found - cannot proceed with comparison.\")\n",
    "        return None\n",
    "    \n",
    "    # Print a few sample overlap periods to debug\n",
    "    print(\"Sample overlap periods (first 5):\")\n",
    "    for date in overlap_periods[:5]:\n",
    "        print(f\"  - {date}\")\n",
    "    \n",
    "    # Create DataFrame with the overlapping periods\n",
    "    overlap_df = pd.DataFrame(index=overlap_periods)\n",
    "    overlap_df['start_time'] = overlap_df.index\n",
    "    overlap_df['end_time'] = overlap_df['start_time'] + pd.Timedelta(days=1)\n",
    "    \n",
    "    # Add filter sample data\n",
    "    # Map each 9am start time back to the filter collection date (24h later)\n",
    "    filter_collection_dates = overlap_df['start_time'] + pd.Timedelta(days=1)\n",
    "    \n",
    "    # Match with filter data - with more debugging and flexible matching\n",
    "    print(\"Adding filter data to overlap DataFrame...\")\n",
    "    filter_columns_added = False\n",
    "    matches_found = 0\n",
    "    \n",
    "    for i, row in overlap_df.iterrows():\n",
    "        # Get the filter collection date (24h after start time)\n",
    "        collection_date = row['start_time'] + pd.Timedelta(days=1)\n",
    "        \n",
    "        # Try exact datetime match first\n",
    "        matching_sample = filter_df[filter_df['SampleDate'] == collection_date]\n",
    "        \n",
    "        # If no exact match, try matching only the date part (ignoring time)\n",
    "        if len(matching_sample) == 0:\n",
    "            # Convert collection_date to date-only for comparison\n",
    "            collection_date_only = collection_date.date()\n",
    "            # Convert filter_df SampleDate to date-only for comparison\n",
    "            matching_sample = filter_df[filter_df['SampleDate'].dt.date == collection_date_only]\n",
    "            \n",
    "            if len(matching_sample) > 0:\n",
    "                print(f\"Found date-only match for {collection_date} -> {matching_sample['SampleDate'].iloc[0]}\")\n",
    "        \n",
    "        if len(matching_sample) > 0:\n",
    "            matches_found += 1\n",
    "            \n",
    "            # Add filter data to the overlap DataFrame\n",
    "            try:\n",
    "                overlap_df.loc[i, 'filter_id'] = matching_sample['filter_id'].iloc[0]\n",
    "                overlap_df.loc[i, 'EC_FTIR'] = matching_sample['EC_FTIR'].iloc[0]\n",
    "                overlap_df.loc[i, 'Fabs'] = matching_sample['Fabs'].iloc[0]\n",
    "                filter_columns_added = True\n",
    "            except Exception as e:\n",
    "                print(f\"Error adding filter data for {collection_date}: {e}\")\n",
    "            \n",
    "            # Process Aethalometer data for this period\n",
    "            period_end = row['end_time']\n",
    "            aeth_stats = extract_daily_aethalometer_data(aethalometer_df, row['start_time'], period_end)\n",
    "            \n",
    "            if aeth_stats:\n",
    "                for key, value in aeth_stats.items():\n",
    "                    if key not in ['period_start', 'period_end']:\n",
    "                        overlap_df.loc[i, f'aeth_{key}'] = value\n",
    "    \n",
    "    print(f\"Matched {matches_found} out of {len(overlap_df)} overlap periods with filter data\")\n",
    "    \n",
    "    # Check if we successfully added any data\n",
    "    if not filter_columns_added:\n",
    "        print(\"WARNING: No filter data was added to the overlap DataFrame\")\n",
    "        print(\"This could be due to a mismatch in dates or missing columns\")\n",
    "        \n",
    "        # Attempt a more lenient approach - match filter collection dates to the day before excellent periods\n",
    "        print(\"\\nAttempting alternative date matching approach...\")\n",
    "        \n",
    "        # Create a set of all filter collection dates (date only, no time)\n",
    "        filter_dates_set = set(date.date() for date in filter_df['SampleDate'] if not pd.isna(date))\n",
    "        \n",
    "        # Create a new DataFrame to store matches\n",
    "        new_overlap_df = pd.DataFrame()\n",
    "        \n",
    "        # For each filter date, find the corresponding excellent period\n",
    "        matches = 0\n",
    "        for collection_date in filter_dates_set:\n",
    "            # Convert to datetime for easier manipulation\n",
    "            collection_dt = pd.Timestamp(collection_date)\n",
    "            \n",
    "            # Find the excellent period that started 24h before this collection date\n",
    "            start_time = collection_dt.normalize() + pd.Timedelta(hours=9) - pd.Timedelta(days=1)\n",
    "            \n",
    "            # Check if this start time is in excellent_periods\n",
    "            if start_time in excellent_starts.values:\n",
    "                matches += 1\n",
    "                \n",
    "                # Get filter data\n",
    "                matching_filter = filter_df[filter_df['SampleDate'].dt.date == collection_date]\n",
    "                \n",
    "                if len(matching_filter) > 0:\n",
    "                    # Create a new row for this match\n",
    "                    new_row = pd.DataFrame({\n",
    "                        'start_time': [start_time],\n",
    "                        'end_time': [start_time + pd.Timedelta(days=1)],\n",
    "                        'filter_id': [matching_filter['filter_id'].iloc[0]],\n",
    "                        'EC_FTIR': [matching_filter['EC_FTIR'].iloc[0]],\n",
    "                        'Fabs': [matching_filter['Fabs'].iloc[0]]\n",
    "                    })\n",
    "                    \n",
    "                    # Add Aethalometer data\n",
    "                    aeth_stats = extract_daily_aethalometer_data(\n",
    "                        aethalometer_df, start_time, start_time + pd.Timedelta(days=1)\n",
    "                    )\n",
    "                    \n",
    "                    if aeth_stats:\n",
    "                        for key, value in aeth_stats.items():\n",
    "                            if key not in ['period_start', 'period_end']:\n",
    "                                new_row[f'aeth_{key}'] = value\n",
    "                    \n",
    "                    # Append to our new DataFrame\n",
    "                    new_overlap_df = pd.concat([new_overlap_df, new_row], ignore_index=True)\n",
    "        \n",
    "        if matches > 0:\n",
    "            print(f\"Alternative approach found {matches} matches\")\n",
    "            if len(new_overlap_df) > 0:\n",
    "                print(f\"Successfully created alternate overlap DataFrame with {len(new_overlap_df)} rows\")\n",
    "                print(f\"Columns: {new_overlap_df.columns.tolist()}\")\n",
    "                return new_overlap_df\n",
    "    \n",
    "    # Check which columns exist before dropping\n",
    "    print(f\"Overlap DataFrame columns: {overlap_df.columns.tolist()}\")\n",
    "    \n",
    "    # Define required columns\n",
    "    required_cols = ['filter_id', 'aeth_mean']\n",
    "    missing_cols = [col for col in required_cols if col not in overlap_df.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"WARNING: Missing required columns: {missing_cols}\")\n",
    "        print(\"Keeping all rows for now\")\n",
    "    else:\n",
    "        # Drop any rows without filter or Aethalometer data\n",
    "        print(\"Dropping rows with missing filter or Aethalometer data...\")\n",
    "        orig_len = len(overlap_df)\n",
    "        print(f\"Dropped {orig_len - len(overlap_df)} incomplete rows\")\n",
    "    \n",
    "    print(f\"Final count of complete overlapping periods: {len(overlap_df)}\")\n",
    "    \n",
    "    return overlap_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b417cd3",
   "metadata": {},
   "source": [
    "## Step 3: Smoothing Algorithm Implementations\n",
    " \n",
    "Here we implement the three smoothing algorithms to apply to Aethalometer data prior to comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d9f7577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Optimized Noise-reduction Algorithm (ONA)\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def _numba_nanmean(arr_slice):\n",
    "    \"\"\"\n",
    "    Numba-compatible nanmean function.\n",
    "    \"\"\"\n",
    "    finite_sum = 0.0\n",
    "    finite_count = 0\n",
    "    for x in arr_slice:\n",
    "        if not np.isnan(x): # np.isnan is Numba compatible\n",
    "            finite_sum += x\n",
    "            finite_count += 1\n",
    "    if finite_count == 0:\n",
    "        return np.nan\n",
    "    return finite_sum / finite_count\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def process_ona_segment_numba_core(\n",
    "    bc_col_np: np.ndarray,\n",
    "    atn_col_np: np.ndarray,\n",
    "    delta_atn_min: float,\n",
    "    num_rows: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Core ONA algorithm implemented for Numba.\n",
    "    Operates on NumPy arrays for a single data segment.\n",
    "    \"\"\"\n",
    "    # Initialize output arrays\n",
    "    smoothed_col_np = bc_col_np.copy() # Start with original BC values\n",
    "    points_col_np = np.ones(num_rows, dtype=np.int64) # Default points averaged is 1\n",
    "\n",
    "    # If only one point (or none) in the segment, it's effectively averaged with itself.\n",
    "    if num_rows <= 1:\n",
    "        return smoothed_col_np, points_col_np\n",
    "\n",
    "    j = 0 # Current starting index of the averaging window (0-based)\n",
    "    while j < num_rows:\n",
    "        cur_atn = atn_col_np[j]\n",
    "\n",
    "        # Find the end of the window (exclusive index).\n",
    "        # The window includes point j. All subsequent points k in the window\n",
    "        # must satisfy: atn_col_np[k] <= cur_atn + delta_atn_min\n",
    "        window_end_exclusive = j + 1\n",
    "        while window_end_exclusive < num_rows:\n",
    "            if atn_col_np[window_end_exclusive] > cur_atn + delta_atn_min:\n",
    "                break # End of window found\n",
    "            window_end_exclusive += 1\n",
    "        \n",
    "        # The current window for averaging is from index j to window_end_exclusive-1\n",
    "        slice_bc_np = bc_col_np[j:window_end_exclusive]\n",
    "        \n",
    "        avg_bc = _numba_nanmean(slice_bc_np)\n",
    "        num_points_in_window = window_end_exclusive - j # Length of the slice\n",
    "\n",
    "        # Apply the averaged BC value and points count to all rows in the window\n",
    "        for k_idx in range(j, window_end_exclusive):\n",
    "            smoothed_col_np[k_idx] = avg_bc\n",
    "            points_col_np[k_idx] = num_points_in_window\n",
    "            \n",
    "        # Move to the start of the next potential window\n",
    "        j = window_end_exclusive\n",
    "            \n",
    "    return smoothed_col_np, points_col_np\n",
    "\n",
    "def process_ona_segment_numba_wrapper(\n",
    "    pdf: pd.DataFrame,\n",
    "    bc_col: str,\n",
    "    atn_col: str,\n",
    "    points_col: str,\n",
    "    smoothed_col: str,\n",
    "    delta_atn_min: float\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Wrapper to run the ONA algorithm on one pandas segment using the Numba core.\n",
    "    Returns the pandas DataFrame with updated points_col and smoothed_col columns.\n",
    "    \"\"\"\n",
    "    # Initialize the columns with default values.\n",
    "    if points_col not in pdf.columns:\n",
    "        pdf[points_col] = 1\n",
    "    else:\n",
    "        pdf.loc[:, points_col] = 1 # Use .loc to avoid SettingWithCopyWarning\n",
    "\n",
    "    if smoothed_col not in pdf.columns:\n",
    "        pdf[smoothed_col] = pdf[bc_col].copy()\n",
    "    else:\n",
    "        pdf.loc[:, smoothed_col] = pdf[bc_col].copy()\n",
    "\n",
    "    if len(pdf) <= 1:\n",
    "        # If the segment is very short, ensure original values and 1 point averaged is returned\n",
    "        pdf.loc[:, smoothed_col] = pdf[bc_col].copy()\n",
    "        pdf.loc[:, points_col] = 1\n",
    "        return pdf\n",
    "\n",
    "    # Convert relevant pandas Series to NumPy arrays for Numba\n",
    "    bc_col_np = pdf[bc_col].to_numpy(dtype=np.float64, na_value=np.nan)\n",
    "    atn_col_np = pdf[atn_col].to_numpy(dtype=np.float64, na_value=np.nan)\n",
    "    \n",
    "    num_rows = len(pdf)\n",
    "\n",
    "    # Call the Numba-optimized core function\n",
    "    smoothed_result_np, points_result_np = process_ona_segment_numba_core(\n",
    "        bc_col_np, atn_col_np, delta_atn_min, num_rows\n",
    "    )\n",
    "\n",
    "    # Assign results back to the pandas DataFrame using .loc to ensure modification\n",
    "    pdf.loc[:, smoothed_col] = smoothed_result_np\n",
    "    pdf.loc[:, points_col] = points_result_np\n",
    "    \n",
    "    return pdf\n",
    "\n",
    "def apply_ona(data, wavelength=\"Red\", delta_atn_min=0.05):\n",
    "    \"\"\"\n",
    "    Apply the Optimized Noise-reduction Algorithm to Aethalometer data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame with Aethalometer data\n",
    "    wavelength : str\n",
    "        Which wavelength to process ('UV', 'Blue', 'Green', 'Red', 'IR')\n",
    "    delta_atn_min : float\n",
    "        Minimum change in attenuation to define a window\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    data_processed : pandas.DataFrame\n",
    "        DataFrame with original data plus additional columns for ONA processed BC\n",
    "    \"\"\"\n",
    "    # Column names\n",
    "    bc_col = f\"{wavelength} BCc\"\n",
    "    atn_col = f\"{wavelength} ATN1\"\n",
    "    points_col = f\"{wavelength}_points_averaged\"\n",
    "    smoothed_col = f\"{wavelength}_BC_ONA\"\n",
    "\n",
    "    # Check if required columns exist\n",
    "    if atn_col not in data.columns or bc_col not in data.columns:\n",
    "        print(f\"Warning: Required columns ({atn_col}, {bc_col}) not found for ONA on wavelength {wavelength}. Skipping ONA.\")\n",
    "        result_df = data.copy()\n",
    "        if points_col not in result_df.columns:\n",
    "            result_df[points_col] = 1\n",
    "        if smoothed_col not in result_df.columns:\n",
    "            if bc_col in result_df.columns:\n",
    "                result_df[smoothed_col] = result_df[bc_col]\n",
    "            else:\n",
    "                result_df[smoothed_col] = np.nan\n",
    "        return result_df\n",
    "\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Calculate absolute ATN differences to identify filter changes\n",
    "    df['Î”ATN'] = df[atn_col].diff().abs()\n",
    "    \n",
    "    # A new segment starts if Î”ATN > 30 OR if Î”ATN is null (first row)\n",
    "    df['segment_id'] = ((df['Î”ATN'] > 30) | df['Î”ATN'].isna()).astype(int).cumsum()\n",
    "    \n",
    "    actual_filter_changes = df[df['Î”ATN'] > 30].shape[0]\n",
    "    print(f\"Number of actual filter changes (Î”ATN > 30) detected for {wavelength}: {actual_filter_changes}\")\n",
    "    \n",
    "    # Initialize output columns\n",
    "    df[points_col] = 1\n",
    "    df[smoothed_col] = df[bc_col].copy()\n",
    "    \n",
    "    # Process each segment\n",
    "    segments = df.groupby('segment_id')\n",
    "    processed_segments = []\n",
    "    \n",
    "    for seg_id, segment in segments:\n",
    "        # Sort by index within segment to ensure time order\n",
    "        segment = segment.sort_index()\n",
    "        \n",
    "        # Process the segment\n",
    "        processed_segment = process_ona_segment_numba_wrapper(\n",
    "            segment, bc_col, atn_col, points_col, smoothed_col, delta_atn_min\n",
    "        )\n",
    "        \n",
    "        processed_segments.append(processed_segment)\n",
    "    \n",
    "    # Combine processed segments\n",
    "    if processed_segments:\n",
    "        result_df = pd.concat(processed_segments)\n",
    "        # Restore original sort order\n",
    "        result_df = result_df.sort_index()\n",
    "        \n",
    "        # Drop temporary columns\n",
    "        result_df = result_df.drop(['Î”ATN', 'segment_id'], axis=1)\n",
    "    else:\n",
    "        # Fallback if no segments were processed\n",
    "        result_df = df.drop(['Î”ATN', 'segment_id'], axis=1)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317d33ad",
   "metadata": {},
   "source": [
    "# Implementation of Centered Moving Average (CMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a80550e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cma(data, wavelength='Red', window_size=None):\n",
    "    \"\"\"\n",
    "    Apply the Centered Moving Average algorithm to Aethalometer data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame containing Aethalometer data\n",
    "    wavelength : str\n",
    "        Which wavelength to process ('UV', 'Blue', 'Green', 'Red', 'IR')\n",
    "    window_size : int or None\n",
    "        Size of the moving average window (must be odd). If None, \n",
    "        will use a default based on the data's timebase\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    data_smoothed : pandas.DataFrame\n",
    "        DataFrame with the original data plus additional columns for smoothed BC\n",
    "    \"\"\"\n",
    "    # Create a copy of the input dataframe\n",
    "    data_smoothed = data.copy()\n",
    "    \n",
    "    # Identify the column for BC values based on wavelength\n",
    "    bc_col = f\"{wavelength} BCc\"\n",
    "    smoothed_bc_col = f\"{wavelength}_BC_CMA\"\n",
    "    \n",
    "    # Determine window size if not specified\n",
    "    if window_size is None:\n",
    "        if 'Timebase (s)' in data_smoothed.columns:\n",
    "            timebase = data_smoothed['Timebase (s)'].iloc[0]\n",
    "            if timebase == 1:\n",
    "                window_size = 11  # 11 seconds for 1-second data\n",
    "            elif timebase == 5:\n",
    "                window_size = 5   # 25 seconds for 5-second data\n",
    "            elif timebase == 60:\n",
    "                window_size = 3   # 3 minutes for 1-minute data\n",
    "            else:\n",
    "                window_size = 5   # Default for other timebases\n",
    "        else:\n",
    "            window_size = 5       # Default if timebase is unknown\n",
    "    \n",
    "    # Make sure window_size is odd\n",
    "    if window_size % 2 == 0:\n",
    "        window_size += 1\n",
    "    \n",
    "    print(f\"Using window size of {window_size} for CMA on {wavelength}\")\n",
    "    \n",
    "    # Apply rolling mean with center=True\n",
    "    if bc_col in data_smoothed.columns:\n",
    "        data_smoothed[smoothed_bc_col] = data_smoothed[bc_col].rolling(\n",
    "            window=window_size, center=True, min_periods=1\n",
    "        ).mean()\n",
    "    else:\n",
    "        print(f\"Warning: {bc_col} not found in data, cannot apply CMA\")\n",
    "        data_smoothed[smoothed_bc_col] = np.nan\n",
    "    \n",
    "    return data_smoothed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6dbd37",
   "metadata": {},
   "source": [
    "# Implementation of Double Exponentially Weighted Moving Average (DEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81fad5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dema(data, wavelength='Red', alpha=None):\n",
    "    \"\"\"\n",
    "    Apply the Double Exponentially Weighted Moving Average algorithm\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame containing Aethalometer data\n",
    "    wavelength : str\n",
    "        Which wavelength to process ('UV', 'Blue', 'Green', 'Red', 'IR')\n",
    "    alpha : float\n",
    "        Smoothing parameter (between 0 and 1)\n",
    "        For 60s data, 0.125 approximates a 15-minute smoothing window\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    data_smoothed : pandas.DataFrame\n",
    "        DataFrame with the original data plus additional columns for smoothed BC\n",
    "    \"\"\"\n",
    "    # Create a copy of the input dataframe\n",
    "    data_smoothed = data.copy()\n",
    "    \n",
    "    # Identify the column for BC values based on wavelength\n",
    "    bc_col = f\"{wavelength} BCc\"\n",
    "    ema_col = f\"{wavelength}_EMA\"\n",
    "    dema_col = f\"{wavelength}_BC_DEMA\"\n",
    "    \n",
    "    # Set the smoothing parameter based on timebase if not explicitly provided\n",
    "    if 'Timebase (s)' in data_smoothed.columns:\n",
    "        timebase = data_smoothed['Timebase (s)'].iloc[0]\n",
    "        if alpha is None:\n",
    "            # Use formula 2/(N+1) where N is the desired smoothing period\n",
    "            if timebase == 1:\n",
    "                # Default to approximate 5-minute window for 1-second data\n",
    "                N = 300 / timebase\n",
    "            elif timebase == 5:\n",
    "                # Default to approximate 5-minute window for 5-second data\n",
    "                N = 300 / timebase\n",
    "            elif timebase == 60:\n",
    "                # Default to approximate 15-minute window for 60-second data\n",
    "                N = 900 / timebase\n",
    "            else:\n",
    "                N = 15  # Default for other timebases\n",
    "                \n",
    "            alpha = 2 / (N + 1)\n",
    "    else:\n",
    "        # Default alpha if timebase is unknown\n",
    "        if alpha is None:\n",
    "            alpha = 0.125\n",
    "    \n",
    "    print(f\"Using alpha of {alpha:.4f} for DEMA on {wavelength}\")\n",
    "    \n",
    "    if bc_col in data_smoothed.columns:\n",
    "        # First EMA calculation\n",
    "        data_smoothed[ema_col] = data_smoothed[bc_col].ewm(alpha=alpha, adjust=False).mean()\n",
    "        \n",
    "        # Second EMA calculation (EMA of EMA)\n",
    "        ema_of_ema = data_smoothed[ema_col].ewm(alpha=alpha, adjust=False).mean()\n",
    "        \n",
    "        # Calculate DEMA: (2 * EMA) - EMA(EMA)\n",
    "        data_smoothed[dema_col] = 2 * data_smoothed[ema_col] - ema_of_ema\n",
    "    else:\n",
    "        print(f\"Warning: {bc_col} not found in data, cannot apply DEMA\")\n",
    "        data_smoothed[ema_col] = np.nan\n",
    "        data_smoothed[dema_col] = np.nan\n",
    "    \n",
    "    return data_smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6def045",
   "metadata": {},
   "source": [
    "## Step 4: Function to Apply All Smoothing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52c15343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_all_smoothing_methods(aethalometer_df, wavelength=\"Red\"):\n",
    "    \"\"\"\n",
    "    Apply all three smoothing methods to aethalometer data for a specific wavelength.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    aethalometer_df : pandas.DataFrame\n",
    "        DataFrame with aethalometer data\n",
    "    wavelength : str\n",
    "        Wavelength to process ('UV', 'Blue', 'Green', 'Red', 'IR')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    smoothed_data : dict\n",
    "        Dictionary with keys 'raw', 'ona', 'cma', 'dema' containing the processed dataframes\n",
    "    \"\"\"\n",
    "    print(f\"\\nApplying smoothing methods to {wavelength} wavelength data...\")\n",
    "    \n",
    "    # Raw data (unprocessed)\n",
    "    raw_data = aethalometer_df.copy()\n",
    "    \n",
    "    # Apply ONA\n",
    "    print(f\"\\nApplying ONA to {wavelength} wavelength data...\")\n",
    "    ona_data = apply_ona(aethalometer_df, wavelength)\n",
    "    \n",
    "    # Apply CMA\n",
    "    print(f\"\\nApplying CMA to {wavelength} wavelength data...\")\n",
    "    cma_data = apply_cma(aethalometer_df, wavelength)\n",
    "    \n",
    "    # Apply DEMA\n",
    "    print(f\"\\nApplying DEMA to {wavelength} wavelength data...\")\n",
    "    dema_data = apply_dema(aethalometer_df, wavelength)\n",
    "    \n",
    "    return {\n",
    "        'raw': raw_data,\n",
    "        'ona': ona_data,\n",
    "        'cma': cma_data,\n",
    "        'dema': dema_data\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a635584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_smoothed_aethalometer_data(smoothed_data, method, period_start, period_end, wavelength=\"Red\"):\n",
    "    \"\"\"\n",
    "    Extract and process smoothed Aethalometer data for a specific 24-hour period.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    smoothed_data : dict\n",
    "        Dictionary with keys 'raw', 'ona', 'cma', 'dema' containing the processed dataframes\n",
    "    method : str\n",
    "        Smoothing method ('raw', 'ona', 'cma', 'dema')\n",
    "    period_start, period_end : datetime\n",
    "        Start and end of the 24-hour period\n",
    "    wavelength : str\n",
    "        Wavelength to process ('UV', 'Blue', 'Green', 'Red', 'IR')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    stats : dict\n",
    "        Dictionary with summary statistics for the period\n",
    "    \"\"\"\n",
    "    # Select the column based on smoothing method\n",
    "    if method == 'raw':\n",
    "        column = f\"{wavelength} BCc\"\n",
    "        df = smoothed_data['raw']\n",
    "    elif method == 'ona':\n",
    "        column = f\"{wavelength}_BC_ONA\"\n",
    "        df = smoothed_data['ona']\n",
    "    elif method == 'cma':\n",
    "        column = f\"{wavelength}_BC_CMA\"\n",
    "        df = smoothed_data['cma']\n",
    "    elif method == 'dema':\n",
    "        column = f\"{wavelength}_BC_DEMA\"\n",
    "        df = smoothed_data['dema']\n",
    "    else:\n",
    "        print(f\"Invalid method: {method}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Extract data for the specific period\n",
    "        period_data = df.loc[period_start:period_end, column].dropna()\n",
    "        \n",
    "        if len(period_data) == 0:\n",
    "            return None\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats = {\n",
    "            'period_start': period_start,\n",
    "            'period_end': period_end,\n",
    "            'count': len(period_data),\n",
    "            'mean': period_data.mean(),\n",
    "            'median': period_data.median(),\n",
    "            'min': period_data.min(),\n",
    "            'max': period_data.max(),\n",
    "            'std': period_data.std(),\n",
    "            '25th': period_data.quantile(0.25),\n",
    "            '75th': period_data.quantile(0.75),\n",
    "            'negative_count': (period_data < 0).sum(),\n",
    "            'negative_percent': (period_data < 0).mean() * 100\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting {method} data for period {period_start} to {period_end}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "337ad379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_overlap_df_with_all_methods(overlap_df_raw, smoothed_data, wavelength=\"Red\"):\n",
    "    \"\"\"\n",
    "    Add columns for all smoothing methods to the overlap DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    overlap_df_raw : pandas.DataFrame\n",
    "        DataFrame with periods that overlap between Aethalometer and filter samples\n",
    "    smoothed_data : dict\n",
    "        Dictionary with keys 'raw', 'ona', 'cma', 'dema' containing the processed dataframes\n",
    "    wavelength : str\n",
    "        Wavelength to process ('UV', 'Blue', 'Green', 'Red', 'IR')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    overlap_df_all : pandas.DataFrame\n",
    "        DataFrame with additional columns for all smoothing methods\n",
    "    \"\"\"\n",
    "    print(\"Creating overlap DataFrame with all smoothing methods...\")\n",
    "    print(f\"Input overlap_df_raw shape: {overlap_df_raw.shape}\")\n",
    "    \n",
    "    # Create a copy of the raw overlap DataFrame\n",
    "    overlap_df_all = overlap_df_raw.copy()\n",
    "    \n",
    "    # Method column names\n",
    "    method_columns = {\n",
    "        'raw': f\"{wavelength} BCc\",\n",
    "        'ona': f\"{wavelength}_BC_ONA\",\n",
    "        'cma': f\"{wavelength}_BC_CMA\",\n",
    "        'dema': f\"{wavelength}_BC_DEMA\"\n",
    "    }\n",
    "    \n",
    "    method_display_names = {\n",
    "        'raw': 'Raw',\n",
    "        'ona': 'ONA',\n",
    "        'cma': 'CMA',\n",
    "        'dema': 'DEMA'\n",
    "    }\n",
    "    \n",
    "    # Process each period for each method\n",
    "    for i, row in overlap_df_all.iterrows():\n",
    "        period_start = row['start_time']\n",
    "        period_end = row['end_time']\n",
    "        \n",
    "        for method_key, method_col in method_columns.items():\n",
    "            df = smoothed_data[method_key]\n",
    "            \n",
    "            # Skip if column doesn't exist\n",
    "            if method_col not in df.columns:\n",
    "                print(f\"Warning: {method_col} not found in {method_key} data\")\n",
    "                continue\n",
    "            \n",
    "            # Extract data for this period\n",
    "            period_data = df.loc[period_start:period_end, method_col].copy()\n",
    "            \n",
    "            if len(period_data) == 0:\n",
    "                print(f\"Warning: No data found for period {period_start} to {period_end}\")\n",
    "                continue\n",
    "            \n",
    "            # Calculate statistics\n",
    "            prefix = 'aeth_' if method_key == 'raw' else f'{method_key}_'\n",
    "            \n",
    "            # Save all statistics\n",
    "            overlap_df_all.loc[i, f'{prefix}count'] = len(period_data)\n",
    "            overlap_df_all.loc[i, f'{prefix}mean'] = period_data.mean()\n",
    "            overlap_df_all.loc[i, f'{prefix}median'] = period_data.median()\n",
    "            overlap_df_all.loc[i, f'{prefix}min'] = period_data.min()\n",
    "            overlap_df_all.loc[i, f'{prefix}max'] = period_data.max()\n",
    "            overlap_df_all.loc[i, f'{prefix}std'] = period_data.std()\n",
    "            overlap_df_all.loc[i, f'{prefix}25th'] = period_data.quantile(0.25)\n",
    "            overlap_df_all.loc[i, f'{prefix}75th'] = period_data.quantile(0.75)\n",
    "            overlap_df_all.loc[i, f'{prefix}negative_count'] = (period_data < 0).sum()\n",
    "            overlap_df_all.loc[i, f'{prefix}negative_percent'] = (period_data < 0).mean() * 100\n",
    "    \n",
    "    # Print a summary of what we've added\n",
    "    print(\"\\nStatistics added for each smoothing method:\")\n",
    "    for method_key, display_name in method_display_names.items():\n",
    "        prefix = 'aeth_' if method_key == 'raw' else f'{method_key}_'\n",
    "        if f'{prefix}mean' in overlap_df_all.columns:\n",
    "            print(f\"{display_name} ({method_key}) - Mean BC range: {overlap_df_all[f'{prefix}mean'].min():.1f} to {overlap_df_all[f'{prefix}mean'].max():.1f}\")\n",
    "    \n",
    "    # Add mean differences between methods\n",
    "    for method1 in ['raw', 'ona', 'cma', 'dema']:\n",
    "        for method2 in ['raw', 'ona', 'cma', 'dema']:\n",
    "            if method1 != method2:\n",
    "                prefix1 = 'aeth_' if method1 == 'raw' else f'{method1}_'\n",
    "                prefix2 = 'aeth_' if method2 == 'raw' else f'{method2}_'\n",
    "                \n",
    "                if f'{prefix1}mean' in overlap_df_all.columns and f'{prefix2}mean' in overlap_df_all.columns:\n",
    "                    col_name = f'{method1}_vs_{method2}_diff_pct'\n",
    "                    overlap_df_all[col_name] = (overlap_df_all[f'{prefix1}mean'] - overlap_df_all[f'{prefix2}mean']) / overlap_df_all[f'{prefix2}mean'] * 100\n",
    "    \n",
    "    print(f\"Output overlap_df_all shape: {overlap_df_all.shape}\")\n",
    "    print(f\"Column count: {len(overlap_df_all.columns)}\")\n",
    "    return overlap_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8335fd",
   "metadata": {},
   "source": [
    "## Step 6: Enhanced Visualization Functions for Comparison with Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cd529ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bc_scatter_all_methods(overlap_df, y_param='EC_FTIR', wavelength=\"Red\", title_prefix=None):\n",
    "    \"\"\"\n",
    "    Create scatter plots comparing all smoothing methods with FTIR EC or HIPS Fabs.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    overlap_df : pandas.DataFrame\n",
    "        DataFrame with overlapping periods including all smoothing methods\n",
    "    y_param : str\n",
    "        Filter parameter to compare against ('EC_FTIR' or 'Fabs')\n",
    "    wavelength : str\n",
    "        Wavelength used for BC data\n",
    "    title_prefix : str or None\n",
    "        Optional prefix for plot title\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        Figure with the plots\n",
    "    \"\"\"\n",
    "    # Method column mappings\n",
    "    method_columns = {\n",
    "        'Raw': 'aeth_mean',\n",
    "        'ONA': 'ona_mean',\n",
    "        'CMA': 'cma_mean',\n",
    "        'DEMA': 'dema_mean'\n",
    "    }\n",
    "    \n",
    "    # Method colors and markers\n",
    "    method_styles = {\n",
    "        'Raw': {'color': 'black', 'marker': 'o', 'alpha': 0.5},\n",
    "        'ONA': {'color': 'blue', 'marker': 's', 'alpha': 0.7},\n",
    "        'CMA': {'color': 'red', 'marker': '^', 'alpha': 0.7},\n",
    "        'DEMA': {'color': 'green', 'marker': 'D', 'alpha': 0.7}\n",
    "    }\n",
    "    \n",
    "    # Parameter labels\n",
    "    param_labels = {\n",
    "        'EC_FTIR': 'FTIR EC (Î¼g/mÂ³)',\n",
    "        'Fabs': 'HIPS Fabs'\n",
    "    }\n",
    "    \n",
    "    # Create figure with 2x2 subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Title for the figure\n",
    "    if title_prefix is None:\n",
    "        title_prefix = f\"{wavelength} BCc vs\"\n",
    "    fig.suptitle(f\"{title_prefix} {param_labels.get(y_param, y_param)}\\nComparison of Smoothing Methods\", fontsize=16)\n",
    "    \n",
    "    # Process each method\n",
    "    regression_results = {}\n",
    "    for i, (method_name, col_name) in enumerate(method_columns.items()):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Skip if column not available\n",
    "        if col_name not in overlap_df.columns or y_param not in overlap_df.columns:\n",
    "            ax.text(0.5, 0.5, f\"Data not available for {method_name}\", \n",
    "                    ha='center', va='center', transform=ax.transAxes)\n",
    "            continue\n",
    "        \n",
    "        # Prepare data\n",
    "        x = overlap_df[col_name] / 1000  # Convert from ng/mÂ³ to Î¼g/mÂ³\n",
    "        y = overlap_df[y_param]\n",
    "        \n",
    "        # Create scatter plot\n",
    "        style = method_styles[method_name]\n",
    "        scatter = ax.scatter(x, y, s=80, **style)\n",
    "        \n",
    "        # Calculate and add trendline\n",
    "        mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "        if mask.sum() > 1:  # Need at least 2 valid points for regression\n",
    "            slope, intercept = np.polyfit(x[mask], y[mask], 1)\n",
    "            x_line = np.linspace(x.min(), x.max(), 100)\n",
    "            y_line = slope * x_line + intercept\n",
    "            ax.plot(x_line, y_line, 'r--', linewidth=2)\n",
    "            \n",
    "            # Add regression equation and RÂ² to plot\n",
    "            r_value = pearsonr(x[mask], y[mask])[0]\n",
    "            r_squared = r_value**2\n",
    "            \n",
    "            equation = f\"y = {slope:.3f}x + {intercept:.3f}\"\n",
    "            r2_text = f\"RÂ² = {r_squared:.3f}\"\n",
    "            \n",
    "            ax.annotate(\n",
    "                equation + '\\n' + r2_text,\n",
    "                xy=(0.05, 0.95),\n",
    "                xycoords='axes fraction',\n",
    "                fontsize=12,\n",
    "                ha='left',\n",
    "                va='top',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8)\n",
    "            )\n",
    "            \n",
    "            # Store regression results\n",
    "            regression_results[method_name] = {\n",
    "                'slope': slope,\n",
    "                'intercept': intercept,\n",
    "                'r_squared': r_squared,\n",
    "                'data_points': mask.sum()\n",
    "            }\n",
    "        \n",
    "        # Format subplot\n",
    "        ax.set_title(f\"{method_name} Processing\", fontsize=14)\n",
    "        if i >= 2:  # Only add x-label to bottom row\n",
    "            ax.set_xlabel(f'Aethalometer {wavelength} BC (Î¼g/mÂ³)', fontsize=12)\n",
    "        if i % 2 == 0:  # Only add y-label to left column\n",
    "            ax.set_ylabel(param_labels.get(y_param, y_param), fontsize=12)\n",
    "        \n",
    "        # Make sure axes start at 0 if all data is positive\n",
    "        if x.min() >= 0 and y.min() >= 0:\n",
    "            ax.set_xlim(left=0)\n",
    "            ax.set_ylim(bottom=0)\n",
    "        \n",
    "        # Add grid\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add 1:1 line if units are comparable\n",
    "        if y_param == 'EC_FTIR':\n",
    "            max_val = max(x.max(), y.max()) * 1.1\n",
    "            ax.plot([0, max_val], [0, max_val], 'k--', alpha=0.3, linewidth=1, label='1:1 Line')\n",
    "            ax.legend()\n",
    "    \n",
    "    # Add a summary table in a text box\n",
    "    if regression_results:\n",
    "        table_text = \"Regression Results:\\n\"\n",
    "        table_text += \"-\" * 60 + \"\\n\"\n",
    "        table_text += f\"{'Method':<10} {'Slope':<10} {'Intercept':<10} {'RÂ²':<10} {'N':<10}\\n\"\n",
    "        table_text += \"-\" * 60 + \"\\n\"\n",
    "        \n",
    "        for method, results in regression_results.items():\n",
    "            table_text += f\"{method:<10} {results['slope']:<10.3f} {results['intercept']:<10.3f} \"\n",
    "            table_text += f\"{results['r_squared']:<10.3f} {results['data_points']:<10}\\n\"\n",
    "        \n",
    "        fig.text(0.5, 0.01, table_text, ha='center', va='bottom', \n",
    "                fontsize=10, family='monospace', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9, bottom=0.15)  # Adjust for suptitle and table\n",
    "    \n",
    "    return fig, regression_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8eeb479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_method_comparison_all_smoothing(overlap_df, wavelength=\"Red\"):\n",
    "    \"\"\"\n",
    "    Create a comprehensive comparison plot of all smoothing methods against both FTIR and HIPS.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    overlap_df : pandas.DataFrame\n",
    "        DataFrame with overlapping periods including all smoothing methods\n",
    "    wavelength : str\n",
    "        Wavelength used for BC data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        Figure with the plots\n",
    "    \"\"\"\n",
    "    # Method column mappings\n",
    "    method_columns = {\n",
    "        'Raw': 'aeth_mean',\n",
    "        'ONA': 'ona_mean',\n",
    "        'CMA': 'cma_mean',\n",
    "        'DEMA': 'dema_mean'\n",
    "    }\n",
    "    \n",
    "    # Method colors and markers\n",
    "    method_styles = {\n",
    "        'Raw': {'color': 'black', 'marker': 'o', 'alpha': 0.5},\n",
    "        'ONA': {'color': 'blue', 'marker': 's', 'alpha': 0.7},\n",
    "        'CMA': {'color': 'red', 'marker': '^', 'alpha': 0.7},\n",
    "        'DEMA': {'color': 'green', 'marker': 'D', 'alpha': 0.7}\n",
    "    }\n",
    "    \n",
    "    # Create figure with 2 subplots (one for FTIR, one for HIPS)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # Plot titles\n",
    "    axes[0].set_title(f\"Comparison with FTIR EC\\n({wavelength} Wavelength, {len(overlap_df)} periods)\", fontsize=14)\n",
    "    axes[1].set_title(f\"Comparison with HIPS Fabs\\n({wavelength} Wavelength, {len(overlap_df)} periods)\", fontsize=14)\n",
    "    \n",
    "    # Process each method for FTIR EC (left plot)\n",
    "    regression_results_ftir = {}\n",
    "    for method_name, col_name in method_columns.items():\n",
    "        if col_name in overlap_df.columns and 'EC_FTIR' in overlap_df.columns:\n",
    "            # Prepare data\n",
    "            x = overlap_df[col_name] / 1000  # Convert from ng/mÂ³ to Î¼g/mÂ³\n",
    "            y = overlap_df['EC_FTIR']\n",
    "            \n",
    "            # Create scatter plot\n",
    "            style = method_styles[method_name]\n",
    "            scatter = axes[0].scatter(x, y, s=80, label=method_name, **style)\n",
    "            \n",
    "            # Calculate and add trendline\n",
    "            mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "            if mask.sum() > 1:  # Need at least 2 valid points for regression\n",
    "                slope, intercept = np.polyfit(x[mask], y[mask], 1)\n",
    "                x_line = np.linspace(x.min(), x.max(), 100)\n",
    "                y_line = slope * x_line + intercept\n",
    "                axes[0].plot(x_line, y_line, color=style['color'], linestyle='--', linewidth=2)\n",
    "                \n",
    "                # Store regression results\n",
    "                r_value = pearsonr(x[mask], y[mask])[0]\n",
    "                r_squared = r_value**2\n",
    "                regression_results_ftir[method_name] = {\n",
    "                    'slope': slope,\n",
    "                    'intercept': intercept,\n",
    "                    'r_squared': r_squared,\n",
    "                    'data_points': mask.sum()\n",
    "                }\n",
    "    \n",
    "    # Add 1:1 line to FTIR plot\n",
    "    max_val_ftir = axes[0].get_xlim()[1]\n",
    "    axes[0].plot([0, max_val_ftir], [0, max_val_ftir], 'k--', alpha=0.3, linewidth=1, label='1:1 Line')\n",
    "    \n",
    "    # Process each method for HIPS Fabs (right plot)\n",
    "    regression_results_hips = {}\n",
    "    for method_name, col_name in method_columns.items():\n",
    "        if col_name in overlap_df.columns and 'Fabs' in overlap_df.columns:\n",
    "            # Prepare data\n",
    "            x = overlap_df[col_name] / 1000  # Convert from ng/mÂ³ to Î¼g/mÂ³\n",
    "            y = overlap_df['Fabs']\n",
    "            \n",
    "            # Create scatter plot\n",
    "            style = method_styles[method_name]\n",
    "            scatter = axes[1].scatter(x, y, s=80, label=method_name, **style)\n",
    "            \n",
    "            # Calculate and add trendline\n",
    "            mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "            if mask.sum() > 1:  # Need at least 2 valid points for regression\n",
    "                slope, intercept = np.polyfit(x[mask], y[mask], 1)\n",
    "                x_line = np.linspace(x.min(), x.max(), 100)\n",
    "                y_line = slope * x_line + intercept\n",
    "                axes[1].plot(x_line, y_line, color=style['color'], linestyle='--', linewidth=2)\n",
    "                \n",
    "                # Store regression results\n",
    "                r_value = pearsonr(x[mask], y[mask])[0]\n",
    "                r_squared = r_value**2\n",
    "                regression_results_hips[method_name] = {\n",
    "                    'slope': slope,\n",
    "                    'intercept': intercept,\n",
    "                    'r_squared': r_squared,\n",
    "                    'data_points': mask.sum()\n",
    "                }\n",
    "    \n",
    "    # Format plots\n",
    "    for i, ax in enumerate(axes):\n",
    "        y_label = 'FTIR EC (Î¼g/mÂ³)' if i == 0 else 'HIPS Fabs'\n",
    "        ax.set_xlabel(f'Aethalometer {wavelength} BC (Î¼g/mÂ³)', fontsize=12)\n",
    "        ax.set_ylabel(y_label, fontsize=12)\n",
    "        ax.legend()\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Make sure axes start at 0 if all data is positive\n",
    "        ax.set_xlim(left=0)\n",
    "        ax.set_ylim(bottom=0)\n",
    "    \n",
    "    # Add a summary table for each regression\n",
    "    if regression_results_ftir or regression_results_hips:\n",
    "        table_text = \"Regression Results Summary:\\n\\n\"\n",
    "        \n",
    "        # FTIR results\n",
    "        if regression_results_ftir:\n",
    "            table_text += \"FTIR EC Comparison:\\n\"\n",
    "            table_text += \"-\" * 60 + \"\\n\"\n",
    "            table_text += f\"{'Method':<10} {'Slope':<10} {'Intercept':<10} {'RÂ²':<10} {'N':<10}\\n\"\n",
    "            table_text += \"-\" * 60 + \"\\n\"\n",
    "            \n",
    "            for method, results in regression_results_ftir.items():\n",
    "                table_text += f\"{method:<10} {results['slope']:<10.3f} {results['intercept']:<10.3f} \"\n",
    "                table_text += f\"{results['r_squared']:<10.3f} {results['data_points']:<10}\\n\"\n",
    "        \n",
    "        # HIPS results\n",
    "        if regression_results_hips:\n",
    "            if regression_results_ftir:\n",
    "                table_text += \"\\n\"\n",
    "            table_text += \"HIPS Fabs Comparison:\\n\"\n",
    "            table_text += \"-\" * 60 + \"\\n\"\n",
    "            table_text += f\"{'Method':<10} {'Slope':<10} {'Intercept':<10} {'RÂ²':<10} {'N':<10}\\n\"\n",
    "            table_text += \"-\" * 60 + \"\\n\"\n",
    "            \n",
    "            for method, results in regression_results_hips.items():\n",
    "                table_text += f\"{method:<10} {results['slope']:<10.3f} {results['intercept']:<10.3f} \"\n",
    "                table_text += f\"{results['r_squared']:<10.3f} {results['data_points']:<10}\\n\"\n",
    "        \n",
    "        fig.text(0.5, 0.01, table_text, ha='center', va='bottom', \n",
    "                fontsize=10, family='monospace', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.25)  # Adjust for table\n",
    "    \n",
    "    return fig, {'ftir': regression_results_ftir, 'hips': regression_results_hips}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a0d0071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seasonal_comparison_smoothed(overlap_df, smoothing_method, wavelength=\"Red\"):\n",
    "    \"\"\"\n",
    "    Create seasonal comparison plots for a specific smoothing method.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    overlap_df : pandas.DataFrame\n",
    "        DataFrame with overlapping periods including all smoothing methods\n",
    "    smoothing_method : str\n",
    "        Smoothing method to plot ('raw', 'ona', 'cma', 'dema')\n",
    "    wavelength : str\n",
    "        Wavelength used for BC data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        Figure with the plots\n",
    "    \"\"\"\n",
    "    # Column mapping based on smoothing method\n",
    "    method_column_map = {\n",
    "        'raw': 'aeth_mean',\n",
    "        'ona': 'ona_mean',\n",
    "        'cma': 'cma_mean',\n",
    "        'dema': 'dema_mean'\n",
    "    }\n",
    "    \n",
    "    method_display_names = {\n",
    "        'raw': 'Raw',\n",
    "        'ona': 'ONA',\n",
    "        'cma': 'CMA',\n",
    "        'dema': 'DEMA'\n",
    "    }\n",
    "    \n",
    "    # Get the correct column\n",
    "    bc_col = method_column_map.get(smoothing_method.lower())\n",
    "    if bc_col not in overlap_df.columns:\n",
    "        print(f\"Error: Column {bc_col} not found in overlap_df\")\n",
    "        return None\n",
    "    \n",
    "    # Add date and season information\n",
    "    df = overlap_df.copy()\n",
    "    if 'date' not in df.columns:\n",
    "        df['date'] = df['start_time'].dt.date\n",
    "    \n",
    "    if 'month' not in df.columns:\n",
    "        df['month'] = df['start_time'].dt.month\n",
    "    \n",
    "    # Map Ethiopian seasons\n",
    "    def map_ethiopian_seasons(month):\n",
    "        \"\"\"Maps month number to Ethiopian season name.\"\"\"\n",
    "        if month in [10, 11, 12, 1, 2]:\n",
    "            return 'Dry Season'\n",
    "        elif month in [3, 4, 5]:\n",
    "            return 'Belg Rainy Season'\n",
    "        else:  # months 6â€“9\n",
    "            return 'Kiremt Rainy Season'\n",
    "    \n",
    "    df['season'] = df['month'].apply(map_ethiopian_seasons)\n",
    "    \n",
    "    # Convert Aethalometer BC from ng/mÂ³ to Î¼g/mÂ³\n",
    "    df['bc_ug'] = df[bc_col] / 1000\n",
    "    \n",
    "    # Define colors for seasons\n",
    "    season_colors = {\n",
    "        'Dry Season': 'gold',\n",
    "        'Belg Rainy Season': 'limegreen',\n",
    "        'Kiremt Rainy Season': 'royalblue'\n",
    "    }\n",
    "    \n",
    "    # Create figure with 2 subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # Plot 1: BC vs EC_FTIR by season\n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    # Separate scatter plots for each season\n",
    "    for season, color in season_colors.items():\n",
    "        season_data = df[df['season'] == season]\n",
    "        if len(season_data) > 0:\n",
    "            ax1.scatter(\n",
    "                season_data['bc_ug'], \n",
    "                season_data['EC_FTIR'],\n",
    "                alpha=0.7, \n",
    "                s=80, \n",
    "                c=color, \n",
    "                edgecolor='black',\n",
    "                label=f\"{season} (n={len(season_data)})\"\n",
    "            )\n",
    "    \n",
    "    # Overall trendline\n",
    "    mask1 = ~np.isnan(df['bc_ug']) & ~np.isnan(df['EC_FTIR'])\n",
    "    \n",
    "    if mask1.sum() > 1:\n",
    "        slope1, intercept1 = np.polyfit(df.loc[mask1, 'bc_ug'], df.loc[mask1, 'EC_FTIR'], 1)\n",
    "        x_line1 = np.linspace(df['bc_ug'].min(), df['bc_ug'].max(), 100)\n",
    "        y_line1 = slope1 * x_line1 + intercept1\n",
    "        ax1.plot(x_line1, y_line1, 'r--', linewidth=2, label='All Seasons Fit')\n",
    "        \n",
    "        # Add regression equation and RÂ²\n",
    "        r_value1 = pearsonr(df.loc[mask1, 'bc_ug'], df.loc[mask1, 'EC_FTIR'])[0]\n",
    "        r_squared1 = r_value1**2\n",
    "        \n",
    "        equation1 = f\"y = {slope1:.3f}x + {intercept1:.3f}\"\n",
    "        r2_text1 = f\"RÂ² = {r_squared1:.3f}\"\n",
    "        \n",
    "        ax1.annotate(\n",
    "            equation1 + '\\n' + r2_text1,\n",
    "            xy=(0.05, 0.95),\n",
    "            xycoords='axes fraction',\n",
    "            fontsize=12,\n",
    "            ha='left',\n",
    "            va='top',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8)\n",
    "        )\n",
    "    \n",
    "    # Format plot 1\n",
    "    ax1.set_xlabel(f'Aethalometer {wavelength} BC (Î¼g/mÂ³) - {method_display_names[smoothing_method.lower()]}', fontsize=12)\n",
    "    ax1.set_ylabel('FTIR EC (Î¼g/mÂ³)', fontsize=12)\n",
    "    ax1.set_title(f\"{wavelength} BC ({method_display_names[smoothing_method.lower()]}) vs FTIR EC by Ethiopian Season\\n({mask1.sum()} samples)\", fontsize=14)\n",
    "    \n",
    "    # Add 1:1 line\n",
    "    max_val1 = max(df['bc_ug'].max(), df['EC_FTIR'].max()) * 1.1\n",
    "    ax1.plot([0, max_val1], [0, max_val1], 'k--', alpha=0.3, linewidth=1, label='1:1 Line')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot 2: BC vs HIPS Fabs by season\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    # Separate scatter plots for each season\n",
    "    for season, color in season_colors.items():\n",
    "        season_data = df[df['season'] == season]\n",
    "        if len(season_data) > 0:\n",
    "            ax2.scatter(\n",
    "                season_data['bc_ug'], \n",
    "                season_data['Fabs'],\n",
    "                alpha=0.7, \n",
    "                s=80, \n",
    "                c=color, \n",
    "                edgecolor='black',\n",
    "                label=f\"{season} (n={len(season_data)})\"\n",
    "            )\n",
    "    \n",
    "    # Overall trendline\n",
    "    mask2 = ~np.isnan(df['bc_ug']) & ~np.isnan(df['Fabs'])\n",
    "    \n",
    "    if mask2.sum() > 1:\n",
    "        slope2, intercept2 = np.polyfit(df.loc[mask2, 'bc_ug'], df.loc[mask2, 'Fabs'], 1)\n",
    "        x_line2 = np.linspace(df['bc_ug'].min(), df['bc_ug'].max(), 100)\n",
    "        y_line2 = slope2 * x_line2 + intercept2\n",
    "        ax2.plot(x_line2, y_line2, 'r--', linewidth=2, label='All Seasons Fit')\n",
    "        \n",
    "        # Add regression equation and RÂ²\n",
    "        r_value2 = pearsonr(df.loc[mask2, 'bc_ug'], df.loc[mask2, 'Fabs'])[0]\n",
    "        r_squared2 = r_value2**2\n",
    "        \n",
    "        equation2 = f\"y = {slope2:.3f}x + {intercept2:.3f}\"\n",
    "        r2_text2 = f\"RÂ² = {r_squared2:.3f}\"\n",
    "        \n",
    "        ax2.annotate(\n",
    "            equation2 + '\\n' + r2_text2,\n",
    "            xy=(0.05, 0.95),\n",
    "            xycoords='axes fraction',\n",
    "            fontsize=12,\n",
    "            ha='left',\n",
    "            va='top',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8)\n",
    "        )\n",
    "    \n",
    "    # Format plot 2\n",
    "    ax2.set_xlabel(f'Aethalometer {wavelength} BC (Î¼g/mÂ³) - {method_display_names[smoothing_method.lower()]}', fontsize=12)\n",
    "    ax2.set_ylabel('HIPS Fabs', fontsize=12)\n",
    "    ax2.set_title(f\"{wavelength} BC ({method_display_names[smoothing_method.lower()]}) vs HIPS Fabs by Ethiopian Season\\n({mask2.sum()} samples)\", fontsize=14)\n",
    "    \n",
    "    # Make sure axes start at 0 if all data is positive\n",
    "    for ax, mask in [(ax1, mask1), (ax2, mask2)]:\n",
    "        if df.loc[mask, 'bc_ug'].min() >= 0:\n",
    "            ax.set_xlim(left=0)\n",
    "        if (ax == ax1 and df.loc[mask, 'EC_FTIR'].min() >= 0) or (ax == ax2 and df.loc[mask, 'Fabs'].min() >= 0):\n",
    "            ax.set_ylim(bottom=0)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create seasonal regression stats table\n",
    "    season_stats = []\n",
    "    for season in season_colors.keys():\n",
    "        season_data = df[df['season'] == season]\n",
    "        if len(season_data) > 1:  # Need at least 2 points for regression\n",
    "            # For BC vs EC_FTIR\n",
    "            mask_ec = ~np.isnan(season_data['bc_ug']) & ~np.isnan(season_data['EC_FTIR'])\n",
    "            \n",
    "            if mask_ec.sum() > 1:\n",
    "                slope_ec, intercept_ec = np.polyfit(\n",
    "                    season_data.loc[mask_ec, 'bc_ug'], \n",
    "                    season_data.loc[mask_ec, 'EC_FTIR'], \n",
    "                    1\n",
    "                )\n",
    "                r_value_ec = pearsonr(\n",
    "                    season_data.loc[mask_ec, 'bc_ug'], \n",
    "                    season_data.loc[mask_ec, 'EC_FTIR']\n",
    "                )[0]\n",
    "                r_squared_ec = r_value_ec**2\n",
    "                \n",
    "                # For BC vs HIPS Fabs\n",
    "                mask_fabs = ~np.isnan(season_data['bc_ug']) & ~np.isnan(season_data['Fabs'])\n",
    "                \n",
    "                if mask_fabs.sum() > 1:\n",
    "                    slope_fabs, intercept_fabs = np.polyfit(\n",
    "                        season_data.loc[mask_fabs, 'bc_ug'],\n",
    "                        season_data.loc[mask_fabs, 'Fabs'],\n",
    "                        1\n",
    "                    )\n",
    "                    r_value_fabs = pearsonr(\n",
    "                        season_data.loc[mask_fabs, 'bc_ug'],\n",
    "                        season_data.loc[mask_fabs, 'Fabs']\n",
    "                    )[0]\n",
    "                    r_squared_fabs = r_value_fabs**2\n",
    "                    \n",
    "                    # Add to stats table\n",
    "                    season_stats.append({\n",
    "                        'Season': season,\n",
    "                        'Count': len(season_data),\n",
    "                        'EC_FTIR_Slope': slope_ec,\n",
    "                        'EC_FTIR_Intercept': intercept_ec,\n",
    "                        'EC_FTIR_R2': r_squared_ec,\n",
    "                        'Fabs_Slope': slope_fabs,\n",
    "                        'Fabs_Intercept': intercept_fabs,\n",
    "                        'Fabs_R2': r_squared_fabs,\n",
    "                        'Method': method_display_names[smoothing_method.lower()]\n",
    "                    })\n",
    "    \n",
    "    # Create and return seasonal stats DataFrame\n",
    "    if season_stats:\n",
    "        season_stats_df = pd.DataFrame(season_stats)\n",
    "        print(f\"\\nSeasonal Regression Statistics ({method_display_names[smoothing_method.lower()]}):\")\n",
    "        print(season_stats_df.round(3))\n",
    "        return fig, season_stats_df\n",
    "    \n",
    "    return fig, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43c9f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mac_values_all_methods(overlap_df, wavelength=\"Red\"):\n",
    "    \"\"\"\n",
    "    Calculate Mass Absorption Cross-section (MAC) values for all smoothing methods.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    overlap_df : pandas.DataFrame\n",
    "        DataFrame with overlapping periods including all smoothing methods\n",
    "    wavelength : str\n",
    "        Wavelength used for BC data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    mac_df : pandas.DataFrame\n",
    "        DataFrame with MAC values for each method\n",
    "    fig : matplotlib.figure.Figure\n",
    "        Figure with MAC distributions\n",
    "    \"\"\"\n",
    "    # Method column mappings\n",
    "    method_columns = {\n",
    "        'Raw': 'aeth_mean',\n",
    "        'ONA': 'ona_mean',\n",
    "        'CMA': 'cma_mean',\n",
    "        'DEMA': 'dema_mean'\n",
    "    }\n",
    "    \n",
    "    # Create a copy of the data\n",
    "    mac_df = overlap_df.copy()\n",
    "    \n",
    "    # Add date and season information if not already present\n",
    "    if 'date' not in mac_df.columns and 'start_time' in mac_df.columns:\n",
    "        mac_df['date'] = mac_df['start_time'].dt.date\n",
    "    \n",
    "    if 'month' not in mac_df.columns and 'start_time' in mac_df.columns:\n",
    "        mac_df['month'] = mac_df['start_time'].dt.month\n",
    "    \n",
    "    if 'season' not in mac_df.columns and 'month' in mac_df.columns:\n",
    "        # Map Ethiopian seasons\n",
    "        def map_ethiopian_seasons(month):\n",
    "            \"\"\"Maps month number to Ethiopian season name.\"\"\"\n",
    "            if month in [10, 11, 12, 1, 2]:\n",
    "                return 'Dry Season'\n",
    "            elif month in [3, 4, 5]:\n",
    "                return 'Belg Rainy Season'\n",
    "            else:  # months 6â€“9\n",
    "                return 'Kiremt Rainy Season'\n",
    "        \n",
    "        mac_df['season'] = mac_df['month'].apply(map_ethiopian_seasons)\n",
    "    \n",
    "    # Calculate MAC values for each method\n",
    "    mac_results = {}\n",
    "    \n",
    "    for method_name, bc_col in method_columns.items():\n",
    "        if bc_col in mac_df.columns:\n",
    "            # Convert BC from ng/mÂ³ to Î¼g/mÂ³\n",
    "            mac_df[f'{method_name}_BC_ug'] = mac_df[bc_col] / 1000\n",
    "            \n",
    "            # Calculate MAC (mÂ²/g) = Fabs / EC_FTIR\n",
    "            mac_df[f'{method_name}_MAC'] = mac_df['Fabs'] / mac_df['EC_FTIR']\n",
    "            \n",
    "            # Filter out invalid MAC values\n",
    "            valid_mac = mac_df[(mac_df[f'{method_name}_MAC'] > 0) & (mac_df[f'{method_name}_MAC'] < 30)]\n",
    "            \n",
    "            if len(valid_mac) > 0:\n",
    "                # Calculate statistics\n",
    "                overall_mac = valid_mac[f'{method_name}_MAC'].mean()\n",
    "                seasonal_macs = valid_mac.groupby('season')[f'{method_name}_MAC'].agg(['mean', 'std', 'count'])\n",
    "                \n",
    "                # Store results\n",
    "                mac_results[method_name] = {\n",
    "                    'overall_mac': overall_mac,\n",
    "                    'seasonal_macs': seasonal_macs,\n",
    "                    'valid_count': len(valid_mac)\n",
    "                }\n",
    "    \n",
    "    # Print summary of MAC values\n",
    "    print(\"\\nMass Absorption Cross-section (MAC) Values Summary:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for method_name, results in mac_results.items():\n",
    "        print(f\"\\n{method_name} Processing:\")\n",
    "        print(f\"Overall MAC: {results['overall_mac']:.2f} mÂ²/g (n={results['valid_count']})\")\n",
    "        print(\"\\nSeasonal MAC Values:\")\n",
    "        print(results['seasonal_macs'].round(2))\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Plot MAC distributions for each method\n",
    "    for i, (method_name, results) in enumerate(mac_results.items()):\n",
    "        if i < len(axes):\n",
    "            ax = axes[i]\n",
    "            \n",
    "            # MAC histogram\n",
    "            valid_mac = mac_df[(mac_df[f'{method_name}_MAC'] > 0) & (mac_df[f'{method_name}_MAC'] < 30)]\n",
    "            ax.hist(valid_mac[f'{method_name}_MAC'], bins=15, alpha=0.7, color='crimson', edgecolor='black')\n",
    "            ax.axvline(results['overall_mac'], color='black', linestyle='--', linewidth=2, \n",
    "                      label=f'Mean MAC: {results[\"overall_mac\"]:.2f} mÂ²/g')\n",
    "            \n",
    "            ax.set_xlabel('MAC (mÂ²/g)', fontsize=12)\n",
    "            ax.set_ylabel('Frequency', fontsize=12)\n",
    "            ax.set_title(f'{method_name} Processing - MAC Distribution\\n(n={results[\"valid_count\"]})', fontsize=14)\n",
    "            ax.legend()\n",
    "            ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Hide empty subplots if fewer than 4 methods\n",
    "    for i in range(len(mac_results), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create a comparison table of MAC values\n",
    "    mac_comparison = pd.DataFrame({\n",
    "        'Method': [],\n",
    "        'Overall MAC': [],\n",
    "        'Sample Count': []\n",
    "    })\n",
    "    \n",
    "    for method_name, results in mac_results.items():\n",
    "        mac_comparison = pd.concat([mac_comparison, pd.DataFrame({\n",
    "            'Method': [method_name],\n",
    "            'Overall MAC': [results['overall_mac']],\n",
    "            'Sample Count': [results['valid_count']]\n",
    "        })], ignore_index=True)\n",
    "    \n",
    "    # Add seasonal MAC values to the comparison\n",
    "    for season in ['Dry Season', 'Belg Rainy Season', 'Kiremt Rainy Season']:\n",
    "        mac_comparison[f'{season} MAC'] = np.nan\n",
    "        \n",
    "        for i, (method_name, results) in enumerate(mac_results.items()):\n",
    "            seasonal_data = results['seasonal_macs']\n",
    "            if season in seasonal_data.index:\n",
    "                mac_comparison.loc[i, f'{season} MAC'] = seasonal_data.loc[season, 'mean']\n",
    "    \n",
    "    print(\"\\nMAC Comparison Across Methods:\")\n",
    "    print(mac_comparison.round(2))\n",
    "    \n",
    "    return mac_df, fig, mac_comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f6ae84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sample_excellent_period(aethalometer_df, excellent_periods, duration_hours=6):\n",
    "    \"\"\"\n",
    "    Find a sample excellent period for visualization.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    aethalometer_df : pandas.DataFrame\n",
    "        DataFrame with aethalometer data\n",
    "    excellent_periods : pandas.DataFrame\n",
    "        DataFrame with excellent periods\n",
    "    duration_hours : int\n",
    "        Duration of the sample period in hours\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    start, end : datetime\n",
    "        Start and end times of the sample period\n",
    "    \"\"\"\n",
    "    # Get a random excellent period\n",
    "    if len(excellent_periods) == 0:\n",
    "        print(\"No excellent periods available\")\n",
    "        return None, None\n",
    "    \n",
    "    # Try to find a period with interesting data\n",
    "    for _, row in excellent_periods.iterrows():\n",
    "        period_start = row['start_time']\n",
    "        period_end = period_start + pd.Timedelta(hours=duration_hours)\n",
    "        \n",
    "        # Check if this period has data\n",
    "        if period_end <= row['end_time']:\n",
    "            # Check if there's enough data in this period\n",
    "            data_slice = aethalometer_df.loc[period_start:period_end]\n",
    "            if len(data_slice) >= duration_hours * 30:  # At least 30 points per hour\n",
    "                return period_start, period_end\n",
    "    \n",
    "    # If no good period found, just use the first period\n",
    "    first_period = excellent_periods.iloc[0]\n",
    "    period_start = first_period['start_time']\n",
    "    period_end = period_start + pd.Timedelta(hours=duration_hours)\n",
    "    \n",
    "    return period_start, period_end# %%\n",
    "def plot_minute_level_comparison(smoothed_data, wavelength=\"Red\", sample_period=None):\n",
    "    \"\"\"\n",
    "    Create a visualization showing the differences between smoothing methods at the 1-minute level.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    smoothed_data : dict\n",
    "        Dictionary with keys 'raw', 'ona', 'cma', 'dema' containing the processed dataframes\n",
    "    wavelength : str\n",
    "        Wavelength to visualize\n",
    "    sample_period : tuple or None\n",
    "        Optional (start, end) tuple to restrict the visualization to a specific period\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        The figure object\n",
    "    \"\"\"\n",
    "    # Extract column names\n",
    "    raw_col = f\"{wavelength} BCc\"\n",
    "    ona_col = f\"{wavelength}_BC_ONA\"\n",
    "    cma_col = f\"{wavelength}_BC_CMA\"\n",
    "    dema_col = f\"{wavelength}_BC_DEMA\"\n",
    "    \n",
    "    # Prepare the data\n",
    "    raw_df = smoothed_data['raw'] \n",
    "    ona_df = smoothed_data['ona']\n",
    "    cma_df = smoothed_data['cma']\n",
    "    dema_df = smoothed_data['dema']\n",
    "    \n",
    "    # Verify columns exist\n",
    "    available_cols = []\n",
    "    if raw_col in raw_df.columns:\n",
    "        available_cols.append(('Raw', raw_df, raw_col, 'k-'))\n",
    "    if ona_col in ona_df.columns:\n",
    "        available_cols.append(('ONA', ona_df, ona_col, 'b-'))\n",
    "    if cma_col in cma_df.columns:\n",
    "        available_cols.append(('CMA', cma_df, cma_col, 'r-'))\n",
    "    if dema_col in dema_df.columns:\n",
    "        available_cols.append(('DEMA', dema_df, dema_col, 'g-'))\n",
    "    \n",
    "    if not available_cols:\n",
    "        print(\"No smoothed data columns available for plotting\")\n",
    "        return None\n",
    "        \n",
    "    # If sample_period is not provided, use a default period\n",
    "    if sample_period is None:\n",
    "        # Find a 6-hour period with good data\n",
    "        start = raw_df.index[0]\n",
    "        end = start + pd.Timedelta(hours=6)\n",
    "        \n",
    "        # Make sure the period contains data for all methods\n",
    "        for _, df, col, _ in available_cols:\n",
    "            if df.loc[start:end, col].isna().all():\n",
    "                # Try a different period if this one has no data\n",
    "                offset = pd.Timedelta(days=1)\n",
    "                start += offset\n",
    "                end += offset\n",
    "                \n",
    "                # Only try a limited number of periods\n",
    "                if start > raw_df.index[-1] - pd.Timedelta(hours=6):\n",
    "                    print(\"Could not find a good sample period with data for all methods\")\n",
    "                    return None\n",
    "    else:\n",
    "        start, end = sample_period\n",
    "    \n",
    "    # Create figure with 3 subplots (original BC, zoomed BC, differences)\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 15), sharex=True)\n",
    "    \n",
    "    # Plot 1: Original data\n",
    "    for name, df, col, style in available_cols:\n",
    "        # Get the data for this period\n",
    "        period_data = df.loc[start:end, col]\n",
    "        axes[0].plot(period_data.index, period_data, style, label=name)\n",
    "    \n",
    "    axes[0].set_title(f\"{wavelength} BC - Comparison of Smoothing Methods (Raw Scale)\", fontsize=14)\n",
    "    axes[0].set_ylabel(\"BC Concentration (ng/mÂ³)\", fontsize=12)\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Zoomed to better see the differences\n",
    "    for name, df, col, style in available_cols:\n",
    "        period_data = df.loc[start:end, col]\n",
    "        axes[1].plot(period_data.index, period_data, style, label=name)\n",
    "    \n",
    "    # Set the y-limits to exclude extreme values\n",
    "    y_values = []\n",
    "    for _, df, col, _ in available_cols:\n",
    "        period_data = df.loc[start:end, col]\n",
    "        y_values.extend(period_data.dropna().tolist())\n",
    "    \n",
    "    if y_values:\n",
    "        # Use percentiles to set limits and focus on the central part\n",
    "        lower = np.percentile(y_values, 5)\n",
    "        upper = np.percentile(y_values, 95)\n",
    "        axes[1].set_ylim(lower, upper)\n",
    "    \n",
    "    axes[1].set_title(f\"{wavelength} BC - Comparison of Smoothing Methods (Zoomed)\", fontsize=14)\n",
    "    axes[1].set_ylabel(\"BC Concentration (ng/mÂ³)\", fontsize=12)\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Differences from Raw data\n",
    "    if 'Raw' in [name for name, _, _, _ in available_cols]:\n",
    "        raw_name, raw_df, raw_col, _ = [(name, df, col, _) for name, df, col, _ in available_cols if name == 'Raw'][0]\n",
    "        raw_data = raw_df.loc[start:end, raw_col]\n",
    "        \n",
    "        for name, df, col, style in [x for x in available_cols if x[0] != 'Raw']:\n",
    "            period_data = df.loc[start:end, col]\n",
    "            # Calculate difference as percentage\n",
    "            diff_pct = (period_data - raw_data) / raw_data * 100\n",
    "            # Use the line color but with dots\n",
    "            color = style[0]\n",
    "            axes[2].plot(diff_pct.index, diff_pct, color + '.', alpha=0.5, label=f\"{name} vs Raw\")\n",
    "            \n",
    "            # Add moving average for clearer trend\n",
    "            diff_pct_smooth = diff_pct.rolling(window=10, center=True).mean()\n",
    "            axes[2].plot(diff_pct_smooth.index, diff_pct_smooth, color + '-', label=f\"{name} vs Raw (10-min avg)\")\n",
    "    \n",
    "    axes[2].set_title(f\"Percentage Difference from Raw Data\", fontsize=14)\n",
    "    axes[2].set_ylabel(\"Difference (%)\", fontsize=12)\n",
    "    axes[2].set_xlabel(\"Time\", fontsize=12)\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add overall title\n",
    "    period_str = f\"{start.strftime('%Y-%m-%d %H:%M')} to {end.strftime('%Y-%m-%d %H:%M')}\"\n",
    "    plt.suptitle(f\"Minute-Level Comparison of {wavelength} BC Smoothing Methods\\n{period_str}\", fontsize=16)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e0f4ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_minute_level_comparison(smoothed_data, wavelength=\"Red\", sample_period=None):\n",
    "    \"\"\"\n",
    "    Create a visualization showing the differences between smoothing methods at the 1-minute level.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    smoothed_data : dict\n",
    "        Dictionary with keys 'raw', 'ona', 'cma', 'dema' containing the processed dataframes\n",
    "    wavelength : str\n",
    "        Wavelength to visualize\n",
    "    sample_period : tuple or None\n",
    "        Optional (start, end) tuple to restrict the visualization to a specific period\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        The figure object\n",
    "    \"\"\"\n",
    "    # Extract column names\n",
    "    raw_col = f\"{wavelength} BCc\"\n",
    "    ona_col = f\"{wavelength}_BC_ONA\"\n",
    "    cma_col = f\"{wavelength}_BC_CMA\"\n",
    "    dema_col = f\"{wavelength}_BC_DEMA\"\n",
    "    \n",
    "    # Prepare the data\n",
    "    raw_df = smoothed_data['raw'] \n",
    "    ona_df = smoothed_data['ona']\n",
    "    cma_df = smoothed_data['cma']\n",
    "    dema_df = smoothed_data['dema']\n",
    "    \n",
    "    # Verify columns exist\n",
    "    available_cols = []\n",
    "    if raw_col in raw_df.columns:\n",
    "        available_cols.append(('Raw', raw_df, raw_col, 'k-'))\n",
    "    if ona_col in ona_df.columns:\n",
    "        available_cols.append(('ONA', ona_df, ona_col, 'b-'))\n",
    "    if cma_col in cma_df.columns:\n",
    "        available_cols.append(('CMA', cma_df, cma_col, 'r-'))\n",
    "    if dema_col in dema_df.columns:\n",
    "        available_cols.append(('DEMA', dema_df, dema_col, 'g-'))\n",
    "    \n",
    "    if not available_cols:\n",
    "        print(\"No smoothed data columns available for plotting\")\n",
    "        return None\n",
    "        \n",
    "    # If sample_period is not provided, use a default period\n",
    "    if sample_period is None:\n",
    "        # Find a 6-hour period with good data\n",
    "        start = raw_df.index[0]\n",
    "        end = start + pd.Timedelta(hours=6)\n",
    "        \n",
    "        # Make sure the period contains data for all methods\n",
    "        for _, df, col, _ in available_cols:\n",
    "            if df.loc[start:end, col].isna().all():\n",
    "                # Try a different period if this one has no data\n",
    "                offset = pd.Timedelta(days=1)\n",
    "                start += offset\n",
    "                end += offset\n",
    "                \n",
    "                # Only try a limited number of periods\n",
    "                if start > raw_df.index[-1] - pd.Timedelta(hours=6):\n",
    "                    print(\"Could not find a good sample period with data for all methods\")\n",
    "                    return None\n",
    "    else:\n",
    "        start, end = sample_period\n",
    "    \n",
    "    # Create figure with 3 subplots (original BC, zoomed BC, differences)\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 15), sharex=True)\n",
    "    \n",
    "    # Plot 1: Original data\n",
    "    for name, df, col, style in available_cols:\n",
    "        # Get the data for this period\n",
    "        period_data = df.loc[start:end, col]\n",
    "        axes[0].plot(period_data.index, period_data, style, label=name)\n",
    "    \n",
    "    axes[0].set_title(f\"{wavelength} BC - Comparison of Smoothing Methods (Raw Scale)\", fontsize=14)\n",
    "    axes[0].set_ylabel(\"BC Concentration (ng/mÂ³)\", fontsize=12)\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Zoomed to better see the differences\n",
    "    for name, df, col, style in available_cols:\n",
    "        period_data = df.loc[start:end, col]\n",
    "        axes[1].plot(period_data.index, period_data, style, label=name)\n",
    "    \n",
    "    # Set the y-limits to exclude extreme values\n",
    "    y_values = []\n",
    "    for _, df, col, _ in available_cols:\n",
    "        period_data = df.loc[start:end, col]\n",
    "        y_values.extend(period_data.dropna().tolist())\n",
    "    \n",
    "    if y_values:\n",
    "        # Use percentiles to set limits and focus on the central part\n",
    "        lower = np.percentile(y_values, 5)\n",
    "        upper = np.percentile(y_values, 95)\n",
    "        axes[1].set_ylim(lower, upper)\n",
    "    \n",
    "    axes[1].set_title(f\"{wavelength} BC - Comparison of Smoothing Methods (Zoomed)\", fontsize=14)\n",
    "    axes[1].set_ylabel(\"BC Concentration (ng/mÂ³)\", fontsize=12)\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Differences from Raw data\n",
    "    if 'Raw' in [name for name, _, _, _ in available_cols]:\n",
    "        raw_name, raw_df, raw_col, _ = [(name, df, col, _) for name, df, col, _ in available_cols if name == 'Raw'][0]\n",
    "        raw_data = raw_df.loc[start:end, raw_col]\n",
    "        \n",
    "        for name, df, col, style in [x for x in available_cols if x[0] != 'Raw']:\n",
    "            period_data = df.loc[start:end, col]\n",
    "            # Calculate difference as percentage\n",
    "            diff_pct = (period_data - raw_data) / raw_data * 100\n",
    "            # Use the line color but with dots\n",
    "            color = style[0]\n",
    "            axes[2].plot(diff_pct.index, diff_pct, color + '.', alpha=0.5, label=f\"{name} vs Raw\")\n",
    "            \n",
    "            # Add moving average for clearer trend\n",
    "            diff_pct_smooth = diff_pct.rolling(window=10, center=True).mean()\n",
    "            axes[2].plot(diff_pct_smooth.index, diff_pct_smooth, color + '-', label=f\"{name} vs Raw (10-min avg)\")\n",
    "    \n",
    "    axes[2].set_title(f\"Percentage Difference from Raw Data\", fontsize=14)\n",
    "    axes[2].set_ylabel(\"Difference (%)\", fontsize=12)\n",
    "    axes[2].set_xlabel(\"Time\", fontsize=12)\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add overall title\n",
    "    period_str = f\"{start.strftime('%Y-%m-%d %H:%M')} to {end.strftime('%Y-%m-%d %H:%M')}\"\n",
    "    plt.suptitle(f\"Minute-Level Comparison of {wavelength} BC Smoothing Methods\\n{period_str}\", fontsize=16)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8b37b8",
   "metadata": {},
   "source": [
    "## Step 7: Main Execution Function\n",
    " \n",
    "This function brings together all the components to perform the complete analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function to perform the black carbon cross-method analysis\n",
    "    with multiple smoothing techniques.\n",
    "    \"\"\"\n",
    "    print(\"Black Carbon Cross-Method Analysis with Smoothing Techniques\")\n",
    "    print(\"==========================================================\")\n",
    "    print(\"This script analyzes excellent quality data from:\")\n",
    "    print(\"1. Aethalometer (Red BCc) - with Raw, ONA, CMA, and DEMA processing\")\n",
    "    print(\"2. FTIR (Elemental Carbon)\")\n",
    "    print(\"3. HIPS (Filter light absorption)\")\n",
    "    print(\"==========================================================\\n\")\n",
    "    \n",
    "    # Define file paths - adjust these to your actual file paths\n",
    "    aethalometer_path = \"/Users/ahzs645/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data/Aethelometry Data/Jacros_MA350_1-min_2022-2024_Cleaned.csv\"\n",
    "    db_path = \"/Users/ahzs645/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data/EC-HIPS-Aeth Comparison/Data/Original Data/Combined Database/spartan_ftir_hips.db\"\n",
    "    \n",
    "    # Load Aethalometer data\n",
    "    print(\"\\n--- Loading Aethalometer Data ---\")\n",
    "    aethalometer_df = load_aethalometer_data(aethalometer_path)\n",
    "    \n",
    "    if aethalometer_df is None:\n",
    "        print(\"ERROR: Failed to load Aethalometer data. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Load filter sample data\n",
    "    print(\"\\n--- Loading Filter Sample Data ---\")\n",
    "    etad_data, ftir_data = load_filter_sample_data(db_path)\n",
    "    \n",
    "    if len(etad_data) == 0:\n",
    "        print(\"ERROR: No filter sample data available. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Identify excellent periods directly (no quality_df parameter)\n",
    "    print(\"\\n--- Identifying Excellent Quality Periods ---\")\n",
    "    excellent_periods = identify_excellent_periods(aethalometer_df)\n",
    "    \n",
    "    if excellent_periods is None or len(excellent_periods) == 0:\n",
    "        print(\"ERROR: No excellent quality periods identified. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Find overlapping periods with filter samples BEFORE applying smoothing\n",
    "    print(\"\\n--- Finding Overlapping Periods ---\")\n",
    "    overlap_df_raw = find_overlapping_excellent_data(aethalometer_df, etad_data, excellent_periods)\n",
    "    \n",
    "    if overlap_df_raw is None or len(overlap_df_raw) == 0:\n",
    "        print(\"ERROR: No overlapping periods found. Exiting.\")\n",
    "        return\n",
    "        \n",
    "    # *** NEW CODE BLOCK - Extract just the Aethalometer data for those specific days ***\n",
    "    print(\"\\n--- Extracting Data for Overlapping Days ---\")\n",
    "    filtered_aeth_data = pd.DataFrame()\n",
    "    for i, row in overlap_df_raw.iterrows():\n",
    "        day_data = aethalometer_df.loc[row['start_time']:row['end_time']]\n",
    "        filtered_aeth_data = pd.concat([filtered_aeth_data, day_data])\n",
    "    \n",
    "    print(f\"Extracted {len(filtered_aeth_data)} data points across {len(overlap_df_raw)} excellent days\")\n",
    "    \n",
    "    # Now apply smoothing only to the filtered data\n",
    "    print(\"\\n--- Applying Smoothing Methods to Filtered Data ---\")\n",
    "    smoothed_data = apply_all_smoothing_methods(filtered_aeth_data, wavelength=\"Red\")\n",
    "    # *** END NEW CODE BLOCK ***\n",
    "    \n",
    "    # Visualize smoothing at the 1-minute level\n",
    "    print(\"\\n--- Creating Minute-Level Visualization ---\")\n",
    "    sample_start, sample_end = find_sample_excellent_period(filtered_aeth_data, overlap_df_raw, duration_hours=6)\n",
    "    if sample_start is not None and sample_end is not None:\n",
    "        fig_minute = plot_minute_level_comparison(smoothed_data, wavelength=\"Red\", sample_period=(sample_start, sample_end))\n",
    "        if fig_minute:\n",
    "            plt.savefig(\"minute_level_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "            plt.close(fig_minute)\n",
    "    \n",
    "    # Add smoothed data to the overlap DataFrame\n",
    "    print(\"\\n--- Adding Smoothed Data to Overlap DataFrame ---\")\n",
    "    overlap_df_all = create_overlap_df_with_all_methods(overlap_df_raw, smoothed_data, wavelength=\"Red\")\n",
    "    \n",
    "\n",
    "    \n",
    "    # Verify the method differences \n",
    "    print(\"\\nVerifying differences between smoothing methods:\")\n",
    "    \n",
    "    # Check if the mean BC values differ between methods\n",
    "    methods = ['aeth_mean', 'ona_mean', 'cma_mean', 'dema_mean']\n",
    "    means = {}\n",
    "    for method in methods:\n",
    "        if method in overlap_df_all.columns:\n",
    "            means[method] = overlap_df_all[method].mean()\n",
    "    \n",
    "    # Calculate percentage differences\n",
    "    if len(means) > 1:\n",
    "        print(\"\\nMethod average BC values:\")\n",
    "        for method, mean_val in means.items():\n",
    "            print(f\"{method}: {mean_val:.2f} ng/mÂ³\")\n",
    "        \n",
    "        print(\"\\nPercentage differences from raw data:\")\n",
    "        raw_mean = means.get('aeth_mean', 0)\n",
    "        for method, mean_val in means.items():\n",
    "            if method != 'aeth_mean' and raw_mean != 0:\n",
    "                pct_diff = (mean_val - raw_mean) / raw_mean * 100\n",
    "                print(f\"{method}: {pct_diff:.2f}%\")\n",
    "    \n",
    "    # Calculate correlations between methods\n",
    "    if all(method in overlap_df_all.columns for method in methods):\n",
    "        corr_matrix = overlap_df_all[methods].corr()\n",
    "        print(\"\\nCorrelation matrix between methods:\")\n",
    "        print(corr_matrix.round(3))\n",
    "    \n",
    "    # Create visualization plots\n",
    "    print(\"\\n--- Creating Cross-Method Plots with All Smoothing Methods ---\")\n",
    "    print(f\"Using {len(overlap_df_all)} days with excellent data from all methods\")\n",
    "    \n",
    "    # Compare all methods with FTIR EC\n",
    "    fig_ftir, reg_results_ftir = plot_bc_scatter_all_methods(\n",
    "        overlap_df_all, y_param='EC_FTIR', wavelength=\"Red\"\n",
    "    )\n",
    "    plt.savefig(\"comparison_all_methods_with_ftir.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig_ftir)\n",
    "    \n",
    "    # Compare all methods with HIPS Fabs\n",
    "    fig_hips, reg_results_hips = plot_bc_scatter_all_methods(\n",
    "        overlap_df_all, y_param='Fabs', wavelength=\"Red\"\n",
    "    )\n",
    "    plt.savefig(\"comparison_all_methods_with_hips.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig_hips)\n",
    "    \n",
    "    # Visualize the MAC values for each method\n",
    "    print(\"\\n--- Calculating MAC Values For Each Method ---\")\n",
    "    # MAC = Fabs / EC_FTIR for each method's BC\n",
    "    for method in ['Raw', 'ONA', 'CMA', 'DEMA']:\n",
    "        method_col = 'aeth_mean' if method == 'Raw' else f'{method.lower()}_mean'\n",
    "        if method_col in overlap_df_all.columns:\n",
    "            # MAC doesn't use BC directly, it's a ratio of filter measurements\n",
    "            # But we'll label each MAC value by which BC method it's compared with\n",
    "            overlap_df_all[f'{method}_MAC'] = overlap_df_all['Fabs'] / overlap_df_all['EC_FTIR']\n",
    "    \n",
    "    # Plot MAC distributions\n",
    "    mac_cols = [col for col in overlap_df_all.columns if col.endswith('_MAC')]\n",
    "    if mac_cols:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Plot MAC histograms for each method\n",
    "        # Note: All MAC values are identical since MAC = Fabs/EC_FTIR which doesn't depend on BC\n",
    "        # But we plot them by method for comparison\n",
    "        for col in mac_cols:\n",
    "            method = col.replace('_MAC', '')\n",
    "            plt.hist(overlap_df_all[col].dropna(), alpha=0.5, label=f'{method} MAC')\n",
    "        \n",
    "        plt.xlabel('MAC (mÂ²/g)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('MAC Value Distribution by Method\\nNote: MAC values are identical across methods')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(\"mac_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # Save the processed data and results\n",
    "    print(\"\\n--- Saving Results ---\")\n",
    "    overlap_df_all.to_csv(\"overlap_data_with_all_smoothing_methods.csv\", index=True)\n",
    "    \n",
    "    # Create a summary of regression results\n",
    "    regression_summary = {\n",
    "        'FTIR_EC': reg_results_ftir,\n",
    "        'HIPS_Fabs': reg_results_hips\n",
    "    }\n",
    "    \n",
    "    print(\"\\n--- Analysis Complete ---\")\n",
    "    print(f\"Successfully analyzed {len(overlap_df_all)} overlapping excellent quality days with multiple smoothing methods\")\n",
    "    \n",
    "    # Return results for further analysis if needed\n",
    "    return {\n",
    "        'aethalometer_df': aethalometer_df,\n",
    "        'smoothed_data': smoothed_data,\n",
    "        'filter_df': etad_data,\n",
    "        'excellent_periods': excellent_periods,\n",
    "        'overlap_df_all': overlap_df_all,\n",
    "        'regression_summary': regression_summary\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bad8252",
   "metadata": {},
   "source": [
    "## Run the Analysis\n",
    " \n",
    "Execute the main function to perform the complete black carbon cross-method analysis with multiple smoothing methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7caddccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Carbon Cross-Method Analysis with Smoothing Techniques\n",
      "==========================================================\n",
      "This script analyzes excellent quality data from:\n",
      "1. Aethalometer (Red BCc) - with Raw, ONA, CMA, and DEMA processing\n",
      "2. FTIR (Elemental Carbon)\n",
      "3. HIPS (Filter light absorption)\n",
      "==========================================================\n",
      "\n",
      "\n",
      "--- Loading Aethalometer Data ---\n",
      "Loading Aethalometer data from: /Users/ahzs645/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data/Aethelometry Data/Jacros_MA350_1-min_2022-2024_Cleaned.csv\n",
      "Using Polars for data loading (faster)\n",
      "Successfully parsed dates with format: %Y-%m-%d %I:%M:%S %p\n",
      "Loaded 1,095,086 Aethalometer records spanning 2022-04-12 09:46:00 to 2024-08-20 09:01:00\n",
      "Red BCc data available: count    1094754.00\n",
      "mean        8084.10\n",
      "std         9291.06\n",
      "min      -182273.00\n",
      "25%         2928.00\n",
      "50%         5382.00\n",
      "75%         9733.00\n",
      "max       583168.00\n",
      "Name: Red BCc, dtype: float64\n",
      "\n",
      "--- Loading Filter Sample Data ---\n",
      "Loading ETAD (HIPS) and FTIR filter sample data from: /Users/ahzs645/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data/EC-HIPS-Aeth Comparison/Data/Original Data/Combined Database/spartan_ftir_hips.db\n",
      "Loaded 168 ETAD samples from database (162 with valid dates)\n",
      "  - All samples have both HIPS and FTIR measurements\n",
      "\n",
      "--- Identifying Excellent Quality Periods ---\n",
      "Computing excellent periods from scratch\n",
      "Computed 608 excellent periods from scratch\n",
      "\n",
      "--- Finding Overlapping Periods ---\n",
      "\n",
      "Finding overlapping excellent periods with filter samples...\n",
      "Filter DataFrame columns: ['filter_id', 'SampleDate', 'EC_FTIR', 'OC_FTIR', 'Fabs', 'Site']\n",
      "Excellent periods columns: ['start_time', 'end_time', 'aethalometer_quality']\n",
      "Filter dates range: 2022-12-07 00:00:00 to 2024-05-12 00:00:00\n",
      "Total filter dates: 162\n",
      "Sample filter dates (first 5):\n",
      "  - 2022-12-07 00:00:00\n",
      "  - 2022-12-10 00:00:00\n",
      "  - 2022-12-13 00:00:00\n",
      "  - 2022-12-16 00:00:00\n",
      "  - 2022-12-19 00:00:00\n",
      "Excellent periods range: 2022-04-13 09:00:00 to 2024-08-20 09:00:00\n",
      "Total excellent periods: 608\n",
      "Sample excellent period start times (first 5):\n",
      "  - 2022-04-13 09:00:00\n",
      "  - 2022-04-16 09:00:00\n",
      "  - 2022-04-17 09:00:00\n",
      "  - 2022-04-18 09:00:00\n",
      "  - 2022-04-19 09:00:00\n",
      "Found 113 overlapping excellent periods with filter samples\n",
      "Sample overlap periods (first 5):\n",
      "  - 2022-12-10 09:00:00\n",
      "  - 2022-12-13 09:00:00\n",
      "  - 2022-12-16 09:00:00\n",
      "  - 2022-12-19 09:00:00\n",
      "  - 2022-12-22 09:00:00\n",
      "Adding filter data to overlap DataFrame...\n",
      "Matched 0 out of 113 overlap periods with filter data\n",
      "WARNING: No filter data was added to the overlap DataFrame\n",
      "This could be due to a mismatch in dates or missing columns\n",
      "\n",
      "Attempting alternative date matching approach...\n",
      "Alternative approach found 109 matches\n",
      "Successfully created alternate overlap DataFrame with 109 rows\n",
      "Columns: ['start_time', 'end_time', 'filter_id', 'EC_FTIR', 'Fabs', 'aeth_count', 'aeth_mean', 'aeth_median', 'aeth_min', 'aeth_max', 'aeth_std', 'aeth_25th', 'aeth_75th', 'aeth_negative_count', 'aeth_negative_percent']\n",
      "\n",
      "--- Extracting Data for Overlapping Days ---\n",
      "Extracted 154234 data points across 109 excellent days\n",
      "\n",
      "--- Applying Smoothing Methods to Filtered Data ---\n",
      "\n",
      "Applying smoothing methods to Red wavelength data...\n",
      "\n",
      "Applying ONA to Red wavelength data...\n",
      "Number of actual filter changes (Î”ATN > 30) detected for Red: 133\n",
      "\n",
      "Applying CMA to Red wavelength data...\n",
      "Using window size of 3 for CMA on Red\n",
      "\n",
      "Applying DEMA to Red wavelength data...\n",
      "Using alpha of 0.1250 for DEMA on Red\n",
      "\n",
      "--- Creating Minute-Level Visualization ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Timestamp('2022-04-13 09:00:00')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:609\u001b[39m, in \u001b[36mpandas._libs.index.DatetimeEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 1649840400000000000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:577\u001b[39m, in \u001b[36mpandas._libs.index.DatetimeEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:611\u001b[39m, in \u001b[36mpandas._libs.index.DatetimeEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: Timestamp('2022-04-13 09:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/datetimes.py:630\u001b[39m, in \u001b[36mDatetimeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: Timestamp('2022-04-13 09:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     results = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# *** END NEW CODE BLOCK ***\u001b[39;00m\n\u001b[32m     63\u001b[39m \n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Visualize smoothing at the 1-minute level\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Creating Minute-Level Visualization ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m sample_start, sample_end = \u001b[43mfind_sample_excellent_period\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_aeth_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexcellent_periods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration_hours\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m sample_end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     68\u001b[39m     fig_minute = plot_minute_level_comparison(smoothed_data, wavelength=\u001b[33m\"\u001b[39m\u001b[33mRed\u001b[39m\u001b[33m\"\u001b[39m, sample_period=(sample_start, sample_end))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mfind_sample_excellent_period\u001b[39m\u001b[34m(aethalometer_df, excellent_periods, duration_hours)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Check if this period has data\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m period_end <= row[\u001b[33m'\u001b[39m\u001b[33mend_time\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Check if there's enough data in this period\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     data_slice = \u001b[43maethalometer_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mperiod_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mperiod_end\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_slice) >= duration_hours * \u001b[32m30\u001b[39m:  \u001b[38;5;66;03m# At least 30 points per hour\u001b[39;00m\n\u001b[32m     34\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m period_start, period_end\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/indexing.py:1411\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1409\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   1410\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_key(key, axis)\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_slice_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m com.is_bool_indexer(key):\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getbool_axis(key, axis=axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/indexing.py:1443\u001b[39m, in \u001b[36m_LocIndexer._get_slice_axis\u001b[39m\u001b[34m(self, slice_obj, axis)\u001b[39m\n\u001b[32m   1440\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1442\u001b[39m labels = obj._get_axis(axis)\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m indexer = \u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mslice_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1445\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   1446\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._slice(indexer, axis=axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/datetimes.py:682\u001b[39m, in \u001b[36mDatetimeIndex.slice_indexer\u001b[39m\u001b[34m(self, start, end, step)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# GH#33146 if start and end are combinations of str and None and Index is not\u001b[39;00m\n\u001b[32m    675\u001b[39m \u001b[38;5;66;03m# monotonic, we can not use Index.slice_indexer because it does not honor the\u001b[39;00m\n\u001b[32m    676\u001b[39m \u001b[38;5;66;03m# actual elements, is only searching for start and end\u001b[39;00m\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    678\u001b[39m     check_str_or_none(start)\n\u001b[32m    679\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m check_str_or_none(end)\n\u001b[32m    680\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_monotonic_increasing\n\u001b[32m    681\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m682\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mslice_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    684\u001b[39m mask = np.array(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    685\u001b[39m in_index = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6662\u001b[39m, in \u001b[36mIndex.slice_indexer\u001b[39m\u001b[34m(self, start, end, step)\u001b[39m\n\u001b[32m   6618\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mslice_indexer\u001b[39m(\n\u001b[32m   6619\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   6620\u001b[39m     start: Hashable | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   6621\u001b[39m     end: Hashable | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   6622\u001b[39m     step: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   6623\u001b[39m ) -> \u001b[38;5;28mslice\u001b[39m:\n\u001b[32m   6624\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   6625\u001b[39m \u001b[33;03m    Compute the slice indexer for input labels and step.\u001b[39;00m\n\u001b[32m   6626\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   6660\u001b[39m \u001b[33;03m    slice(1, 3, None)\u001b[39;00m\n\u001b[32m   6661\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6662\u001b[39m     start_slice, end_slice = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mslice_locs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6664\u001b[39m     \u001b[38;5;66;03m# return a slice\u001b[39;00m\n\u001b[32m   6665\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(start_slice):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6879\u001b[39m, in \u001b[36mIndex.slice_locs\u001b[39m\u001b[34m(self, start, end, step)\u001b[39m\n\u001b[32m   6877\u001b[39m start_slice = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   6878\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m6879\u001b[39m     start_slice = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_slice_bound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mleft\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   6880\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m start_slice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   6881\u001b[39m     start_slice = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6804\u001b[39m, in \u001b[36mIndex.get_slice_bound\u001b[39m\u001b[34m(self, label, side)\u001b[39m\n\u001b[32m   6801\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._searchsorted_monotonic(label, side)\n\u001b[32m   6802\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[32m   6803\u001b[39m         \u001b[38;5;66;03m# raise the original KeyError\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6804\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m   6806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(slc, np.ndarray):\n\u001b[32m   6807\u001b[39m     \u001b[38;5;66;03m# get_loc may return a boolean array, which\u001b[39;00m\n\u001b[32m   6808\u001b[39m     \u001b[38;5;66;03m# is OK as long as they are representable by a slice.\u001b[39;00m\n\u001b[32m   6809\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m is_bool_dtype(slc.dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6798\u001b[39m, in \u001b[36mIndex.get_slice_bound\u001b[39m\u001b[34m(self, label, side)\u001b[39m\n\u001b[32m   6796\u001b[39m \u001b[38;5;66;03m# we need to look up the label\u001b[39;00m\n\u001b[32m   6797\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m6798\u001b[39m     slc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6799\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   6800\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/datetimes.py:632\u001b[39m, in \u001b[36mDatetimeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    630\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Index.get_loc(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(orig_key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: Timestamp('2022-04-13 09:00:00')"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c23100a",
   "metadata": {},
   "source": [
    "## Explore Results\n",
    " \n",
    "After running the analysis, you can explore the results further. Here are some examples of additional analyses:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed608e12",
   "metadata": {},
   "source": [
    "Explore the regression results in detail\n",
    "Uncomment and run after executing the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc8d6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reduced Ordinary Least Squares (OLS) Equations:\n",
      "======================================================================\n",
      "\n",
      "FTIR EC vs BC:\n",
      "Raw: EC = 0.379 Ã— BC + 1.704  (RÂ² = 0.404, n = 109)\n",
      "ONA: EC = 0.379 Ã— BC + 1.704  (RÂ² = 0.404, n = 109)\n",
      "CMA: EC = 0.379 Ã— BC + 1.704  (RÂ² = 0.404, n = 109)\n",
      "DEMA: EC = 0.379 Ã— BC + 1.704  (RÂ² = 0.404, n = 109)\n",
      "\n",
      "HIPS Fabs vs BC:\n",
      "Raw: Fabs = 1.698 Ã— BC + 33.840  (RÂ² = 0.329, n = 109)\n",
      "ONA: Fabs = 1.698 Ã— BC + 33.842  (RÂ² = 0.329, n = 109)\n",
      "CMA: Fabs = 1.698 Ã— BC + 33.842  (RÂ² = 0.329, n = 109)\n",
      "DEMA: Fabs = 1.698 Ã— BC + 33.840  (RÂ² = 0.329, n = 109)\n"
     ]
    }
   ],
   "source": [
    "if 'regression_summary' in results:\n",
    "    reg_summary = results['regression_summary']\n",
    "    \n",
    "    print(\"\\nReduced Ordinary Least Squares (OLS) Equations:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # FTIR EC comparison\n",
    "    if 'FTIR_EC' in reg_summary:\n",
    "        print(\"\\nFTIR EC vs BC:\")\n",
    "        for method, stats in reg_summary['FTIR_EC'].items():\n",
    "            print(f\"{method}: EC = {stats['slope']:.3f} Ã— BC + {stats['intercept']:.3f}  (RÂ² = {stats['r_squared']:.3f}, n = {stats['data_points']})\")\n",
    "    \n",
    "    # HIPS Fabs comparison\n",
    "    if 'HIPS_Fabs' in reg_summary:\n",
    "        print(\"\\nHIPS Fabs vs BC:\")\n",
    "        for method, stats in reg_summary['HIPS_Fabs'].items():\n",
    "            print(f\"{method}: Fabs = {stats['slope']:.3f} Ã— BC + {stats['intercept']:.3f}  (RÂ² = {stats['r_squared']:.3f}, n = {stats['data_points']})\")\n",
    "    \n",
    "    # MAC comparison\n",
    "    if 'mac_comparison' in results:\n",
    "        mac_comp = results['mac_comparison']\n",
    "        \n",
    "        print(\"\\nMAC Values by Method and Season:\")\n",
    "        print(\"=\" * 70)\n",
    "        print(mac_comp.round(2).to_string(index=False))\n",
    "        \n",
    "        # Calculate method-to-method ratios for MAC values\n",
    "        if len(mac_comp) > 1:\n",
    "            print(\"\\nMAC Ratios (Row Method / Column Method):\")\n",
    "            methods = mac_comp['Method'].tolist()\n",
    "            ratio_matrix = np.zeros((len(methods), len(methods)))\n",
    "            \n",
    "            for i, method1 in enumerate(methods):\n",
    "                for j, method2 in enumerate(methods):\n",
    "                    if i != j:\n",
    "                        mac1 = mac_comp.loc[mac_comp['Method'] == method1, 'Overall MAC'].values[0]\n",
    "                        mac2 = mac_comp.loc[mac_comp['Method'] == method2, 'Overall MAC'].values[0]\n",
    "                        ratio_matrix[i, j] = mac1 / mac2\n",
    "            \n",
    "            ratio_df = pd.DataFrame(ratio_matrix, index=methods, columns=methods)\n",
    "            print(ratio_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d63b57e",
   "metadata": {},
   "source": [
    "Analyze the performance improvements by smoothing method\n",
    "Uncomment and run after executing the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920cd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Improvement Metrics by Smoothing Method:\n",
      "====================================================================================================\n",
      "Method  Raw RÂ² vs FTIR  Method RÂ² vs FTIR  FTIR RÂ² Improvement (%)  Raw RÂ² vs HIPS  Method RÂ² vs HIPS  HIPS RÂ² Improvement (%)  Raw Negative Values (%)  Method Negative Values (%)  Negative Value Reduction (%)\n",
      "   ONA             0.4                0.4                    -0.02            0.33               0.33                    -0.03                      0.0                         0.0                             0\n",
      "   CMA             0.4                0.4                    -0.02            0.33               0.33                    -0.02                      0.0                         0.0                             0\n",
      "  DEMA             0.4                0.4                    -0.03            0.33               0.33                    -0.01                      0.0                         0.0                             0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'overlap_df_all' in results:\n",
    "    overlap_df = results['overlap_df_all']\n",
    "    \n",
    "    # Calculate improvement metrics\n",
    "    methods = ['ona', 'cma', 'dema']\n",
    "    improvement_metrics = []\n",
    "    \n",
    "    for method in methods:\n",
    "        # Get column names\n",
    "        raw_col = 'aeth_mean'\n",
    "        method_col = f'{method}_mean'\n",
    "        \n",
    "        if raw_col in overlap_df.columns and method_col in overlap_df.columns:\n",
    "            # Calculate metrics vs FTIR\n",
    "            if 'EC_FTIR' in overlap_df.columns:\n",
    "                # Convert to Î¼g/mÂ³\n",
    "                raw_vs_ftir = pearsonr(overlap_df[raw_col] / 1000, overlap_df['EC_FTIR'])[0]**2\n",
    "                method_vs_ftir = pearsonr(overlap_df[method_col] / 1000, overlap_df['EC_FTIR'])[0]**2\n",
    "                ftir_improvement = (method_vs_ftir - raw_vs_ftir) / raw_vs_ftir * 100\n",
    "            else:\n",
    "                raw_vs_ftir = np.nan\n",
    "                method_vs_ftir = np.nan\n",
    "                ftir_improvement = np.nan\n",
    "            \n",
    "            # Calculate metrics vs HIPS\n",
    "            if 'Fabs' in overlap_df.columns:\n",
    "                raw_vs_hips = pearsonr(overlap_df[raw_col] / 1000, overlap_df['Fabs'])[0]**2\n",
    "                method_vs_hips = pearsonr(overlap_df[method_col] / 1000, overlap_df['Fabs'])[0]**2\n",
    "                hips_improvement = (method_vs_hips - raw_vs_hips) / raw_vs_hips * 100\n",
    "            else:\n",
    "                raw_vs_hips = np.nan\n",
    "                method_vs_hips = np.nan\n",
    "                hips_improvement = np.nan\n",
    "            \n",
    "            # Calculate negative value reduction\n",
    "            raw_neg_pct = (overlap_df[raw_col] < 0).mean() * 100\n",
    "            method_neg_pct = (overlap_df[method_col] < 0).mean() * 100\n",
    "            neg_reduction = (raw_neg_pct - method_neg_pct) / raw_neg_pct * 100 if raw_neg_pct > 0 else 0\n",
    "            \n",
    "            # Add to metrics\n",
    "            improvement_metrics.append({\n",
    "                'Method': method.upper(),\n",
    "                'Raw RÂ² vs FTIR': raw_vs_ftir,\n",
    "                'Method RÂ² vs FTIR': method_vs_ftir,\n",
    "                'FTIR RÂ² Improvement (%)': ftir_improvement,\n",
    "                'Raw RÂ² vs HIPS': raw_vs_hips,\n",
    "                'Method RÂ² vs HIPS': method_vs_hips,\n",
    "                'HIPS RÂ² Improvement (%)': hips_improvement,\n",
    "                'Raw Negative Values (%)': raw_neg_pct,\n",
    "                'Method Negative Values (%)': method_neg_pct,\n",
    "                'Negative Value Reduction (%)': neg_reduction\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame and display\n",
    "    if improvement_metrics:\n",
    "        improvement_df = pd.DataFrame(improvement_metrics)\n",
    "        print(\"\\nImprovement Metrics by Smoothing Method:\")\n",
    "        print(\"=\" * 100)\n",
    "        print(improvement_df.round(2).to_string(index=False))\n",
    "        \n",
    "        # Create bar plot of improvements\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        \n",
    "        # Prepare data for plotting\n",
    "        methods = improvement_df['Method']\n",
    "        ftir_improvement = improvement_df['FTIR RÂ² Improvement (%)']\n",
    "        hips_improvement = improvement_df['HIPS RÂ² Improvement (%)']\n",
    "        neg_reduction = improvement_df['Negative Value Reduction (%)']\n",
    "        \n",
    "        # Set up bar positions\n",
    "        x = np.arange(len(methods))\n",
    "        width = 0.25\n",
    "        \n",
    "        # Create bars\n",
    "        plt.bar(x - width, ftir_improvement, width, label='FTIR RÂ² Improvement (%)', color='blue')\n",
    "        plt.bar(x, hips_improvement, width, label='HIPS RÂ² Improvement (%)', color='green')\n",
    "        plt.bar(x + width, neg_reduction, width, label='Negative Value Reduction (%)', color='red')\n",
    "        \n",
    "        # Add labels and formatting\n",
    "        plt.xlabel('Smoothing Method')\n",
    "        plt.ylabel('Percent Improvement')\n",
    "        plt.title('Performance Improvements by Smoothing Method')\n",
    "        plt.xticks(x, methods)\n",
    "        plt.legend()\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"improvement_metrics_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
