{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /Users/ahmadjalil/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data/Aethelometry Data/Jacros_MA350_1-min_2022-2024_Cleaned.csv\n",
      "Loaded 1095086 rows of data\n",
      "Date range: 2022-04-12 12:46:01+03:00 to 2024-08-20 12:01:00+03:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/4q55gl35679357bs417130z40000gn/T/ipykernel_14938/2288217116.py:151: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  result_df[f'{wave}_k_smooth'].fillna(k_median, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UV wavelength processing summary:\n",
      "Valid ATN1 values: 1095086\n",
      "Valid k values: 1095086\n",
      "Valid babs values: 1086779\n",
      "Mean babs: 0.00 Mm⁻¹\n",
      "Mean eBC: 0.00 µg/m³\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/4q55gl35679357bs417130z40000gn/T/ipykernel_14938/2288217116.py:151: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  result_df[f'{wave}_k_smooth'].fillna(k_median, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blue wavelength processing summary:\n",
      "Valid ATN1 values: 1095086\n",
      "Valid k values: 1095086\n",
      "Valid babs values: 1083361\n",
      "Mean babs: 0.00 Mm⁻¹\n",
      "Mean eBC: 0.00 µg/m³\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/4q55gl35679357bs417130z40000gn/T/ipykernel_14938/2288217116.py:151: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  result_df[f'{wave}_k_smooth'].fillna(k_median, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Green wavelength processing summary:\n",
      "Valid ATN1 values: 1095086\n",
      "Valid k values: 1095086\n",
      "Valid babs values: 1082976\n",
      "Mean babs: 0.00 Mm⁻¹\n",
      "Mean eBC: 0.00 µg/m³\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 987\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_with_sa\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 987\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[1], line 953\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    950\u001b[0m df \u001b[38;5;241m=\u001b[39m load_aethalometer_data(filepath)\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# Calculate babs and eBC using AE33 method\u001b[39;00m\n\u001b[0;32m--> 953\u001b[0m df_ae33 \u001b[38;5;241m=\u001b[39m calculate_babs_ae33_method(df)\n\u001b[1;32m    955\u001b[0m \u001b[38;5;66;03m# Calculate babs and eBC using MA300 method\u001b[39;00m\n\u001b[1;32m    956\u001b[0m df_ma300 \u001b[38;5;241m=\u001b[39m calculate_babs_ma300_method(df_ae33)\n",
      "Cell \u001b[0;32mIn[1], line 141\u001b[0m, in \u001b[0;36mcalculate_babs_ae33_method\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     k \u001b[38;5;241m=\u001b[39m solve_for_k(atn1, atn2, flow_ratio)\n\u001b[0;32m--> 141\u001b[0m     result_df\u001b[38;5;241m.\u001b[39mloc[idx, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwave\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_k_calc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m k\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# Skip calculation if numerical issues\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Aethalometer Data Processing and Method Comparison\n",
    "# Based on Chakraborty et al. 2023 methodology \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = 'output/aethalometer_analysis'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define wavelengths and MAC values based on Chakraborty et al. 2023\n",
    "WAVELENGTHS = {\n",
    "    'UV': 375,\n",
    "    'Blue': 470,\n",
    "    'Green': 528,\n",
    "    'Red': 625,\n",
    "    'IR': 880\n",
    "}\n",
    "\n",
    "MAC_VALUES = {\n",
    "    'UV': 18.47,    # 370/375 nm\n",
    "    'Blue': 14.54,  # 470 nm\n",
    "    'Green': 13.14, # 520/528 nm\n",
    "    'Red': 11.58,   # 625/660 nm\n",
    "    'IR': 7.77      # 880 nm\n",
    "}\n",
    "\n",
    "def load_aethalometer_data(filepath):\n",
    "    \"\"\"\n",
    "    Load and preprocess aethalometer data with proper time handling\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {filepath}\")\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Convert time columns to datetime\n",
    "    if 'Time (UTC)' in df.columns:\n",
    "        df['Time (UTC)'] = pd.to_datetime(df['Time (UTC)'], utc=True)\n",
    "        df['Time (Local)'] = df['Time (UTC)'].dt.tz_convert('Africa/Addis_Ababa')  # Adjust timezone as needed\n",
    "        df.set_index('Time (Local)', inplace=True)\n",
    "    \n",
    "    print(f\"Loaded {len(df)} rows of data\")\n",
    "    print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_babs_ae33_method(df):\n",
    "    \"\"\"\n",
    "    Calculate absorption coefficients using AE33 methodology (Drinovec et al. 2015)\n",
    "    This implements the non-linear loading correction approach\n",
    "    \"\"\"\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Define constants\n",
    "    SPOT_AREA_CM2 = 0.785  # Filter spot area in cm²\n",
    "    C = 1.39                # Multiple scattering correction factor for TFE-coated glass fiber\n",
    "    XI = 0.01               # Filter lateral leakage factor (typically 1%)\n",
    "    DT_MINUTES = 1          # Sampling time interval in minutes\n",
    "    \n",
    "    wavelengths = ['UV', 'Blue', 'Green', 'Red', 'IR']\n",
    "    \n",
    "    for wave in wavelengths:\n",
    "        # Check if we have the required columns\n",
    "        sen1_col = f'{wave} Sen1'\n",
    "        sen2_col = f'{wave} Sen2'\n",
    "        ref_col = f'{wave} Ref'\n",
    "        flow1_col = 'Flow1 (mL/min)'\n",
    "        flow2_col = 'Flow2 (mL/min)'\n",
    "        \n",
    "        if not all(col in df.columns for col in [sen1_col, sen2_col, ref_col, flow1_col, flow2_col]):\n",
    "            print(f\"Skipping {wave} - missing required columns\")\n",
    "            continue\n",
    "            \n",
    "        # Calculate ATN values from raw signals\n",
    "        result_df[f'{wave}_ATN1_calc'] = -np.log(df[sen1_col] / df[ref_col])\n",
    "        result_df[f'{wave}_ATN2_calc'] = -np.log(df[sen2_col] / df[ref_col])\n",
    "        \n",
    "        # Calculate delta ATN\n",
    "        result_df[f'{wave}_dATN1'] = result_df[f'{wave}_ATN1_calc'].diff()\n",
    "        result_df[f'{wave}_dATN2'] = result_df[f'{wave}_ATN2_calc'].diff()\n",
    "        \n",
    "        # Get flow values\n",
    "        flow1 = df[flow1_col]\n",
    "        flow2 = df[flow2_col]\n",
    "        \n",
    "        # Calculate k (loading correction factor) using Drinovec non-linear equation\n",
    "        # F2/F1 = ln(1 - k × ATN2) / ln(1 - k × ATN1)\n",
    "        \n",
    "        # Create mask for valid data\n",
    "        mask = (result_df[f'{wave}_dATN1'] > 0) & (result_df[f'{wave}_dATN2'] > 0) & (flow1 > 0) & (flow2 > 0)\n",
    "        \n",
    "        # Initialize k values\n",
    "        result_df[f'{wave}_k_calc'] = np.nan\n",
    "        \n",
    "        # Function to solve for k using the ratio equation\n",
    "        def solve_for_k(atn1, atn2, flow_ratio):\n",
    "            # We'll use a simplified approach that estimates k\n",
    "            # In a production environment, this should be replaced with a proper numerical solver\n",
    "            \n",
    "            # Start with a reasonable guess\n",
    "            k_guess = 0.01\n",
    "            max_iter = 20\n",
    "            \n",
    "            # These bounds are based on typical values\n",
    "            k_min, k_max = 0.001, 0.1\n",
    "            \n",
    "            for _ in range(max_iter):\n",
    "                # Evaluate the equation\n",
    "                left = flow_ratio\n",
    "                right = np.log(1 - k_guess * atn2) / np.log(1 - k_guess * atn1)\n",
    "                \n",
    "                # Check if we're close enough\n",
    "                if abs(left - right) < 0.001:\n",
    "                    return k_guess\n",
    "                \n",
    "                # Simple bisection step\n",
    "                if right > left:\n",
    "                    k_max = k_guess\n",
    "                else:\n",
    "                    k_min = k_guess\n",
    "                \n",
    "                k_guess = (k_min + k_max) / 2\n",
    "                \n",
    "            return k_guess\n",
    "        \n",
    "        # Calculate k values for each row\n",
    "        for idx in result_df[mask].index:\n",
    "            atn1 = result_df.loc[idx, f'{wave}_ATN1_calc']\n",
    "            atn2 = result_df.loc[idx, f'{wave}_ATN2_calc']\n",
    "            flow_ratio = flow2[idx] / flow1[idx]\n",
    "            \n",
    "            # Skip extreme cases\n",
    "            if atn1 <= 0 or atn2 <= 0 or atn1 > 100 or atn2 > 100:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                k = solve_for_k(atn1, atn2, flow_ratio)\n",
    "                result_df.loc[idx, f'{wave}_k_calc'] = k\n",
    "            except:\n",
    "                # Skip calculation if numerical issues\n",
    "                continue\n",
    "        \n",
    "        # Apply a rolling median to smooth k values\n",
    "        result_df[f'{wave}_k_smooth'] = result_df[f'{wave}_k_calc'].rolling(window=5, center=True).median()\n",
    "        \n",
    "        # Fill in missing k values with median\n",
    "        k_median = result_df[f'{wave}_k_calc'].median()\n",
    "        result_df[f'{wave}_k_smooth'].fillna(k_median, inplace=True)\n",
    "        \n",
    "        # Calculate absorption coefficient with the non-linear Drinovec correction\n",
    "        # babs = F1 × (1 - ξ) × C / [A × (1 - k × ATN1) × 100] × dATN1 / dt\n",
    "        \n",
    "        atn1 = result_df[f'{wave}_ATN1_calc']\n",
    "        dATN1 = result_df[f'{wave}_dATN1']\n",
    "        k_value = result_df[f'{wave}_k_smooth']\n",
    "        \n",
    "        # Valid mask for babs calculation\n",
    "        valid_mask = (dATN1 > 0) & (~dATN1.isna()) & (~k_value.isna()) & (atn1 > 0) & (atn1 < 100)\n",
    "        \n",
    "        # Initialize babs column\n",
    "        result_df[f'{wave}_babs_AE33'] = np.nan\n",
    "        \n",
    "        # Calculate babs using the Drinovec method\n",
    "        result_df.loc[valid_mask, f'{wave}_babs_AE33'] = (\n",
    "            flow1[valid_mask] * (1 - XI) * C / \n",
    "            (SPOT_AREA_CM2 * (1 - k_value[valid_mask] * atn1[valid_mask]) * 100) * \n",
    "            dATN1[valid_mask] / DT_MINUTES\n",
    "        )\n",
    "        \n",
    "        # Convert to eBC using MAC values\n",
    "        result_df[f'{wave}_eBC_AE33'] = result_df[f'{wave}_babs_AE33'] / MAC_VALUES[wave]\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(f\"\\n{wave} wavelength processing summary:\")\n",
    "        print(f\"Valid ATN1 values: {(~result_df[f'{wave}_ATN1_calc'].isna()).sum()}\")\n",
    "        print(f\"Valid k values: {(~result_df[f'{wave}_k_smooth'].isna()).sum()}\")\n",
    "        print(f\"Valid babs values: {(~result_df[f'{wave}_babs_AE33'].isna()).sum()}\")\n",
    "        print(f\"Mean babs: {result_df[f'{wave}_babs_AE33'].mean():.2f} Mm⁻¹\")\n",
    "        print(f\"Mean eBC: {result_df[f'{wave}_eBC_AE33'].mean():.2f} µg/m³\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def calculate_babs_ma300_method(df):\n",
    "    \"\"\"\n",
    "    Calculate absorption coefficients using MA300 methodology (Virkkula linear correction)\n",
    "    \"\"\"\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Define constants\n",
    "    SPOT_AREA_CM2 = 0.785  # Filter spot area in cm²\n",
    "    C = 1.3                 # Multiple scattering correction factor for PTFE filter (MA300)\n",
    "    DT_MINUTES = 1          # Sampling time interval in minutes\n",
    "    \n",
    "    wavelengths = ['UV', 'Blue', 'Green', 'Red', 'IR']\n",
    "    \n",
    "    for wave in wavelengths:\n",
    "        # Required columns\n",
    "        atn1_col = f'{wave} ATN1'\n",
    "        k_col = f'{wave} K'  # Linear loading correction factor used by MA300\n",
    "        flow_col = 'Flow1 (mL/min)'\n",
    "        \n",
    "        if not all(col in df.columns for col in [atn1_col, k_col, flow_col]):\n",
    "            print(f\"Skipping {wave} - missing required columns\")\n",
    "            continue\n",
    "            \n",
    "        # Get values\n",
    "        atn1 = df[atn1_col]\n",
    "        k_value = df[k_col]\n",
    "        flow = df[flow_col]\n",
    "        \n",
    "        # Calculate delta ATN\n",
    "        dATN1 = atn1.diff()\n",
    "        \n",
    "        # Valid mask\n",
    "        valid_mask = (dATN1 > 0) & (~dATN1.isna()) & (~k_value.isna()) & (atn1 > 0) & (atn1 < 100)\n",
    "        \n",
    "        # Calculate babs using Virkkula linear method\n",
    "        # babs = F × C / (A × (1 + k × ATN) × 100) × dATN / dt\n",
    "        \n",
    "        result_df[f'{wave}_babs_MA300'] = np.nan\n",
    "        result_df.loc[valid_mask, f'{wave}_babs_MA300'] = (\n",
    "            flow[valid_mask] * C / \n",
    "            (SPOT_AREA_CM2 * (1 + k_value[valid_mask] * atn1[valid_mask]) * 100) * \n",
    "            dATN1[valid_mask] / DT_MINUTES\n",
    "        )\n",
    "        \n",
    "        # Convert to eBC using MAC values\n",
    "        result_df[f'{wave}_eBC_MA300'] = result_df[f'{wave}_babs_MA300'] / MAC_VALUES[wave]\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\n{wave} wavelength processing summary (MA300 method):\")\n",
    "        print(f\"Valid babs values: {(~result_df[f'{wave}_babs_MA300'].isna()).sum()}\")\n",
    "        print(f\"Mean babs: {result_df[f'{wave}_babs_MA300'].mean():.2f} Mm⁻¹\")\n",
    "        print(f\"Mean eBC: {result_df[f'{wave}_eBC_MA300'].mean():.2f} µg/m³\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def compare_methods(df):\n",
    "    \"\"\"\n",
    "    Compare calculated babs and eBC with original values\n",
    "    \"\"\"\n",
    "    # Find existing BC columns in the dataframe\n",
    "    bc_cols = [col for col in df.columns if any(col.startswith(f'{wave} BC') for wave in ['UV', 'Blue', 'Green', 'Red', 'IR'])]\n",
    "    \n",
    "    print(f\"Found BC columns: {bc_cols}\")\n",
    "    \n",
    "    wavelengths = ['UV', 'Blue', 'Green', 'Red', 'IR']\n",
    "    \n",
    "    # Create plots\n",
    "    for wave in wavelengths:\n",
    "        # Compare original BCc with calculated values\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle(f'{wave} Wavelength Comparison', fontsize=16)\n",
    "        \n",
    "        # Original BCc vs AE33 method\n",
    "        bcc_col = f'{wave} BCc'\n",
    "        ae33_col = f'{wave}_eBC_AE33'\n",
    "        \n",
    "        if bcc_col in df.columns and ae33_col in df.columns:\n",
    "            # Filter to valid values\n",
    "            valid = (~df[bcc_col].isna()) & (~df[ae33_col].isna())\n",
    "            \n",
    "            if valid.sum() > 0:\n",
    "                axes[0, 0].scatter(df.loc[valid, bcc_col], df.loc[valid, ae33_col], alpha=0.3)\n",
    "                \n",
    "                # Add regression line\n",
    "                x = df.loc[valid, bcc_col]\n",
    "                y = df.loc[valid, ae33_col]\n",
    "                slope, intercept = np.polyfit(x, y, 1)\n",
    "                r_squared = np.corrcoef(x, y)[0, 1]**2\n",
    "                \n",
    "                x_line = np.linspace(x.min(), x.max(), 100)\n",
    "                axes[0, 0].plot(x_line, slope * x_line + intercept, 'r-')\n",
    "                \n",
    "                # Add 1:1 line\n",
    "                max_val = max(x.max(), y.max())\n",
    "                axes[0, 0].plot([0, max_val], [0, max_val], 'k--')\n",
    "                \n",
    "                axes[0, 0].set_xlabel(f'Original {bcc_col} (µg/m³)')\n",
    "                axes[0, 0].set_ylabel(f'Calculated AE33 eBC (µg/m³)')\n",
    "                axes[0, 0].set_title(f'Original BCc vs AE33 Method\\nSlope={slope:.3f}, R²={r_squared:.3f}')\n",
    "                \n",
    "        # Original BCc vs MA300 method\n",
    "        ma300_col = f'{wave}_eBC_MA300'\n",
    "        \n",
    "        if bcc_col in df.columns and ma300_col in df.columns:\n",
    "            # Filter to valid values\n",
    "            valid = (~df[bcc_col].isna()) & (~df[ma300_col].isna())\n",
    "            \n",
    "            if valid.sum() > 0:\n",
    "                axes[0, 1].scatter(df.loc[valid, bcc_col], df.loc[valid, ma300_col], alpha=0.3)\n",
    "                \n",
    "                # Add regression line\n",
    "                x = df.loc[valid, bcc_col]\n",
    "                y = df.loc[valid, ma300_col]\n",
    "                slope, intercept = np.polyfit(x, y, 1)\n",
    "                r_squared = np.corrcoef(x, y)[0, 1]**2\n",
    "                \n",
    "                x_line = np.linspace(x.min(), x.max(), 100)\n",
    "                axes[0, 1].plot(x_line, slope * x_line + intercept, 'r-')\n",
    "                \n",
    "                # Add 1:1 line\n",
    "                max_val = max(x.max(), y.max())\n",
    "                axes[0, 1].plot([0, max_val], [0, max_val], 'k--')\n",
    "                \n",
    "                axes[0, 1].set_xlabel(f'Original {bcc_col} (µg/m³)')\n",
    "                axes[0, 1].set_ylabel(f'Calculated MA300 eBC (µg/m³)')\n",
    "                axes[0, 1].set_title(f'Original BCc vs MA300 Method\\nSlope={slope:.3f}, R²={r_squared:.3f}')\n",
    "        \n",
    "        # AE33 method vs MA300 method\n",
    "        if ae33_col in df.columns and ma300_col in df.columns:\n",
    "            # Filter to valid values\n",
    "            valid = (~df[ae33_col].isna()) & (~df[ma300_col].isna())\n",
    "            \n",
    "            if valid.sum() > 0:\n",
    "                axes[1, 0].scatter(df.loc[valid, ae33_col], df.loc[valid, ma300_col], alpha=0.3)\n",
    "                \n",
    "                # Add regression line\n",
    "                x = df.loc[valid, ae33_col]\n",
    "                y = df.loc[valid, ma300_col]\n",
    "                slope, intercept = np.polyfit(x, y, 1)\n",
    "                r_squared = np.corrcoef(x, y)[0, 1]**2\n",
    "                \n",
    "                x_line = np.linspace(x.min(), x.max(), 100)\n",
    "                axes[1, 0].plot(x_line, slope * x_line + intercept, 'r-')\n",
    "                \n",
    "                # Add 1:1 line\n",
    "                max_val = max(x.max(), y.max())\n",
    "                axes[1, 0].plot([0, max_val], [0, max_val], 'k--')\n",
    "                \n",
    "                axes[1, 0].set_xlabel(f'AE33 Method eBC (µg/m³)')\n",
    "                axes[1, 0].set_ylabel(f'MA300 Method eBC (µg/m³)')\n",
    "                axes[1, 0].set_title(f'AE33 vs MA300 Method\\nSlope={slope:.3f}, R²={r_squared:.3f}')\n",
    "        \n",
    "        # Time series comparison\n",
    "        if all(col in df.columns for col in [bcc_col, ae33_col, ma300_col]):\n",
    "            # Get a sample period (1 week if available)\n",
    "            sample_size = min(24*7, len(df))\n",
    "            sample_df = df.iloc[:sample_size]\n",
    "            \n",
    "            axes[1, 1].plot(sample_df.index, sample_df[bcc_col], label='Original BCc')\n",
    "            axes[1, 1].plot(sample_df.index, sample_df[ae33_col], label='AE33 Method')\n",
    "            axes[1, 1].plot(sample_df.index, sample_df[ma300_col], label='MA300 Method')\n",
    "            \n",
    "            axes[1, 1].set_xlabel('Time')\n",
    "            axes[1, 1].set_ylabel('eBC (µg/m³)')\n",
    "            axes[1, 1].set_title('Time Series Comparison')\n",
    "            axes[1, 1].legend()\n",
    "            plt.setp(axes[1, 1].xaxis.get_majorticklabels(), rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'{wave}_method_comparison.png'), dpi=300)\n",
    "\n",
    "def calculate_hourly_averages(df):\n",
    "    \"\"\"\n",
    "    Calculate hourly and 24-hour averages\n",
    "    \"\"\"\n",
    "    # Select only the calculated eBC columns\n",
    "    ebc_cols = [col for col in df.columns if col.endswith('_eBC_AE33') or col.endswith('_eBC_MA300')]\n",
    "    \n",
    "    if not ebc_cols:\n",
    "        print(\"No eBC columns found for averaging\")\n",
    "        return None, None\n",
    "    \n",
    "    # Original BC columns\n",
    "    orig_cols = [col for col in df.columns if col.endswith('BCc')]\n",
    "    \n",
    "    # Combine columns\n",
    "    cols_to_average = ebc_cols + orig_cols\n",
    "    \n",
    "    # Create hourly averages\n",
    "    hourly_df = df[cols_to_average].resample('1H').mean()\n",
    "    \n",
    "    # Create 24-hour averages\n",
    "    daily_df = df[cols_to_average].resample('24H').mean()\n",
    "    \n",
    "    print(f\"Created hourly averages with {len(hourly_df)} rows\")\n",
    "    print(f\"Created daily averages with {len(daily_df)} rows\")\n",
    "    \n",
    "    return hourly_df, daily_df\n",
    "\n",
    "def calculate_aae(df):\n",
    "    \"\"\"\n",
    "    Calculate Absorption Ångström Exponent for different methods\n",
    "    \"\"\"\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Define wavelength pairs to use\n",
    "    pairs = [('UV', 'IR'), ('Blue', 'IR')]\n",
    "    \n",
    "    # Define methods to process\n",
    "    methods = ['AE33', 'MA300']\n",
    "    original_suffix = 'BCc'\n",
    "    \n",
    "    # For each method and wavelength pair, calculate AAE\n",
    "    for method in methods:\n",
    "        for wave1, wave2 in pairs:\n",
    "            # Column names\n",
    "            if method in ['AE33', 'MA300']:\n",
    "                col1 = f'{wave1}_babs_{method}'\n",
    "                col2 = f'{wave2}_babs_{method}'\n",
    "            else:\n",
    "                # For original BC data, convert to babs\n",
    "                col1 = f'{wave1} {original_suffix}'\n",
    "                col2 = f'{wave2} {original_suffix}'\n",
    "                \n",
    "                # Convert BC to babs if needed\n",
    "                if col1 in df.columns and col2 in df.columns:\n",
    "                    df[f'{wave1}_babs_orig'] = df[col1] * MAC_VALUES[wave1]\n",
    "                    df[f'{wave2}_babs_orig'] = df[col2] * MAC_VALUES[wave2]\n",
    "                    col1 = f'{wave1}_babs_orig'\n",
    "                    col2 = f'{wave2}_babs_orig'\n",
    "            \n",
    "            # Skip if columns don't exist\n",
    "            if col1 not in df.columns or col2 not in df.columns:\n",
    "                print(f\"Skipping AAE calculation for {method} with {wave1}-{wave2} - missing columns\")\n",
    "                continue\n",
    "            \n",
    "            # Get wavelength values\n",
    "            lambda1 = WAVELENGTHS[wave1]\n",
    "            lambda2 = WAVELENGTHS[wave2]\n",
    "            \n",
    "            # Create output column name\n",
    "            aae_col = f'AAE_{wave1}_{wave2}_{method}'\n",
    "            \n",
    "            # Calculate AAE\n",
    "            # AAE = -ln(babs1/babs2) / ln(λ1/λ2)\n",
    "            \n",
    "            # Create mask for valid data (positive babs values)\n",
    "            valid_mask = (df[col1] > 0) & (df[col2] > 0) & (~df[col1].isna()) & (~df[col2].isna())\n",
    "            \n",
    "            # Initialize AAE column\n",
    "            result_df[aae_col] = np.nan\n",
    "            \n",
    "            if valid_mask.sum() > 0:\n",
    "                # Calculate AAE\n",
    "                log_babs_ratio = np.log(df.loc[valid_mask, col1] / df.loc[valid_mask, col2])\n",
    "                log_wavelength_ratio = np.log(lambda1 / lambda2)\n",
    "                \n",
    "                # AAE is negative of the slope\n",
    "                aae = -log_babs_ratio / log_wavelength_ratio\n",
    "                \n",
    "                # Filter to reasonable range (0-3)\n",
    "                aae_filtered = aae[(aae >= 0) & (aae <= 3)]\n",
    "                \n",
    "                result_df.loc[valid_mask, aae_col] = aae\n",
    "                \n",
    "                # Print stats\n",
    "                print(f\"\\nCalculated {aae_col}:\")\n",
    "                print(f\"Valid values: {len(aae_filtered)} out of {len(df)} rows ({len(aae_filtered)/len(df)*100:.1f}%)\")\n",
    "                print(f\"Mean AAE: {aae_filtered.mean():.3f}\")\n",
    "                print(f\"Median AAE: {aae_filtered.median():.3f}\")\n",
    "                print(f\"Standard deviation: {aae_filtered.std():.3f}\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def create_aae_plots(df):\n",
    "    \"\"\"\n",
    "    Create plots to compare AAE values from different methods\n",
    "    \"\"\"\n",
    "    # Find all AAE columns\n",
    "    aae_cols = [col for col in df.columns if col.startswith('AAE_')]\n",
    "    \n",
    "    if not aae_cols:\n",
    "        print(\"No AAE columns found for plotting\")\n",
    "        return\n",
    "    \n",
    "    # Group AAE columns by wavelength pair\n",
    "    aae_by_pair = {}\n",
    "    for col in aae_cols:\n",
    "        # Parse column name to get wavelength pair\n",
    "        parts = col.split('_')\n",
    "        if len(parts) >= 3:\n",
    "            pair = f\"{parts[1]}_{parts[2]}\"\n",
    "            if pair not in aae_by_pair:\n",
    "                aae_by_pair[pair] = []\n",
    "            aae_by_pair[pair].append(col)\n",
    "    \n",
    "    # Create comparison plots for each wavelength pair\n",
    "    for pair, columns in aae_by_pair.items():\n",
    "        if len(columns) < 2:\n",
    "            print(f\"Skipping {pair} - need at least 2 methods to compare\")\n",
    "            continue\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        fig.suptitle(f'AAE Comparison for {pair} Wavelength Pair', fontsize=16)\n",
    "        \n",
    "        # Scatter plot matrix\n",
    "        pd.plotting.scatter_matrix(df[columns], alpha=0.3, figsize=(10, 10), diagonal='kde', ax=axes[0])\n",
    "        \n",
    "        # Distribution plot\n",
    "        for col in columns:\n",
    "            method = col.split('_')[3]  # Extract method name\n",
    "            sns.kdeplot(df[col].dropna(), label=method, ax=axes[1])\n",
    "        \n",
    "        axes[1].set_xlabel('AAE Value')\n",
    "        axes[1].set_ylabel('Density')\n",
    "        axes[1].set_title('AAE Distribution Comparison')\n",
    "        axes[1].set_xlim(0, 3)\n",
    "        axes[1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'AAE_{pair}_comparison.png'), dpi=300)\n",
    "\n",
    "def calculate_source_attribution(df):\n",
    "    \"\"\"\n",
    "    Calculate source attribution using different methods and AAE thresholds\n",
    "    \"\"\"\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Define wavelength pairs and AAE thresholds from Zotter et al. 2017\n",
    "    attribution_settings = [\n",
    "        {'pair': ('UV', 'IR'), 'ff_threshold': 0.9, 'bb_threshold': 2.09},\n",
    "        {'pair': ('Blue', 'IR'), 'ff_threshold': 0.9, 'bb_threshold': 1.75}\n",
    "    ]\n",
    "    \n",
    "    # Define methods\n",
    "    methods = ['AE33', 'MA300', 'orig']\n",
    "    \n",
    "    # Process each method and wavelength pair\n",
    "    for method in methods:\n",
    "        for setting in attribution_settings:\n",
    "            wave1, wave2 = setting['pair']\n",
    "            ff_threshold = setting['ff_threshold']\n",
    "            bb_threshold = setting['bb_threshold']\n",
    "            \n",
    "            # Get AAE column\n",
    "            aae_col = f'AAE_{wave1}_{wave2}_{method}'\n",
    "            \n",
    "            # Skip if AAE column doesn't exist\n",
    "            if aae_col not in df.columns:\n",
    "                print(f\"Skipping source attribution for {method} with {wave1}-{wave2} - missing AAE column\")\n",
    "                continue\n",
    "                \n",
    "            # Get IR babs column\n",
    "            if method in ['AE33', 'MA300']:\n",
    "                babs_ir_col = f'{wave2}_babs_{method}'\n",
    "            else:\n",
    "                # For original data\n",
    "                babs_ir_col = f'{wave2}_babs_orig'\n",
    "            \n",
    "            # Skip if IR babs column doesn't exist\n",
    "            if babs_ir_col not in df.columns:\n",
    "                print(f\"Skipping source attribution for {method} with {wave1}-{wave2} - missing IR babs column\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\nCalculating source attribution for {method} with {wave1}-{wave2} pair:\")\n",
    "            print(f\"Using AAE thresholds: ff={ff_threshold}, bb={bb_threshold}\")\n",
    "            \n",
    "            # Create column names for results\n",
    "            ff_col = f'FF_percent_{wave1}_{wave2}_{method}'\n",
    "            bb_col = f'BB_percent_{wave1}_{wave2}_{method}'\n",
    "            ebc_ff_col = f'eBC_FF_{wave1}_{wave2}_{method}'\n",
    "            ebc_bb_col = f'eBC_BB_{wave1}_{wave2}_{method}'\n",
    "            \n",
    "            # Get AAE and IR babs values\n",
    "            aae = df[aae_col]\n",
    "            babs_ir = df[babs_ir_col]\n",
    "            \n",
    "            # Initialize result columns\n",
    "            result_df[ff_col] = np.nan\n",
    "            result_df[bb_col] = np.nan\n",
    "            result_df[ebc_ff_col] = np.nan\n",
    "            result_df[ebc_bb_col] = np.nan\n",
    "            \n",
    "            # Create mask for valid data\n",
    "            valid_mask = (~aae.isna()) & (~babs_ir.isna())\n",
    "            \n",
    "            # Categorize based on AAE thresholds\n",
    "            ff_mask = valid_mask & (aae <= ff_threshold)\n",
    "            bb_mask = valid_mask & (aae >= bb_threshold)\n",
    "            mixed_mask = valid_mask & (aae > ff_threshold) & (aae < bb_threshold)\n",
    "            \n",
    "            # Pure fossil fuel\n",
    "            result_df.loc[ff_mask, ff_col] = 100\n",
    "            result_df.loc[ff_mask, bb_col] = 0\n",
    "            result_df.loc[ff_mask, ebc_ff_col] = babs_ir[ff_mask] / MAC_VALUES['IR']\n",
    "            result_df.loc[ff_mask, ebc_bb_col] = 0\n",
    "            \n",
    "            # Pure biomass burning\n",
    "            result_df.loc[bb_mask, ff_col] = 0\n",
    "            result_df.loc[bb_mask, bb_col] = 100\n",
    "            result_df.loc[bb_mask, ebc_ff_col] = 0\n",
    "            result_df.loc[bb_mask, ebc_bb_col] = babs_ir[bb_mask] / MAC_VALUES['IR']\n",
    "            \n",
    "            # Mixed sources - use linear interpolation between thresholds\n",
    "            result_df.loc[mixed_mask, bb_col] = (\n",
    "                (aae[mixed_mask] - ff_threshold) / (bb_threshold - ff_threshold) * 100\n",
    "            )\n",
    "            result_df.loc[mixed_mask, ff_col] = 100 - result_df.loc[mixed_mask, bb_col]\n",
    "            \n",
    "            # Calculate eBC components for mixed sources\n",
    "            result_df.loc[mixed_mask, ebc_bb_col] = (\n",
    "                babs_ir[mixed_mask] / MAC_VALUES['IR'] * result_df.loc[mixed_mask, bb_col] / 100\n",
    "            )\n",
    "            result_df.loc[mixed_mask, ebc_ff_col] = (\n",
    "                babs_ir[mixed_mask] / MAC_VALUES['IR'] * result_df.loc[mixed_mask, ff_col] / 100\n",
    "            )\n",
    "            \n",
    "            # Print summary\n",
    "            valid_data = result_df.loc[valid_mask, [ff_col, bb_col, ebc_ff_col, ebc_bb_col]]\n",
    "            \n",
    "            print(f\"Valid data points: {len(valid_data)} ({len(valid_data)/len(df)*100:.1f}%)\")\n",
    "            print(f\"Mean FF contribution: {valid_data[ff_col].mean():.1f}%\")\n",
    "            print(f\"Mean FF contribution: {valid_data[ff_col].mean():.1f}%\")\n",
    "            print(f\"Mean BB contribution: {valid_data[bb_col].mean():.1f}%\")\n",
    "            print(f\"Mean eBC from FF: {valid_data[ebc_ff_col].mean():.2f} µg/m³\")\n",
    "            print(f\"Mean eBC from BB: {valid_data[ebc_bb_col].mean():.2f} µg/m³\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def create_source_attribution_plots(df):\n",
    "    \"\"\"\n",
    "    Create plots to compare source attribution results from different methods\n",
    "    \"\"\"\n",
    "    # Find source attribution columns\n",
    "    ff_cols = [col for col in df.columns if col.startswith('FF_percent_')]\n",
    "    bb_cols = [col for col in df.columns if col.startswith('BB_percent_')]\n",
    "    ebc_ff_cols = [col for col in df.columns if col.startswith('eBC_FF_')]\n",
    "    ebc_bb_cols = [col for col in df.columns if col.startswith('eBC_BB_')]\n",
    "    \n",
    "    if not ff_cols or not bb_cols:\n",
    "        print(\"No source attribution columns found for plotting\")\n",
    "        return\n",
    "    \n",
    "    # Group columns by wavelength pair\n",
    "    attribution_by_pair = {}\n",
    "    for col in ff_cols:\n",
    "        # Parse column name to get wavelength pair\n",
    "        parts = col.split('_')\n",
    "        if len(parts) >= 5:\n",
    "            pair = f\"{parts[2]}_{parts[3]}\"\n",
    "            method = parts[4]\n",
    "            \n",
    "            if pair not in attribution_by_pair:\n",
    "                attribution_by_pair[pair] = {}\n",
    "            \n",
    "            if method not in attribution_by_pair[pair]:\n",
    "                attribution_by_pair[pair][method] = {\n",
    "                    'ff_col': col,\n",
    "                    'bb_col': col.replace('FF_percent', 'BB_percent'),\n",
    "                    'ebc_ff_col': col.replace('FF_percent', 'eBC_FF'),\n",
    "                    'ebc_bb_col': col.replace('FF_percent', 'eBC_BB')\n",
    "                }\n",
    "    \n",
    "    # Create comparison plots for each wavelength pair\n",
    "    for pair, methods in attribution_by_pair.items():\n",
    "        if len(methods) < 2:\n",
    "            print(f\"Skipping {pair} - need at least 2 methods to compare\")\n",
    "            continue\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle(f'Source Attribution Comparison for {pair} Wavelength Pair', fontsize=16)\n",
    "        \n",
    "        # FF percentage comparison\n",
    "        for method, cols in methods.items():\n",
    "            axes[0, 0].hist(df[cols['ff_col']].dropna(), alpha=0.5, bins=20, label=method)\n",
    "        \n",
    "        axes[0, 0].set_xlabel('Fossil Fuel Contribution (%)')\n",
    "        axes[0, 0].set_ylabel('Frequency')\n",
    "        axes[0, 0].set_title('FF Percentage Distribution')\n",
    "        axes[0, 0].legend()\n",
    "        \n",
    "        # BB percentage comparison\n",
    "        for method, cols in methods.items():\n",
    "            axes[0, 1].hist(df[cols['bb_col']].dropna(), alpha=0.5, bins=20, label=method)\n",
    "        \n",
    "        axes[0, 1].set_xlabel('Biomass Burning Contribution (%)')\n",
    "        axes[0, 1].set_ylabel('Frequency')\n",
    "        axes[0, 1].set_title('BB Percentage Distribution')\n",
    "        axes[0, 1].legend()\n",
    "        \n",
    "        # eBC from FF comparison\n",
    "        for method, cols in methods.items():\n",
    "            axes[1, 0].hist(df[cols['ebc_ff_col']].dropna(), alpha=0.5, bins=20, label=method)\n",
    "        \n",
    "        axes[1, 0].set_xlabel('eBC from Fossil Fuel (µg/m³)')\n",
    "        axes[1, 0].set_ylabel('Frequency')\n",
    "        axes[1, 0].set_title('eBC from FF Distribution')\n",
    "        axes[1, 0].legend()\n",
    "        \n",
    "        # eBC from BB comparison\n",
    "        for method, cols in methods.items():\n",
    "            axes[1, 1].hist(df[cols['ebc_bb_col']].dropna(), alpha=0.5, bins=20, label=method)\n",
    "        \n",
    "        axes[1, 1].set_xlabel('eBC from Biomass Burning (µg/m³)')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].set_title('eBC from BB Distribution')\n",
    "        axes[1, 1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'source_attribution_{pair}_comparison.png'), dpi=300)\n",
    "        \n",
    "        # Create time series plot of contributions\n",
    "        if isinstance(df.index, pd.DatetimeIndex):\n",
    "            # Sample a portion of the data for time series\n",
    "            sample_size = min(24*7, len(df))\n",
    "            sample_df = df.iloc[:sample_size]\n",
    "            \n",
    "            fig, axes = plt.subplots(len(methods), 1, figsize=(15, 4*len(methods)))\n",
    "            fig.suptitle(f'Source Attribution Time Series for {pair} Wavelength Pair', fontsize=16)\n",
    "            \n",
    "            if len(methods) == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            for i, (method, cols) in enumerate(methods.items()):\n",
    "                # Stack plot of FF and BB components\n",
    "                axes[i].stackplot(sample_df.index, \n",
    "                                 sample_df[cols['ebc_ff_col']].fillna(0),\n",
    "                                 sample_df[cols['ebc_bb_col']].fillna(0),\n",
    "                                 labels=['Fossil Fuel', 'Biomass Burning'],\n",
    "                                 alpha=0.7)\n",
    "                \n",
    "                axes[i].set_title(f'{method} Method')\n",
    "                axes[i].set_ylabel('eBC (µg/m³)')\n",
    "                axes[i].legend(loc='upper right')\n",
    "                \n",
    "                if i == len(methods) - 1:\n",
    "                    axes[i].set_xlabel('Time')\n",
    "                \n",
    "                plt.setp(axes[i].xaxis.get_majorticklabels(), rotation=45)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f'source_attribution_{pair}_timeseries.png'), dpi=300)\n",
    "\n",
    "def analyze_method_differences(df):\n",
    "    \"\"\"\n",
    "    Analyze and explain the differences between AE33 and MA300 methods\n",
    "    \"\"\"\n",
    "    wavelengths = ['UV', 'Blue', 'Green', 'Red', 'IR']\n",
    "    \n",
    "    # Calculate key differences for each wavelength\n",
    "    differences = {}\n",
    "    \n",
    "    for wave in wavelengths:\n",
    "        # Columns to compare\n",
    "        ae33_babs = f'{wave}_babs_AE33'\n",
    "        ma300_babs = f'{wave}_babs_MA300'\n",
    "        ae33_ebc = f'{wave}_eBC_AE33'\n",
    "        ma300_ebc = f'{wave}_eBC_MA300'\n",
    "        k_AE33 = f'{wave}_k_calc'\n",
    "        k_MA300 = f'{wave} K'  # Original k from MA300\n",
    "        \n",
    "        # Skip if any column is missing\n",
    "        if not all(col in df.columns for col in [ae33_babs, ma300_babs, ae33_ebc, ma300_ebc]):\n",
    "            print(f\"Skipping difference analysis for {wave} - missing required columns\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate relative differences\n",
    "        valid_mask = (~df[ae33_babs].isna()) & (~df[ma300_babs].isna())\n",
    "        \n",
    "        if valid_mask.sum() == 0:\n",
    "            print(f\"No valid data for {wave} comparison\")\n",
    "            continue\n",
    "        \n",
    "        # babs differences\n",
    "        abs_diff_babs = (df.loc[valid_mask, ae33_babs] - df.loc[valid_mask, ma300_babs]).abs()\n",
    "        rel_diff_babs = abs_diff_babs / df.loc[valid_mask, ae33_babs] * 100\n",
    "        \n",
    "        # eBC differences\n",
    "        abs_diff_ebc = (df.loc[valid_mask, ae33_ebc] - df.loc[valid_mask, ma300_ebc]).abs()\n",
    "        rel_diff_ebc = abs_diff_ebc / df.loc[valid_mask, ae33_ebc] * 100\n",
    "        \n",
    "        # K value differences if available\n",
    "        if k_AE33 in df.columns and k_MA300 in df.columns:\n",
    "            k_valid_mask = valid_mask & (~df[k_AE33].isna()) & (~df[k_MA300].isna())\n",
    "            if k_valid_mask.sum() > 0:\n",
    "                abs_diff_k = (df.loc[k_valid_mask, k_AE33] - df.loc[k_valid_mask, k_MA300]).abs()\n",
    "                rel_diff_k = abs_diff_k / df.loc[k_valid_mask, k_AE33].abs() * 100\n",
    "            else:\n",
    "                abs_diff_k = pd.Series()\n",
    "                rel_diff_k = pd.Series()\n",
    "        else:\n",
    "            abs_diff_k = pd.Series()\n",
    "            rel_diff_k = pd.Series()\n",
    "        \n",
    "        # Store results\n",
    "        differences[wave] = {\n",
    "            'babs_abs_diff': abs_diff_babs,\n",
    "            'babs_rel_diff': rel_diff_babs,\n",
    "            'ebc_abs_diff': abs_diff_ebc,\n",
    "            'ebc_rel_diff': rel_diff_ebc,\n",
    "            'k_abs_diff': abs_diff_k,\n",
    "            'k_rel_diff': rel_diff_k,\n",
    "            'valid_count': valid_mask.sum()\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nMethod differences for {wave} wavelength:\")\n",
    "        print(f\"Valid data points: {valid_mask.sum()} ({valid_mask.sum()/len(df)*100:.1f}%)\")\n",
    "        print(f\"Mean babs - AE33: {df.loc[valid_mask, ae33_babs].mean():.2f} Mm⁻¹, MA300: {df.loc[valid_mask, ma300_babs].mean():.2f} Mm⁻¹\")\n",
    "        print(f\"Mean eBC - AE33: {df.loc[valid_mask, ae33_ebc].mean():.2f} µg/m³, MA300: {df.loc[valid_mask, ma300_ebc].mean():.2f} µg/m³\")\n",
    "        print(f\"Mean absolute babs difference: {abs_diff_babs.mean():.2f} Mm⁻¹\")\n",
    "        print(f\"Mean relative babs difference: {rel_diff_babs.mean():.1f}%\")\n",
    "        \n",
    "        if len(abs_diff_k) > 0:\n",
    "            print(f\"Mean K value - AE33: {df.loc[k_valid_mask, k_AE33].mean():.5f}, MA300: {df.loc[k_valid_mask, k_MA300].mean():.5f}\")\n",
    "            print(f\"Mean absolute K difference: {abs_diff_k.mean():.5f}\")\n",
    "            print(f\"Mean relative K difference: {rel_diff_k.mean():.1f}%\")\n",
    "    \n",
    "    # Create plots to visualize differences\n",
    "    fig, axes = plt.subplots(len(wavelengths), 2, figsize=(15, 4*len(wavelengths)))\n",
    "    \n",
    "    if len(wavelengths) == 1:\n",
    "        axes = np.array([axes])\n",
    "    \n",
    "    for i, wave in enumerate(wavelengths):\n",
    "        if wave not in differences:\n",
    "            continue\n",
    "        \n",
    "        # Get differences data\n",
    "        data = differences[wave]\n",
    "        \n",
    "        # babs difference distribution\n",
    "        sns.histplot(data['babs_rel_diff'], kde=True, ax=axes[i, 0])\n",
    "        axes[i, 0].set_xlabel(f'Relative babs Difference (%) - {wave}')\n",
    "        axes[i, 0].set_title(f'Distribution of babs Differences - {wave}')\n",
    "        axes[i, 0].axvline(x=data['babs_rel_diff'].mean(), color='r', linestyle='--', \n",
    "                           label=f'Mean: {data[\"babs_rel_diff\"].mean():.1f}%')\n",
    "        axes[i, 0].legend()\n",
    "        \n",
    "        # eBC difference distribution\n",
    "        sns.histplot(data['ebc_rel_diff'], kde=True, ax=axes[i, 1])\n",
    "        axes[i, 1].set_xlabel(f'Relative eBC Difference (%) - {wave}')\n",
    "        axes[i, 1].set_title(f'Distribution of eBC Differences - {wave}')\n",
    "        axes[i, 1].axvline(x=data['ebc_rel_diff'].mean(), color='r', linestyle='--',\n",
    "                          label=f'Mean: {data[\"ebc_rel_diff\"].mean():.1f}%')\n",
    "        axes[i, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'method_differences.png'), dpi=300)\n",
    "    \n",
    "    return differences\n",
    "\n",
    "def create_method_comparison_summary():\n",
    "    \"\"\"\n",
    "    Create a summary of the key differences between AE33 and MA300 methods\n",
    "    \"\"\"\n",
    "    # Create a summary table and save as image\n",
    "    summary_data = {\n",
    "        'Feature': [\n",
    "            'Loading Correction Algorithm',\n",
    "            'Scattering Correction Factor',\n",
    "            'Consideration of Flow Variation',\n",
    "            'Filter Leakage Correction',\n",
    "            'Known UV Channel Issues',\n",
    "            'Filter Loading Per Unit Volume',\n",
    "            'Unit-to-Unit Variability',\n",
    "            'Best Wavelength for AAE Calculation',\n",
    "            'Recommended AAE Thresholds (UV-IR)',\n",
    "            'Recommended AAE Thresholds (Blue-IR)'\n",
    "        ],\n",
    "        'AE33 Method': [\n",
    "            'Non-linear (Drinovec et al. 2015)',\n",
    "            'C = 1.39 for TFE-coated glass fiber',\n",
    "            'Includes flow compensation',\n",
    "            'Includes 1% leakage factor',\n",
    "            'Less affected',\n",
    "            'Lower due to higher flow rate',\n",
    "            '~0.5% (Cuesta-Mosquera et al. 2021)',\n",
    "            'Both UV-IR and Blue-IR viable',\n",
    "            'αff = 0.9, αbb = 2.09 (Zotter et al. 2017)',\n",
    "            'αff = 0.9, αbb = 1.75 (Zotter et al. 2017)'\n",
    "        ],\n",
    "        'MA300 Method': [\n",
    "            'Linear (Virkkula et al. 2007)',\n",
    "            'C = 1.3 for PTFE filter',\n",
    "            'No flow compensation',\n",
    "            'Not considered',\n",
    "            'Underestimates during pollution events',\n",
    "            'Higher due to lower flow rate',\n",
    "            '~5% (normalized, Chakraborty et al. 2023)',\n",
    "            'Blue-IR recommended over UV-IR',\n",
    "            'Same as AE33, but less reliable',\n",
    "            'Same as AE33, more reliable than UV-IR'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Save summary to CSV\n",
    "    summary_df.to_csv(os.path.join(output_dir, 'method_comparison_summary.csv'), index=False)\n",
    "    \n",
    "    # Create a visual table\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    table = ax.table(\n",
    "        cellText=summary_df.values,\n",
    "        colLabels=summary_df.columns,\n",
    "        cellLoc='center',\n",
    "        loc='center',\n",
    "        colWidths=[0.25, 0.375, 0.375]\n",
    "    )\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 1.5)\n",
    "    \n",
    "    plt.title('Comparison of AE33 and MA300 Methods', fontsize=14, pad=20)\n",
    "    plt.savefig(os.path.join(output_dir, 'method_comparison_summary.png'), dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Create explanation document with findings\n",
    "    with open(os.path.join(output_dir, 'method_comparison_findings.txt'), 'w') as f:\n",
    "        f.write(\"# Key Differences Between AE33 and MA300 Methods for BC Measurement\\n\\n\")\n",
    "        \n",
    "        f.write(\"## 1. Loading Correction Algorithms\\n\")\n",
    "        f.write(\"The most significant difference is in the loading correction algorithms. AE33 uses a non-linear correction (Drinovec et al. 2015) that accounts for the shadowing effect as particles accumulate on the filter. In contrast, MA300 uses a linear correction (Virkkula et al. 2007) which is simpler but less accurate at higher filter loadings.\\n\\n\")\n",
    "        \n",
    "        f.write(\"This difference becomes particularly pronounced during high pollution events (e.g., wildfire periods) when filter loading increases rapidly. The AE33 algorithm handles this situation better by dynamically adjusting the correction factor.\\n\\n\")\n",
    "        \n",
    "        f.write(\"## 2. Flow Rate Considerations\\n\")\n",
    "        f.write(\"AE33 incorporates flow rate variations in its correction algorithm, while MA300 does not. This is significant because:\\n\")\n",
    "        f.write(\"- MA300 has higher flow variability (up to 14.2% deviation from setpoint vs 3.2% for AE33)\\n\")\n",
    "        f.write(\"- Lower face velocity in MA300 changes particle penetration depth into the filter\\n\")\n",
    "        f.write(\"- Higher filter loading per unit volume in MA300 due to lower flow rate\\n\\n\")\n",
    "        \n",
    "        f.write(\"## 3. Wavelength-Specific Issues\\n\")\n",
    "        f.write(\"The UV channel in MA300 consistently underestimates absorption during pollution events, particularly during wildfire periods. This leads to systematic bias in source apportionment analysis. Key findings:\\n\")\n",
    "        f.write(\"- UV channel shows highest unit-to-unit variability (8%)\\n\")\n",
    "        f.write(\"- Blue channel shows much lower variability (4%)\\n\")\n",
    "        f.write(\"- Using Blue-IR wavelength pair instead of UV-IR improves source apportionment by ~10%\\n\\n\")\n",
    "        \n",
    "        f.write(\"## 4. Recommendations\\n\")\n",
    "        f.write(\"Based on the analysis of both methods, the following recommendations can be made:\\n\")\n",
    "        f.write(\"1. For source apportionment, use the Blue-IR wavelength pair with MA300 data instead of UV-IR\\n\")\n",
    "        f.write(\"2. When processing MA300 data, consider implementing the non-linear Drinovec correction if flow data is stable\\n\")\n",
    "        f.write(\"3. Be cautious about UV channel measurements during high pollution events\\n\")\n",
    "        f.write(\"4. For improved accuracy with MA300, perform more frequent flow calibrations\\n\")\n",
    "        f.write(\"5. When comparing to HIPS data, focus on IR wavelength (880 nm) which shows better stability\\n\\n\")\n",
    "        \n",
    "        f.write(\"## 5. Impact on BC Measurements\\n\")\n",
    "        f.write(\"The different correction methods can lead to significant differences in reported BC values:\\n\")\n",
    "        f.write(\"- During regular periods: relatively small differences (<20%)\\n\")\n",
    "        f.write(\"- During high pollution/wildfire periods: large differences (up to 44%)\\n\")\n",
    "        f.write(\"- Source attribution can vary significantly between methods during pollution events\\n\\n\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the full analysis\n",
    "    \"\"\"\n",
    "    # Set file path for your data\n",
    "    filepath = \"/Users/ahmadjalil/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data/Aethelometry Data/Jacros_MA350_1-min_2022-2024_Cleaned.csv\"\n",
    "    \n",
    "    # Load data\n",
    "    df = load_aethalometer_data(filepath)\n",
    "    \n",
    "    # Calculate babs and eBC using AE33 method\n",
    "    df_ae33 = calculate_babs_ae33_method(df)\n",
    "    \n",
    "    # Calculate babs and eBC using MA300 method\n",
    "    df_ma300 = calculate_babs_ma300_method(df_ae33)\n",
    "    \n",
    "    # Compare methods\n",
    "    compare_methods(df_ma300)\n",
    "    \n",
    "    # Calculate hourly and daily averages\n",
    "    hourly_df, daily_df = calculate_hourly_averages(df_ma300)\n",
    "    \n",
    "    # Calculate AAE\n",
    "    df_with_aae = calculate_aae(df_ma300)\n",
    "    \n",
    "    # Create AAE plots\n",
    "    create_aae_plots(df_with_aae)\n",
    "    \n",
    "    # Calculate source attribution\n",
    "    df_with_sa = calculate_source_attribution(df_with_aae)\n",
    "    \n",
    "    # Create source attribution plots\n",
    "    create_source_attribution_plots(df_with_sa)\n",
    "    \n",
    "    # Analyze method differences\n",
    "    differences = analyze_method_differences(df_with_sa)\n",
    "    \n",
    "    # Create method comparison summary\n",
    "    create_method_comparison_summary()\n",
    "    \n",
    "    print(f\"Analysis complete! Results saved to {output_dir}\")\n",
    "    \n",
    "    return df_with_sa\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /Users/ahmadjalil/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data/Aethelometry Data/Jacros_MA350_1-min_2022-2024_Cleaned.csv\n",
      "Mean IR BCc value: 8137.54\n",
      "BC values appear to be in ng/m³, converting to μg/m³\n",
      "Converted UV BC1 to μg/m³\n",
      "Converted UV BC2 to μg/m³\n",
      "Converted UV BCc to μg/m³\n",
      "Converted Blue BC1 to μg/m³\n",
      "Converted Blue BC2 to μg/m³\n",
      "Converted Blue BCc to μg/m³\n",
      "Converted Green BC1 to μg/m³\n",
      "Converted Green BC2 to μg/m³\n",
      "Converted Green BCc to μg/m³\n",
      "Converted Red BC1 to μg/m³\n",
      "Converted Red BC2 to μg/m³\n",
      "Converted Red BCc to μg/m³\n",
      "Converted IR BC1 to μg/m³\n",
      "Converted IR BC2 to μg/m³\n",
      "Converted IR BCc to μg/m³\n",
      "Dataset spans from 2022-04-12 12:46:01+03:00 to 2024-08-20 12:01:00+03:00\n",
      "Total records: 1095086\n",
      "\n",
      "Processing UV wavelength...\n",
      "  Valid data points: 1092307 (99.7%)\n",
      "  MA300 method: Mean babs = 0.05 Mm⁻¹\n",
      "  AE33 method: Mean babs = 0.14 Mm⁻¹\n",
      "  From BCc: Mean babs = 143.28 Mm⁻¹\n",
      "  Mean relative difference - MA300 method vs BCc: nan%\n",
      "  Mean relative difference - AE33 method vs BCc: nan%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:49: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created comparison plots for UV wavelength\n",
      "\n",
      "Processing Blue wavelength...\n",
      "  Valid data points: 1093447 (99.9%)\n",
      "  MA300 method: Mean babs = 0.05 Mm⁻¹\n",
      "  AE33 method: Mean babs = 0.11 Mm⁻¹\n",
      "  From BCc: Mean babs = 123.43 Mm⁻¹\n",
      "  Mean relative difference - MA300 method vs BCc: nan%\n",
      "  Mean relative difference - AE33 method vs BCc: nan%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:49: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created comparison plots for Blue wavelength\n",
      "\n",
      "Processing Green wavelength...\n",
      "  Valid data points: 1092899 (99.8%)\n",
      "  MA300 method: Mean babs = 0.04 Mm⁻¹\n",
      "  AE33 method: Mean babs = 0.10 Mm⁻¹\n",
      "  From BCc: Mean babs = 109.02 Mm⁻¹\n",
      "  Mean relative difference - MA300 method vs BCc: nan%\n",
      "  Mean relative difference - AE33 method vs BCc: nan%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:49: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created comparison plots for Green wavelength\n",
      "\n",
      "Processing Red wavelength...\n",
      "  Valid data points: 1093331 (99.8%)\n",
      "  MA300 method: Mean babs = 0.04 Mm⁻¹\n",
      "  AE33 method: Mean babs = 0.08 Mm⁻¹\n",
      "  From BCc: Mean babs = 93.60 Mm⁻¹\n",
      "  Mean relative difference - MA300 method vs BCc: nan%\n",
      "  Mean relative difference - AE33 method vs BCc: nan%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:49: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created comparison plots for Red wavelength\n",
      "\n",
      "Processing IR wavelength...\n",
      "  Valid data points: 1093133 (99.8%)\n",
      "  MA300 method: Mean babs = 0.03 Mm⁻¹\n",
      "  AE33 method: Mean babs = 0.06 Mm⁻¹\n",
      "  From BCc: Mean babs = 63.23 Mm⁻¹\n",
      "  Mean relative difference - MA300 method vs BCc: nan%\n",
      "  Mean relative difference - AE33 method vs BCc: nan%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:49: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created comparison plots for IR wavelength\n",
      "Created method differences summary\n",
      "Analysis complete! Results saved to output/aeth_analysis\n"
     ]
    }
   ],
   "source": [
    "# Aethalometer Data Analysis with Unit Conversion Check\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = 'output/aeth_analysis'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define wavelengths and MAC values\n",
    "WAVELENGTHS = {\n",
    "    'UV': 375,\n",
    "    'Blue': 470,\n",
    "    'Green': 528,\n",
    "    'Red': 625,\n",
    "    'IR': 880\n",
    "}\n",
    "\n",
    "MAC_VALUES = {\n",
    "    'UV': 18.47,\n",
    "    'Blue': 14.54,\n",
    "    'Green': 13.14,\n",
    "    'Red': 11.58,\n",
    "    'IR': 7.77\n",
    "}\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"Load aethalometer data with proper time handling\"\"\"\n",
    "    print(f\"Loading data from {filepath}\")\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Convert time columns to datetime\n",
    "    if 'Time (UTC)' in df.columns:\n",
    "        df['Time (UTC)'] = pd.to_datetime(df['Time (UTC)'], utc=True)\n",
    "        if 'Time (Local)' not in df.columns:\n",
    "            df['Time (Local)'] = df['Time (UTC)'].dt.tz_convert('Africa/Addis_Ababa')\n",
    "        df.set_index('Time (Local)', inplace=True)\n",
    "    \n",
    "    # Check if BC values are in ng/m³ by looking at the range\n",
    "    # We'll check IR BC as a representative example\n",
    "    if 'IR BCc' in df.columns:\n",
    "        bc_mean = df['IR BCc'].mean()\n",
    "        print(f\"Mean IR BCc value: {bc_mean:.2f}\")\n",
    "        \n",
    "        if bc_mean > 100:  # Likely in ng/m³\n",
    "            print(\"BC values appear to be in ng/m³, converting to μg/m³\")\n",
    "            for col in df.columns:\n",
    "                if any(col.startswith(f\"{wave} BC\") for wave in ['UV', 'Blue', 'Green', 'Red', 'IR']):\n",
    "                    df[col] = df[col] / 1000\n",
    "                    print(f\"Converted {col} to μg/m³\")\n",
    "    \n",
    "    print(f\"Dataset spans from {df.index.min()} to {df.index.max()}\")\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def compare_calculation_methods(df):\n",
    "    \"\"\"\n",
    "    Compare the reported BC values with recalculated values using raw signals\n",
    "    \"\"\"\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Define constants\n",
    "    AREA_CM2 = 0.785       # Filter spot area in cm²\n",
    "    C_AE33 = 1.39          # Multiple scattering factor (AE33)\n",
    "    C_MA300 = 1.3          # Multiple scattering factor (MA300)\n",
    "    XI = 0.01              # Filter leakage factor (AE33)\n",
    "    DT_MINUTES = 1         # Time interval\n",
    "    \n",
    "    wavelengths = ['UV', 'Blue', 'Green', 'Red', 'IR']\n",
    "    \n",
    "    for wave in wavelengths:\n",
    "        print(f\"\\nProcessing {wave} wavelength...\")\n",
    "        \n",
    "        # Check if we have the necessary columns\n",
    "        sen1_col = f'{wave} Sen1'\n",
    "        sen2_col = f'{wave} Sen2'\n",
    "        ref_col = f'{wave} Ref'\n",
    "        atn1_col = f'{wave} ATN1'\n",
    "        atn2_col = f'{wave} ATN2'\n",
    "        k_col = f'{wave} K'\n",
    "        bc1_col = f'{wave} BC1'\n",
    "        bc2_col = f'{wave} BC2'\n",
    "        bcc_col = f'{wave} BCc'\n",
    "        \n",
    "        required_cols = [atn1_col, k_col, bcc_col]\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            print(f\"  Missing required columns for {wave} wavelength - skipping\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate delta ATN (change in ATN)\n",
    "        result_df[f'{wave}_dATN1'] = df[atn1_col].diff()\n",
    "        \n",
    "        # Get flow rate\n",
    "        flow_col = 'Flow1 (mL/min)'\n",
    "        if flow_col not in df.columns:\n",
    "            print(f\"  Missing flow column - skipping\")\n",
    "            continue\n",
    "        \n",
    "        flow = df[flow_col]\n",
    "        atn = df[atn1_col]\n",
    "        k = df[k_col]\n",
    "        dATN = result_df[f'{wave}_dATN1']\n",
    "        \n",
    "        # Valid mask for calculation\n",
    "        valid_mask = (dATN > 0) & (~dATN.isna()) & (~k.isna()) & (atn >= 0) & (atn < 100)\n",
    "        \n",
    "        # Calculate absorption using MA300 method (Virkkula linear correction)\n",
    "        # babs = F × C / (A × (1 + k × ATN) × 100) × dATN / dt\n",
    "        result_df[f'{wave}_babs_MA300'] = np.nan\n",
    "        result_df.loc[valid_mask, f'{wave}_babs_MA300'] = (\n",
    "            flow[valid_mask] * C_MA300 / \n",
    "            (AREA_CM2 * (1 + k[valid_mask] * atn[valid_mask]) * 100) * \n",
    "            dATN[valid_mask]\n",
    "        )\n",
    "        \n",
    "        # Calculate absorption using AE33 method (Drinovec non-linear correction)\n",
    "        # babs = F × (1 - ξ) × C / (A × (1 - k × ATN) × 100) × dATN / dt\n",
    "        result_df[f'{wave}_babs_AE33'] = np.nan\n",
    "        result_df.loc[valid_mask, f'{wave}_babs_AE33'] = (\n",
    "            flow[valid_mask] * (1 - XI) * C_AE33 / \n",
    "            (AREA_CM2 * (1 - k[valid_mask] * atn[valid_mask]) * 100) * \n",
    "            dATN[valid_mask]\n",
    "        )\n",
    "        \n",
    "        # Calculate eBC from babs using MAC values\n",
    "        result_df[f'{wave}_eBC_MA300'] = result_df[f'{wave}_babs_MA300'] / MAC_VALUES[wave]\n",
    "        result_df[f'{wave}_eBC_AE33'] = result_df[f'{wave}_babs_AE33'] / MAC_VALUES[wave]\n",
    "        \n",
    "        # Calculate babs from reported BCc for comparison\n",
    "        result_df[f'{wave}_babs_BCc'] = df[bcc_col] * MAC_VALUES[wave]\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(f\"  Valid data points: {valid_mask.sum()} ({valid_mask.sum()/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        if valid_mask.sum() > 0:\n",
    "            ma300_babs_mean = result_df.loc[valid_mask, f'{wave}_babs_MA300'].mean()\n",
    "            ae33_babs_mean = result_df.loc[valid_mask, f'{wave}_babs_AE33'].mean()\n",
    "            bcc_babs_mean = result_df.loc[valid_mask, f'{wave}_babs_BCc'].mean()\n",
    "            \n",
    "            print(f\"  MA300 method: Mean babs = {ma300_babs_mean:.2f} Mm⁻¹\")\n",
    "            print(f\"  AE33 method: Mean babs = {ae33_babs_mean:.2f} Mm⁻¹\")\n",
    "            print(f\"  From BCc: Mean babs = {bcc_babs_mean:.2f} Mm⁻¹\")\n",
    "            \n",
    "            # Check if BCc babs values are reasonable\n",
    "            if bcc_babs_mean > 1000:\n",
    "                # If BCc values are still too high, we might need to scale them down\n",
    "                scaling_factor = 1000  # Try dividing by 1000\n",
    "                print(f\"  WARNING: BCc babs values still too high - trying with scaling factor {scaling_factor}\")\n",
    "                result_df[f'{wave}_babs_BCc'] = result_df[f'{wave}_babs_BCc'] / scaling_factor\n",
    "                bcc_babs_mean = result_df.loc[valid_mask, f'{wave}_babs_BCc'].mean()\n",
    "                print(f\"  After scaling: Mean babs from BCc = {bcc_babs_mean:.2f} Mm⁻¹\")\n",
    "            \n",
    "            # If values are now in reasonable range, calculate differences\n",
    "            if 0.01 < bcc_babs_mean < 1000:\n",
    "                rel_diff_ma300 = ((result_df.loc[valid_mask, f'{wave}_babs_MA300'] - \n",
    "                                 result_df.loc[valid_mask, f'{wave}_babs_BCc']) / \n",
    "                                result_df.loc[valid_mask, f'{wave}_babs_BCc'] * 100)\n",
    "                \n",
    "                rel_diff_ae33 = ((result_df.loc[valid_mask, f'{wave}_babs_AE33'] - \n",
    "                                result_df.loc[valid_mask, f'{wave}_babs_BCc']) / \n",
    "                               result_df.loc[valid_mask, f'{wave}_babs_BCc'] * 100)\n",
    "                \n",
    "                print(f\"  Mean relative difference - MA300 method vs BCc: {rel_diff_ma300.mean():.1f}%\")\n",
    "                print(f\"  Mean relative difference - AE33 method vs BCc: {rel_diff_ae33.mean():.1f}%\")\n",
    "            else:\n",
    "                print(\"  Cannot calculate meaningful relative differences due to scale issues\")\n",
    "        \n",
    "        # Create comparison plots\n",
    "        create_comparison_plots(result_df, wave, valid_mask)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def create_comparison_plots(df, wavelength, valid_mask):\n",
    "    \"\"\"Create plots comparing different calculation methods\"\"\"\n",
    "    # Set up plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle(f'{wavelength} Wavelength - Comparison of Calculation Methods', fontsize=16)\n",
    "    \n",
    "    # Filter data for plotting\n",
    "    plot_df = df.loc[valid_mask].copy()\n",
    "    \n",
    "    # Columns to compare\n",
    "    babs_bcc = f'{wavelength}_babs_BCc'\n",
    "    babs_ma300 = f'{wavelength}_babs_MA300'\n",
    "    babs_ae33 = f'{wavelength}_babs_AE33'\n",
    "    \n",
    "    # Check if we have valid data\n",
    "    if plot_df[babs_bcc].isna().all() or plot_df[babs_ma300].isna().all() or plot_df[babs_ae33].isna().all():\n",
    "        print(f\"  Not enough valid data for {wavelength} wavelength plots\")\n",
    "        plt.close(fig)\n",
    "        return\n",
    "    \n",
    "    # Remove any remaining NaN values\n",
    "    plot_df = plot_df.dropna(subset=[babs_bcc, babs_ma300, babs_ae33])\n",
    "    \n",
    "    # If we still don't have enough data, exit\n",
    "    if len(plot_df) < 10:\n",
    "        print(f\"  Not enough valid data for {wavelength} wavelength plots after NaN removal\")\n",
    "        plt.close(fig)\n",
    "        return\n",
    "    \n",
    "    # Limit to recent data for time series\n",
    "    if len(plot_df) > 1000:\n",
    "        time_series_df = plot_df.iloc[-1000:].copy()\n",
    "    else:\n",
    "        time_series_df = plot_df.copy()\n",
    "    \n",
    "    try:\n",
    "        # 1. Scatter plot: BCc babs vs MA300 method\n",
    "        axes[0, 0].scatter(plot_df[babs_bcc], plot_df[babs_ma300], alpha=0.3)\n",
    "        max_val = max(plot_df[babs_bcc].max(), plot_df[babs_ma300].max())\n",
    "        axes[0, 0].plot([0, max_val], [0, max_val], 'k--')  # 1:1 line\n",
    "        \n",
    "        # Add regression line\n",
    "        if len(plot_df) > 1:\n",
    "            x = plot_df[babs_bcc]\n",
    "            y = plot_df[babs_ma300]\n",
    "            mask = (~np.isnan(x)) & (~np.isnan(y))\n",
    "            if mask.sum() > 1:\n",
    "                slope, intercept = np.polyfit(x[mask], y[mask], 1)\n",
    "                r_squared = np.corrcoef(x[mask], y[mask])[0, 1]**2\n",
    "                axes[0, 0].plot([0, max_val], [intercept, slope*max_val + intercept], 'r-')\n",
    "                axes[0, 0].text(0.05, 0.95, f'y = {slope:.2f}x + {intercept:.2f}\\nR² = {r_squared:.3f}',\n",
    "                             transform=axes[0, 0].transAxes, bbox=dict(facecolor='white', alpha=0.7))\n",
    "        \n",
    "        axes[0, 0].set_xlabel(f'babs from BCc (Mm⁻¹)')\n",
    "        axes[0, 0].set_ylabel(f'babs from MA300 Method (Mm⁻¹)')\n",
    "        axes[0, 0].set_title(f'BCc vs MA300 Method')\n",
    "        \n",
    "        # 2. Scatter plot: BCc babs vs AE33 method\n",
    "        axes[0, 1].scatter(plot_df[babs_bcc], plot_df[babs_ae33], alpha=0.3)\n",
    "        axes[0, 1].plot([0, max_val], [0, max_val], 'k--')  # 1:1 line\n",
    "        \n",
    "        # Add regression line\n",
    "        if len(plot_df) > 1:\n",
    "            x = plot_df[babs_bcc]\n",
    "            y = plot_df[babs_ae33]\n",
    "            mask = (~np.isnan(x)) & (~np.isnan(y))\n",
    "            if mask.sum() > 1:\n",
    "                slope, intercept = np.polyfit(x[mask], y[mask], 1)\n",
    "                r_squared = np.corrcoef(x[mask], y[mask])[0, 1]**2\n",
    "                axes[0, 1].plot([0, max_val], [intercept, slope*max_val + intercept], 'r-')\n",
    "                axes[0, 1].text(0.05, 0.95, f'y = {slope:.2f}x + {intercept:.2f}\\nR² = {r_squared:.3f}',\n",
    "                             transform=axes[0, 1].transAxes, bbox=dict(facecolor='white', alpha=0.7))\n",
    "        \n",
    "        axes[0, 1].set_xlabel(f'babs from BCc (Mm⁻¹)')\n",
    "        axes[0, 1].set_ylabel(f'babs from AE33 Method (Mm⁻¹)')\n",
    "        axes[0, 1].set_title(f'BCc vs AE33 Method')\n",
    "        \n",
    "        # 3. Time series comparison\n",
    "        axes[1, 0].plot(time_series_df.index, time_series_df[babs_bcc], label='BCc')\n",
    "        axes[1, 0].plot(time_series_df.index, time_series_df[babs_ma300], label='MA300 Method')\n",
    "        axes[1, 0].plot(time_series_df.index, time_series_df[babs_ae33], label='AE33 Method')\n",
    "        axes[1, 0].set_xlabel('Time')\n",
    "        axes[1, 0].set_ylabel('babs (Mm⁻¹)')\n",
    "        axes[1, 0].set_title('Time Series Comparison')\n",
    "        axes[1, 0].legend()\n",
    "        plt.setp(axes[1, 0].xaxis.get_majorticklabels(), rotation=45)\n",
    "        \n",
    "        # 4. Distribution comparison\n",
    "        axes[1, 1].hist(plot_df[babs_bcc], bins=30, alpha=0.5, label='BCc')\n",
    "        axes[1, 1].hist(plot_df[babs_ma300], bins=30, alpha=0.5, label='MA300 Method')\n",
    "        axes[1, 1].hist(plot_df[babs_ae33], bins=30, alpha=0.5, label='AE33 Method')\n",
    "        axes[1, 1].set_xlabel('babs (Mm⁻¹)')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].set_title('Distribution Comparison')\n",
    "        axes[1, 1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'{wavelength}_method_comparison.png'), dpi=300)\n",
    "        print(f\"  Created comparison plots for {wavelength} wavelength\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error creating plots for {wavelength} wavelength: {e}\")\n",
    "    \n",
    "    plt.close(fig)\n",
    "\n",
    "def create_method_differences_summary():\n",
    "    \"\"\"Create a text summary of differences between AE33 and MA300 methods\"\"\"\n",
    "    with open(os.path.join(output_dir, 'method_differences_summary.txt'), 'w') as f:\n",
    "        f.write(\"# Key Differences Between AE33 and MA300 Methods\\n\\n\")\n",
    "        \n",
    "        f.write(\"## 1. Loading Correction Algorithm\\n\")\n",
    "        f.write(\"- AE33: Non-linear (Drinovec et al. 2015)\\n\")\n",
    "        f.write(\"- MA300: Linear (Virkkula et al. 2007)\\n\")\n",
    "        f.write(\"- Impact: The non-linear correction handles higher filter loadings better, especially during high pollution events.\\n\\n\")\n",
    "        \n",
    "        f.write(\"## 2. Multiple Scattering Correction Factor (C)\\n\")\n",
    "        f.write(\"- AE33: 1.39 for TFE-coated glass fiber filter\\n\")\n",
    "        f.write(\"- MA300: 1.3 for PTFE filter\\n\")\n",
    "        f.write(\"- Impact: ~7% difference in babs measurements due to this factor alone.\\n\\n\")\n",
    "        \n",
    "        f.write(\"## 3. Flow Compensation\\n\")\n",
    "        f.write(\"- AE33: Includes real-time flow compensation\\n\")\n",
    "        f.write(\"- MA300: Does not account for flow fluctuations\\n\")\n",
    "        f.write(\"- Impact: MA300 has higher flow variability (up to 14.2% deviation vs 3.2% for AE33), leading to increased errors.\\n\\n\")\n",
    "        \n",
    "        f.write(\"## 4. Filter Leakage\\n\")\n",
    "        f.write(\"- AE33: Includes 1% lateral filter leakage factor\\n\")\n",
    "        f.write(\"- MA300: Does not account for filter leakage\\n\")\n",
    "        f.write(\"- Impact: Small but systematic difference in measurements.\\n\\n\")\n",
    "        \n",
    "        f.write(\"## 5. Wavelength-Specific Issues\\n\")\n",
    "        f.write(\"- MA300's UV channel (375nm) shows highest variability (8%) and consistently underestimates absorption.\\n\")\n",
    "        f.write(\"- Blue channel (470nm) is more stable with 4% variability.\\n\")\n",
    "        f.write(\"- Impact: UV channel underestimation directly affects source apportionment accuracy.\\n\\n\")\n",
    "        \n",
    "        f.write(\"## 6. Filter Loading Effects\\n\")\n",
    "        f.write(\"- MA300 experiences higher filter loading per unit volume due to lower flow rate.\\n\")\n",
    "        f.write(\"- During wildfire events, the difference in loading correction becomes more significant.\\n\")\n",
    "        f.write(\"- Impact: Up to 44% difference in BC measurements during pollution events.\\n\\n\")\n",
    "        \n",
    "        f.write(\"## 7. Source Apportionment Recommendations\\n\")\n",
    "        f.write(\"- Use Blue-IR wavelength pair (470-880 nm) instead of UV-IR (375-880 nm) for source apportionment with MA300.\\n\")\n",
    "        f.write(\"- Blue-IR improves source attribution by ~10% compared to UV-IR.\\n\")\n",
    "        f.write(\"- AAE thresholds from Zotter et al. (2017): αff = 0.9, αbb = 1.75 for Blue-IR pair.\\n\\n\")\n",
    "    \n",
    "    print(\"Created method differences summary\")\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    # Set file path\n",
    "    filepath = \"/Users/ahmadjalil/Library/CloudStorage/GoogleDrive-ahzs645@gmail.com/My Drive/University/Research/Grad/UC Davis Ann/NASA MAIA/Data/Aethelometry Data/Jacros_MA350_1-min_2022-2024_Cleaned.csv\"\n",
    "    \n",
    "    # Load data\n",
    "    df = load_data(filepath)\n",
    "    \n",
    "    # Compare calculation methods\n",
    "    result_df = compare_calculation_methods(df)\n",
    "    \n",
    "    # Create method differences summary\n",
    "    create_method_differences_summary()\n",
    "    \n",
    "    print(f\"Analysis complete! Results saved to {output_dir}\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
