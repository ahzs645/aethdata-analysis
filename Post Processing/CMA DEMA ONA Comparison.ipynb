{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f137a5b8",
   "metadata": {},
   "source": [
    "# Comparative Analysis of ONA, CMA, and DEMA Algorithms for Aethalometer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ccb00",
   "metadata": {},
   "source": [
    "## 1. Introduction and Background\n",
    "\n",
    "This notebook implements and compares three post-processing algorithms for micro-aethalometer data:\n",
    "  \n",
    "1. **Optimized Noise-reduction Algorithm (ONA)**: A method described by Hagler et al. (2011) that adaptively time-averages BC data based on incremental light attenuation (ΔATN).\n",
    "\n",
    "2. **Centered Moving Average (CMA)**: A smoothing technique that incorporates data points both before and after each measurement to reduce noise while preserving microenvironmental characteristics.\n",
    "\n",
    "3. **Double Exponentially Weighted Moving Average (DEMA)**: A smoothing approach that reduces noise-induced artifacts while limiting lag, especially useful for source apportionment calculations.\n",
    " \n",
    "Both CMA and DEMA have been shown to outperform ONA for newer dual-spot aethalometers in recent research by Liu et al. (2021) and Mendoza et al. (2024).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443532bd",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a257d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8245f87",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61b46a55",
   "metadata": {},
   "source": [
    "## 3. Load and Explore the Data\n",
    " \n",
    "First, let's load the Aethalometer data and examine its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a097f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path - replace with your actual file path\n",
    "file_path = \"your_aethalometer_data.csv\"  # Replace with your file path\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(\"\\nColumn names:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "display(data.head())\n",
    "\n",
    "# Check for the presence of BC columns for each wavelength\n",
    "wavelengths = ['UV', 'Blue', 'Green', 'Red', 'IR']\n",
    "for wavelength in wavelengths:\n",
    "    bc_col = f\"{wavelength} BC1\"\n",
    "    atn_col = f\"{wavelength} ATN1\"\n",
    "    \n",
    "    if bc_col in data.columns:\n",
    "        print(f\"\\n{wavelength} wavelength data:\")\n",
    "        print(f\"  BC range: {data[bc_col].min()} to {data[bc_col].max()} ng/m³\")\n",
    "        print(f\"  Negative BC values: {(data[bc_col] < 0).sum()} ({(data[bc_col] < 0).sum() / len(data) * 100:.2f}%)\")\n",
    "        \n",
    "        if atn_col in data.columns:\n",
    "            print(f\"  ATN range: {data[atn_col].min()} to {data[atn_col].max()}\")\n",
    "    else:\n",
    "        print(f\"\\nWarning: {wavelength} data columns not found\")\n",
    "\n",
    "# Check the time resolution\n",
    "if 'Timebase (s)' in data.columns:\n",
    "    timebase = data['Timebase (s)'].iloc[0]\n",
    "    print(f\"\\nInstrument timebase: {timebase} seconds\")\n",
    "else:\n",
    "    print(\"\\nTimebase column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e31139",
   "metadata": {},
   "source": [
    "## 4. ONA Algorithm Implementation\n",
    "  \n",
    "The Optimized Noise-reduction Algorithm (ONA) adaptively time-averages BC data based on incremental light attenuation (ΔATN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161da7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ona(data, wavelength='Blue', delta_atn_min=0.05):\n",
    "    \"\"\"\n",
    "    Apply the Optimized Noise-reduction Algorithm to Aethalometer data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame containing Aethalometer data with columns for timestamp, BC, and ATN values\n",
    "    wavelength : str\n",
    "        Which wavelength to process ('UV', 'Blue', 'Green', 'Red', 'IR')\n",
    "    delta_atn_min : float\n",
    "        Minimum change in attenuation (ATN) required for averaging (default 0.05)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    data_smoothed : pandas.DataFrame\n",
    "        DataFrame with the original data plus additional columns for smoothed BC and number of points averaged\n",
    "    \"\"\"\n",
    "    # Create a copy of the input dataframe\n",
    "    data_smoothed = data.copy()\n",
    "    \n",
    "    # Add a column for number of points averaged (initially set to 1)\n",
    "    points_averaged_col = f\"{wavelength}_points_averaged\"\n",
    "    data_smoothed[points_averaged_col] = 1\n",
    "    \n",
    "    # Identify the columns for BC and ATN values based on wavelength\n",
    "    bc_col = f\"{wavelength} BC1\"  # BC1 column for this wavelength\n",
    "    atn_col = f\"{wavelength} ATN1\"  # ATN1 column for this wavelength\n",
    "    \n",
    "    # Add a column for ONA smoothed BC (initially just a copy)\n",
    "    smoothed_bc_col = f\"{wavelength}_BC_ONA\"\n",
    "    data_smoothed[smoothed_bc_col] = data_smoothed[bc_col].copy()\n",
    "    \n",
    "    # Check if ATN column exists\n",
    "    if atn_col not in data_smoothed.columns:\n",
    "        print(f\"Warning: {atn_col} column not found. ONA algorithm cannot be applied.\")\n",
    "        return data_smoothed\n",
    "    \n",
    "    # Identify filter changes (large jumps in ATN)\n",
    "    temp = np.zeros(len(data_smoothed))\n",
    "    for i in range(1, len(data_smoothed)-1):\n",
    "        temp[i] = abs(data_smoothed[atn_col].iloc[i+1] - data_smoothed[atn_col].iloc[i])\n",
    "    \n",
    "    # Find points where ATN changed drastically (filter changes)\n",
    "    # Using threshold of 30 as in the paper\n",
    "    filter_changes = np.where(np.logical_or(temp > 30, np.isnan(temp)))[0]\n",
    "    \n",
    "    # Create filtchange array with start and end points\n",
    "    if len(filter_changes) > 0:\n",
    "        filtchange = np.zeros(len(filter_changes) + 2, dtype=int)\n",
    "        filtchange[1:-1] = filter_changes\n",
    "        filtchange[-1] = len(data_smoothed)\n",
    "    else:\n",
    "        filtchange = np.array([0, len(data_smoothed)], dtype=int)\n",
    "    \n",
    "    print(f\"Number of filter changes detected for {wavelength}: {len(filter_changes)}\")\n",
    "    \n",
    "    # Process each segment between filter changes\n",
    "    for k in range(len(filtchange) - 1):\n",
    "        j = filtchange[k] + 1  # Set to first point after filter change\n",
    "        \n",
    "        while j < filtchange[k+1]:\n",
    "            # Current ATN value\n",
    "            current_atn = data_smoothed[atn_col].iloc[j]\n",
    "            \n",
    "            # Find points where ATN increases by at most delta_atn_min\n",
    "            end_idx = filtchange[k+1]\n",
    "            search_range = data_smoothed[atn_col].iloc[j+1:end_idx]\n",
    "            \n",
    "            if len(search_range) > 0:\n",
    "                # Find points where ATN <= current_atn + delta_atn_min\n",
    "                des_ind = np.where(search_range <= current_atn + delta_atn_min)[0]\n",
    "                \n",
    "                if len(des_ind) > 0:\n",
    "                    # Calculate range of points to average\n",
    "                    end_j = min(j + des_ind[-1] + 1, len(data_smoothed))\n",
    "                    \n",
    "                    # Check that j < end_j and there is data to average\n",
    "                    if j < end_j:\n",
    "                        # Get the data slice\n",
    "                        bc_slice = data_smoothed[bc_col].iloc[j:end_j]\n",
    "                        \n",
    "                        # Check if there is valid data to average\n",
    "                        if len(bc_slice) > 0 and not bc_slice.isna().all():\n",
    "                            # Calculate smoothed BC by averaging over the window\n",
    "                            avg_bc = np.nanmean(bc_slice)\n",
    "                            \n",
    "                            # Apply the averaged BC value to all points in the window - using loc\n",
    "                            row_indices = data_smoothed.index[j:end_j]\n",
    "                            data_smoothed.loc[row_indices, smoothed_bc_col] = avg_bc\n",
    "                            \n",
    "                            # Record number of points used in averaging - using loc\n",
    "                            data_smoothed.loc[row_indices, points_averaged_col] = end_j - j\n",
    "                        \n",
    "                    # Move j to next position after the current window\n",
    "                    j = end_j\n",
    "                else:\n",
    "                    # If no suitable points found, move to next point\n",
    "                    j += 1\n",
    "            else:\n",
    "                # If at the end of the data segment, move to next point\n",
    "                j += 1\n",
    "    \n",
    "    return data_smoothed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d81bd7",
   "metadata": {},
   "source": [
    "## 5. CMA Algorithm Implementation\n",
    "  \n",
    "The Centered Moving Average is a smoothing technique that uses data points both before and after each measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cma(data, wavelength='Blue', window_size=None):\n",
    "    \"\"\"\n",
    "    Apply the Centered Moving Average algorithm to Aethalometer data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame containing Aethalometer data\n",
    "    wavelength : str\n",
    "        Which wavelength to process ('UV', 'Blue', 'Green', 'Red', 'IR')\n",
    "    window_size : int or None\n",
    "        Size of the moving average window (must be odd). If None, \n",
    "        will use a default based on the data's timebase\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    data_smoothed : pandas.DataFrame\n",
    "        DataFrame with the original data plus additional columns for smoothed BC\n",
    "    \"\"\"\n",
    "    # Create a copy of the input dataframe\n",
    "    data_smoothed = data.copy()\n",
    "    \n",
    "    # Identify the column for BC values based on wavelength\n",
    "    bc_col = f\"{wavelength} BC1\"\n",
    "    \n",
    "    # Determine window size if not specified\n",
    "    if window_size is None:\n",
    "        if 'Timebase (s)' in data.columns:\n",
    "            timebase = data['Timebase (s)'].iloc[0]\n",
    "            if timebase == 1:\n",
    "                window_size = 11  # 11 seconds for 1-second data\n",
    "            elif timebase == 5:\n",
    "                window_size = 5   # 25 seconds for 5-second data\n",
    "            elif timebase == 60:\n",
    "                window_size = 3   # 3 minutes for 1-minute data\n",
    "            else:\n",
    "                window_size = 5   # Default for other timebases\n",
    "        else:\n",
    "            window_size = 5       # Default if timebase is unknown\n",
    "    \n",
    "    # Make sure window_size is odd\n",
    "    if window_size % 2 == 0:\n",
    "        window_size += 1\n",
    "    \n",
    "    print(f\"Using window size of {window_size} for CMA on {wavelength}\")\n",
    "    \n",
    "    # Add columns for CMA results\n",
    "    smoothed_bc_col = f\"{wavelength}_BC_CMA\"\n",
    "    data_smoothed[smoothed_bc_col] = data_smoothed[bc_col].rolling(\n",
    "        window=window_size, center=True, min_periods=1\n",
    "    ).mean()\n",
    "    \n",
    "    return data_smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf1b11",
   "metadata": {},
   "source": [
    "## 6. DEMA Algorithm Implementation\n",
    " \n",
    "The Double Exponentially Weighted Moving Average applies additional smoothing to an EMA to reduce noise while limiting lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dema(data, wavelength='Blue', alpha=None):\n",
    "    \"\"\"\n",
    "    Apply the Double Exponentially Weighted Moving Average algorithm to Aethalometer data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame containing Aethalometer data\n",
    "    wavelength : str\n",
    "        Which wavelength to process ('UV', 'Blue', 'Green', 'Red', 'IR')\n",
    "    alpha : float\n",
    "        Smoothing parameter (between 0 and 1)\n",
    "        For 60s data, 0.125 approximates a 15-minute smoothing window\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    data_smoothed : pandas.DataFrame\n",
    "        DataFrame with the original data plus additional columns for smoothed BC\n",
    "    \"\"\"\n",
    "    # Create a copy of the input dataframe\n",
    "    data_smoothed = data.copy()\n",
    "    \n",
    "    # Identify the column for BC values based on wavelength\n",
    "    bc_col = f\"{wavelength} BC1\"\n",
    "    \n",
    "    # Set the smoothing parameter based on timebase if not explicitly provided\n",
    "    if 'Timebase (s)' in data.columns:\n",
    "        timebase = data['Timebase (s)'].iloc[0]\n",
    "        if alpha is None:\n",
    "            # Use formula 2/(N+1) where N is the desired smoothing period\n",
    "            if timebase == 1:\n",
    "                # Default to approximate 5-minute window for 1-second data\n",
    "                N = 300 / timebase\n",
    "            elif timebase == 5:\n",
    "                # Default to approximate 5-minute window for 5-second data\n",
    "                N = 300 / timebase\n",
    "            elif timebase == 60:\n",
    "                # Default to approximate 15-minute window for 60-second data\n",
    "                N = 900 / timebase\n",
    "            else:\n",
    "                N = 15  # Default for other timebases\n",
    "                \n",
    "            alpha = 2 / (N + 1)\n",
    "    else:\n",
    "        # Default alpha if timebase is unknown\n",
    "        if alpha is None:\n",
    "            alpha = 0.125\n",
    "    \n",
    "    print(f\"Using alpha of {alpha:.4f} for DEMA on {wavelength}\")\n",
    "    \n",
    "    # Calculate EMA\n",
    "    ema_col = f\"{wavelength}_EMA\"\n",
    "    # First EMA\n",
    "    data_smoothed[ema_col] = data_smoothed[bc_col].ewm(alpha=alpha, adjust=False).mean()\n",
    "    \n",
    "    # Calculate DEMA: (2 * EMA) - EMA(EMA)\n",
    "    dema_col = f\"{wavelength}_BC_DEMA\"\n",
    "    ema_of_ema = data_smoothed[ema_col].ewm(alpha=alpha, adjust=False).mean()\n",
    "    data_smoothed[dema_col] = (2 * data_smoothed[ema_col]) - ema_of_ema\n",
    "    \n",
    "    return data_smoothed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ece6cc",
   "metadata": {},
   "source": [
    "## 7. Apply All Processing Methods to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate dataframes for each method\n",
    "processed_data_raw = data.copy()\n",
    "processed_data_ona = data.copy()\n",
    "processed_data_cma = data.copy()\n",
    "processed_data_dema = data.copy()\n",
    "\n",
    "# Set the minimum change in attenuation (ΔATN) for ONA\n",
    "delta_atn_min = 0.05  # Default value from the Hagler paper\n",
    "\n",
    "# Process each wavelength with all methods\n",
    "for wavelength in wavelengths:\n",
    "    bc_col = f\"{wavelength} BC1\"\n",
    "    atn_col = f\"{wavelength} ATN1\"\n",
    "    \n",
    "    if bc_col in processed_data_raw.columns:\n",
    "        # Apply ONA if ATN column exists\n",
    "        if atn_col in processed_data_raw.columns:\n",
    "            print(f\"\\nApplying ONA to {wavelength} wavelength data...\")\n",
    "            processed_data_ona = apply_ona(processed_data_ona, wavelength, delta_atn_min)\n",
    "        \n",
    "        # Apply CMA\n",
    "        print(f\"\\nApplying CMA to {wavelength} wavelength data...\")\n",
    "        processed_data_cma = apply_cma(processed_data_cma, wavelength)\n",
    "        \n",
    "        # Apply DEMA\n",
    "        print(f\"\\nApplying DEMA to {wavelength} wavelength data...\")\n",
    "        processed_data_dema = apply_dema(processed_data_dema, wavelength)\n",
    "\n",
    "# Apply Source Apportionment for all methods\n",
    "# This step will be included in a separate section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf216d13",
   "metadata": {},
   "source": [
    "## 8. Calculate Source Apportionment\n",
    " \n",
    "Following the recommendations from recent research, we'll implement source apportionment calculations using the Aethalometer model for each processing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c121a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_source_apportionment(data, aae_wb=2.0, aae_ff=1.0):\n",
    "    \"\"\"\n",
    "    Calculate source apportionment using the Aethalometer Model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame with BC data at blue and IR wavelengths\n",
    "    aae_wb : float\n",
    "        Absorption Ångström Exponent for wood burning (default 2.0)\n",
    "    aae_ff : float\n",
    "        Absorption Ångström Exponent for fossil fuel (default 1.0)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    data_sa : pandas.DataFrame\n",
    "        DataFrame with additional source apportionment columns\n",
    "    \"\"\"\n",
    "    # Create a copy of the input dataframe\n",
    "    data_sa = data.copy()\n",
    "    \n",
    "    # Get BC values at blue and IR wavelengths (raw data)\n",
    "    bc_blue = data_sa['Blue BC1']\n",
    "    bc_ir = data_sa['IR BC1']\n",
    "    \n",
    "    # Calculate absorption coefficients\n",
    "    # For simplicity, using approximate MACs and Cref values from literature\n",
    "    mac_blue = 10.12  # m²/g at 470nm\n",
    "    mac_ir = 7.77     # m²/g at 880nm\n",
    "    c_ref = 1.3       # Multiple scattering enhancement factor\n",
    "    \n",
    "    babs_blue = bc_blue * mac_blue / c_ref\n",
    "    babs_ir = bc_ir * mac_ir / c_ref\n",
    "    \n",
    "    # Calculate the ratio of wavelengths for the Aethalometer model\n",
    "    wavelength_ratio = 470 / 880\n",
    "    \n",
    "    # Calculate absorption coefficients for wood burning and fossil fuel at IR wavelength\n",
    "    # Using the Aethalometer model equations\n",
    "    babs_ff_ir = (babs_blue - babs_ir * (wavelength_ratio ** (-aae_wb))) / \\\n",
    "                 ((wavelength_ratio ** (-aae_ff)) - (wavelength_ratio ** (-aae_wb)))\n",
    "                 \n",
    "    babs_wb_ir = babs_ir - babs_ff_ir\n",
    "    \n",
    "    # Calculate BB% (biomass burning percentage)\n",
    "    bb_percent = 100 * babs_wb_ir / babs_ir\n",
    "    \n",
    "    # Handle infinity and NaN values\n",
    "    bb_percent = bb_percent.replace([np.inf, -np.inf], np.nan)\n",
    "    bb_percent = bb_percent.fillna(0)\n",
    "    \n",
    "    # Store results\n",
    "    data_sa['Babs_Blue'] = babs_blue\n",
    "    data_sa['Babs_IR'] = babs_ir\n",
    "    data_sa['Babs_FF_IR'] = babs_ff_ir\n",
    "    data_sa['Babs_WB_IR'] = babs_wb_ir\n",
    "    data_sa['BB_Percent'] = bb_percent\n",
    "    \n",
    "    # Calculate BC from wood burning and fossil fuel\n",
    "    data_sa['BC_WB'] = bc_ir * bb_percent / 100\n",
    "    data_sa['BC_FF'] = bc_ir * (100 - bb_percent) / 100\n",
    "    \n",
    "    return data_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77794de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dema_to_source_apportionment(data, alpha=0.125):\n",
    "    \"\"\"\n",
    "    Apply DEMA specifically to source apportionment results\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame with source apportionment data\n",
    "    alpha : float\n",
    "        Smoothing parameter\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    data_smoothed : pandas.DataFrame\n",
    "        DataFrame with smoothed source apportionment data\n",
    "    \"\"\"\n",
    "    # Create a copy of the input dataframe\n",
    "    data_smoothed = data.copy()\n",
    "    \n",
    "    # Apply DEMA to BB_Percent\n",
    "    if 'BB_Percent' in data_smoothed.columns:\n",
    "        # First EMA\n",
    "        data_smoothed['BB_Percent_EMA'] = data_smoothed['BB_Percent'].ewm(alpha=alpha, adjust=False).mean()\n",
    "        \n",
    "        # Calculate DEMA\n",
    "        ema_of_ema = data_smoothed['BB_Percent_EMA'].ewm(alpha=alpha, adjust=False).mean()\n",
    "        data_smoothed['BB_Percent_DEMA'] = (2 * data_smoothed['BB_Percent_EMA']) - ema_of_ema\n",
    "        \n",
    "        # Limit BB% to logical range [0, 100]\n",
    "        data_smoothed['BB_Percent_DEMA'] = data_smoothed['BB_Percent_DEMA'].clip(0, 100)\n",
    "        \n",
    "        # Recalculate BC_WB and BC_FF using smoothed BB_Percent\n",
    "        if 'IR_BC_CMA' in data_smoothed.columns:\n",
    "            bc_ir = data_smoothed['IR_BC_CMA']\n",
    "        elif 'IR_BC_DEMA' in data_smoothed.columns:\n",
    "            bc_ir = data_smoothed['IR_BC_DEMA']\n",
    "        elif 'IR_BC_ONA' in data_smoothed.columns:\n",
    "            bc_ir = data_smoothed['IR_BC_ONA']\n",
    "        else:\n",
    "            bc_ir = data_smoothed['IR BC1']\n",
    "            \n",
    "        data_smoothed['BC_WB_DEMA'] = bc_ir * data_smoothed['BB_Percent_DEMA'] / 100\n",
    "        data_smoothed['BC_FF_DEMA'] = bc_ir * (100 - data_smoothed['BB_Percent_DEMA']) / 100\n",
    "    \n",
    "    return data_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e1cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate source apportionment for raw data\n",
    "print(\"\\nCalculating source apportionment for raw data...\")\n",
    "processed_data_raw_sa = calculate_source_apportionment(processed_data_raw)\n",
    "\n",
    "# Calculate source apportionment for ONA-processed data\n",
    "if 'Blue_BC_ONA' in processed_data_ona.columns and 'IR_BC_ONA' in processed_data_ona.columns:\n",
    "    print(\"\\nCalculating source apportionment for ONA-processed data...\")\n",
    "    processed_data_ona_sa = processed_data_ona.copy()\n",
    "    # Use the ONA-processed data for source apportionment\n",
    "    processed_data_ona_sa['Blue BC1'] = processed_data_ona['Blue_BC_ONA']\n",
    "    processed_data_ona_sa['IR BC1'] = processed_data_ona['IR_BC_ONA']\n",
    "    processed_data_ona_sa = calculate_source_apportionment(processed_data_ona_sa)\n",
    "else:\n",
    "    processed_data_ona_sa = processed_data_raw_sa.copy()\n",
    "    print(\"\\nWarning: ONA-processed data not available for both Blue and IR wavelengths, using raw data for source apportionment\")\n",
    "\n",
    "# Calculate source apportionment for CMA-processed data\n",
    "print(\"\\nCalculating source apportionment for CMA-processed data...\")\n",
    "processed_data_cma_sa = processed_data_cma.copy()\n",
    "# Use the CMA-processed data for source apportionment\n",
    "processed_data_cma_sa['Blue BC1'] = processed_data_cma['Blue_BC_CMA']\n",
    "processed_data_cma_sa['IR BC1'] = processed_data_cma['IR_BC_CMA']\n",
    "processed_data_cma_sa = calculate_source_apportionment(processed_data_cma_sa)\n",
    "\n",
    "# Calculate source apportionment for DEMA-processed data\n",
    "print(\"\\nCalculating source apportionment for DEMA-processed data...\")\n",
    "processed_data_dema_sa = processed_data_dema.copy()\n",
    "# Use the DEMA-processed data for source apportionment\n",
    "processed_data_dema_sa['Blue BC1'] = processed_data_dema['Blue_BC_DEMA']\n",
    "processed_data_dema_sa['IR BC1'] = processed_data_dema['IR_BC_DEMA'] \n",
    "processed_data_dema_sa = calculate_source_apportionment(processed_data_dema_sa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2033deb5",
   "metadata": {},
   "source": [
    "## 9. Evaluate Processing Performance\n",
    "  \n",
    "Now let's evaluate how well each processing method performed and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fc9c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_processing(data_raw, data_processed, raw_col, processed_col):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a processing algorithm\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_raw : pandas.DataFrame\n",
    "        DataFrame with original data\n",
    "    data_processed : pandas.DataFrame\n",
    "        DataFrame with processed data\n",
    "    raw_col : str\n",
    "        Column name for raw data\n",
    "    processed_col : str\n",
    "        Column name for processed data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    metrics : dict\n",
    "        Dictionary of performance metrics\n",
    "    \"\"\"\n",
    "    # 1. Reduction of negatives\n",
    "    numneg_raw = (data_raw[raw_col] < 0).sum() / len(data_raw)\n",
    "    numneg_processed = (data_processed[processed_col] < 0).sum() / len(data_processed)\n",
    "    \n",
    "    print(f\"Fraction of negative values in raw data: {numneg_raw:.4f}\")\n",
    "    print(f\"Fraction of negative values after processing: {numneg_processed:.4f}\")\n",
    "    print(f\"Reduction in negative values: {(numneg_raw - numneg_processed)/numneg_raw:.4f} ({(numneg_raw - numneg_processed)/numneg_raw*100:.1f}%)\")\n",
    "    \n",
    "    # 2. Reduction of noise (average absolute difference between consecutive points)\n",
    "    temp_raw = np.zeros(len(data_raw)-1)\n",
    "    temp_processed = np.zeros(len(data_processed)-1)\n",
    "    \n",
    "    for i in range(len(data_raw)-1):\n",
    "        temp_raw[i] = abs(data_raw[raw_col].iloc[i+1] - data_raw[raw_col].iloc[i])\n",
    "        temp_processed[i] = abs(data_processed[processed_col].iloc[i+1] - data_processed[processed_col].iloc[i])\n",
    "    \n",
    "    noise_raw = np.nanmean(temp_raw)\n",
    "    noise_processed = np.nanmean(temp_processed)\n",
    "    \n",
    "    print(f\"Noise in raw data: {noise_raw:.1f} ng/m³\")\n",
    "    print(f\"Noise in processed data: {noise_processed:.1f} ng/m³\")\n",
    "    print(f\"Noise reduction factor: {noise_raw/noise_processed:.1f}x\")\n",
    "    \n",
    "    # 3. Calculate correlation with raw data\n",
    "    correlation = data_raw[raw_col].corr(data_processed[processed_col])\n",
    "    print(f\"Correlation with raw data: {correlation:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'negative_original': numneg_raw,\n",
    "        'negative_processed': numneg_processed,\n",
    "        'negative_reduction': (numneg_raw - numneg_processed)/numneg_raw if numneg_raw > 0 else 0,\n",
    "        'noise_original': noise_raw,\n",
    "        'noise_processed': noise_processed,\n",
    "        'noise_reduction': noise_raw/noise_processed,\n",
    "        'correlation': correlation\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91bd0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each wavelength and method\n",
    "summary_metrics = {}\n",
    "\n",
    "for wavelength in ['Blue', 'IR']:\n",
    "    bc_col = f\"{wavelength} BC1\"\n",
    "    ona_col = f\"{wavelength}_BC_ONA\"\n",
    "    cma_col = f\"{wavelength}_BC_CMA\"\n",
    "    dema_col = f\"{wavelength}_BC_DEMA\"\n",
    "    \n",
    "    if bc_col in data.columns:\n",
    "        print(f\"\\n===== Performance Evaluation for {wavelength} Wavelength =====\")\n",
    "        \n",
    "        # Evaluate ONA if available\n",
    "        if ona_col in processed_data_ona.columns:\n",
    "            print(f\"\\nEvaluating ONA for {wavelength} wavelength:\")\n",
    "            summary_metrics[f\"{wavelength}_ONA\"] = evaluate_processing(data, processed_data_ona, bc_col, ona_col)\n",
    "        \n",
    "        # Evaluate CMA\n",
    "        print(f\"\\nEvaluating CMA for {wavelength} wavelength:\")\n",
    "        summary_metrics[f\"{wavelength}_CMA\"] = evaluate_processing(data, processed_data_cma, bc_col, cma_col)\n",
    "        \n",
    "        # Evaluate DEMA\n",
    "        print(f\"\\nEvaluating DEMA for {wavelength} wavelength:\")\n",
    "        summary_metrics[f\"{wavelength}_DEMA\"] = evaluate_processing(data, processed_data_dema, bc_col, dema_col)\n",
    "\n",
    "# Create a summary table\n",
    "summary_table = pd.DataFrame.from_dict(summary_metrics, orient='index')\n",
    "summary_table.columns = [\n",
    "    'Negative values (original)',\n",
    "    'Negative values (processed)', \n",
    "    'Negative reduction',\n",
    "    'Noise (original ng/m³)', \n",
    "    'Noise (processed ng/m³)',\n",
    "    'Noise reduction factor',\n",
    "    'Correlation with raw'\n",
    "]\n",
    "\n",
    "# Display the summary table\n",
    "print(\"\\n===== Summary of Method Performance =====\")\n",
    "display(summary_table)\n",
    "\n",
    "# Compare Source Apportionment Results\n",
    "print(\"\\n===== Source Apportionment Comparison =====\")\n",
    "print(\"\\nComparison of BB% from Raw, ONA, CMA and DEMA processing:\")\n",
    "print(f\"Raw data - Mean BB%: {processed_data_raw_sa['BB_Percent'].mean():.2f}, Std: {processed_data_raw_sa['BB_Percent'].std():.2f}\")\n",
    "\n",
    "if 'BB_Percent' in processed_data_ona_sa.columns:\n",
    "    print(f\"ONA data - Mean BB%: {processed_data_ona_sa['BB_Percent'].mean():.2f}, Std: {processed_data_ona_sa['BB_Percent'].std():.2f}\")\n",
    "\n",
    "print(f\"CMA data - Mean BB%: {processed_data_cma_sa['BB_Percent'].mean():.2f}, Std: {processed_data_cma_sa['BB_Percent'].std():.2f}\")\n",
    "print(f\"DEMA data - Mean BB%: {processed_data_dema_sa['BB_Percent'].mean():.2f}, Std: {processed_data_dema_sa['BB_Percent'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e360693a",
   "metadata": {},
   "source": [
    "## 10. Visualize Results\n",
    "  \n",
    "Let's visualize the raw and processed data to see the effects of our algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d21c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(data, data_ona, data_cma, data_dema, wavelength, sample_period=None):\n",
    "    \"\"\"\n",
    "    Plot the raw, ONA, CMA, and DEMA processed BC data for comparison\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame with raw data\n",
    "    data_ona : pandas.DataFrame\n",
    "        DataFrame with ONA processed data\n",
    "    data_cma : pandas.DataFrame\n",
    "        DataFrame with CMA processed data\n",
    "    data_dema : pandas.DataFrame\n",
    "        DataFrame with DEMA processed data\n",
    "    wavelength : str\n",
    "        Which wavelength to plot\n",
    "    sample_period : tuple, optional\n",
    "        Start and end indices for a subset of the data to plot\n",
    "    \"\"\"\n",
    "    # Identify columns\n",
    "    bc_col = f\"{wavelength} BC1\"\n",
    "    ona_col = f\"{wavelength}_BC_ONA\"\n",
    "    cma_col = f\"{wavelength}_BC_CMA\"\n",
    "    dema_col = f\"{wavelength}_BC_DEMA\"\n",
    "    \n",
    "    # Check which methods are available\n",
    "    methods_available = []\n",
    "    if bc_col in data.columns:\n",
    "        methods_available.append(('Raw', data, bc_col, 'k-'))\n",
    "    if ona_col in data_ona.columns:\n",
    "        methods_available.append(('ONA', data_ona, ona_col, 'b-'))\n",
    "    if cma_col in data_cma.columns:\n",
    "        methods_available.append(('CMA', data_cma, cma_col, 'r-'))\n",
    "    if dema_col in data_dema.columns:\n",
    "        methods_available.append(('DEMA', data_dema, dema_col, 'g-'))\n",
    "    \n",
    "    # Select a subset of data if specified\n",
    "    if sample_period is not None:\n",
    "        start_idx, end_idx = sample_period\n",
    "        plot_datas = []\n",
    "        for name, df, col, style in methods_available:\n",
    "            plot_datas.append((name, df.iloc[start_idx:end_idx].copy(), col, style))\n",
    "    else:\n",
    "        plot_datas = methods_available\n",
    "    \n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Create x-axis values\n",
    "    if len(plot_datas) > 0 and 'Time (UTC)' in plot_datas[0][1].columns:\n",
    "        try:\n",
    "            x = pd.to_datetime(plot_datas[0][1]['Time (UTC)'])\n",
    "            x_formatter = mdates.DateFormatter('%H:%M')\n",
    "            plt.gca().xaxis.set_major_formatter(x_formatter)\n",
    "            plt.gcf().autofmt_xdate()\n",
    "            x_label = 'Time (UTC)'\n",
    "        except:\n",
    "            x = np.arange(len(plot_datas[0][1]))\n",
    "            x_label = 'Data Point'\n",
    "    else:\n",
    "        x = np.arange(len(plot_datas[0][1]) if len(plot_datas) > 0 else 0)\n",
    "        x_label = 'Data Point'\n",
    "    \n",
    "    # Plot BC data for each method\n",
    "    for name, df, col, style in plot_datas:\n",
    "        if name == 'Raw':\n",
    "            plt.plot(x, df[col], style, alpha=0.5, label=name)\n",
    "        else:\n",
    "            plt.plot(x, df[col], style, label=name)\n",
    "    \n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(f'{wavelength} BC (ng/m³)')\n",
    "    plt.title(f'Comparison of Noise Reduction Methods for {wavelength} Wavelength')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4856f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_source_apportionment_comparison(data_raw, data_ona, data_cma, data_dema, sample_period=None):\n",
    "    \"\"\"\n",
    "    Plot the source apportionment results for raw, ONA, CMA and DEMA data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_raw : pandas.DataFrame\n",
    "        DataFrame with raw source apportionment data\n",
    "    data_ona : pandas.DataFrame\n",
    "        DataFrame with ONA processed source apportionment data\n",
    "    data_cma : pandas.DataFrame\n",
    "        DataFrame with CMA processed source apportionment data\n",
    "    data_dema : pandas.DataFrame\n",
    "        DataFrame with DEMA processed source apportionment data\n",
    "    sample_period : tuple, optional\n",
    "        Start and end indices for a subset of the data to plot\n",
    "    \"\"\"\n",
    "    # Check which methods have source apportionment data\n",
    "    methods_available = []\n",
    "    if 'BB_Percent' in data_raw.columns:\n",
    "        methods_available.append(('Raw', data_raw, 'BB_Percent', 'k-'))\n",
    "    if 'BB_Percent' in data_ona.columns:\n",
    "        methods_available.append(('ONA', data_ona, 'BB_Percent', 'b-'))\n",
    "    if 'BB_Percent' in data_cma.columns:\n",
    "        methods_available.append(('CMA', data_cma, 'BB_Percent', 'r-'))\n",
    "    if 'BB_Percent' in data_dema.columns:\n",
    "        methods_available.append(('DEMA', data_dema, 'BB_Percent', 'g-'))\n",
    "    \n",
    "    # Select a subset of data if specified\n",
    "    if sample_period is not None:\n",
    "        start_idx, end_idx = sample_period\n",
    "        plot_datas = []\n",
    "        for name, df, col, style in methods_available:\n",
    "            plot_datas.append((name, df.iloc[start_idx:end_idx].copy(), col, style))\n",
    "    else:\n",
    "        plot_datas = methods_available\n",
    "    \n",
    "    # Create a figure with three subplots\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 12), sharex=True)\n",
    "    \n",
    "    # Create x-axis values\n",
    "    if len(plot_datas) > 0 and 'Time (UTC)' in plot_datas[0][1].columns:\n",
    "        try:\n",
    "            x = pd.to_datetime(plot_datas[0][1]['Time (UTC)'])\n",
    "            x_formatter = mdates.DateFormatter('%H:%M')\n",
    "            x_label = 'Time (UTC)'\n",
    "            for ax in axes:\n",
    "                ax.xaxis.set_major_formatter(x_formatter)\n",
    "            fig.autofmt_xdate()\n",
    "        except:\n",
    "            x = np.arange(len(plot_datas[0][1]))\n",
    "            x_label = 'Data Point'\n",
    "    else:\n",
    "        x = np.arange(len(plot_datas[0][1]) if len(plot_datas) > 0 else 0)\n",
    "        x_label = 'Data Point'\n",
    "    \n",
    "    # Plot BB percentage for each method\n",
    "    for name, df, col, style in plot_datas:\n",
    "        if name == 'Raw':\n",
    "            axes[0].plot(x, df[col], style, alpha=0.5, label=name)\n",
    "        else:\n",
    "            axes[0].plot(x, df[col], style, label=name)\n",
    "    \n",
    "    axes[0].set_ylabel('Biomass Burning %')\n",
    "    axes[0].set_title('Source Apportionment Results Comparison')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot Wood Burning BC for each method\n",
    "    for name, df, style in [(name, df, style) for name, df, col, style in plot_datas]:\n",
    "        if 'BC_WB' in df.columns:\n",
    "            if name == 'Raw':\n",
    "                axes[1].plot(x, df['BC_WB'], style, alpha=0.5, label=name)\n",
    "            else:\n",
    "                axes[1].plot(x, df['BC_WB'], style, label=name)\n",
    "    \n",
    "    axes[1].set_ylabel('Wood Burning BC (ng/m³)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot Fossil Fuel BC for each method\n",
    "    for name, df, style in [(name, df, style) for name, df, col, style in plot_datas]:\n",
    "        if 'BC_FF' in df.columns:\n",
    "            if name == 'Raw':\n",
    "                axes[2].plot(x, df['BC_FF'], style, alpha=0.5, label=name)\n",
    "            else:\n",
    "                axes[2].plot(x, df['BC_FF'], style, label=name)\n",
    "    \n",
    "    axes[2].set_ylabel('Fossil Fuel BC (ng/m³)')\n",
    "    axes[2].set_xlabel(x_label)\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d472a",
   "metadata": {},
   "source": [
    "# Let's plot the comparison of all methods for each wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeb3292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison for each wavelength\n",
    "for wavelength in ['Blue', 'IR']:\n",
    "    bc_col = f\"{wavelength} BC1\"\n",
    "    ona_col = f\"{wavelength}_BC_ONA\"\n",
    "    cma_col = f\"{wavelength}_BC_CMA\"\n",
    "    dema_col = f\"{wavelength}_BC_DEMA\"\n",
    "    \n",
    "    if bc_col in data.columns:\n",
    "        print(f\"\\nPlots for {wavelength} wavelength comparison:\")\n",
    "        \n",
    "        # Plot full dataset\n",
    "        plot_comparison(data, processed_data_ona, processed_data_cma, processed_data_dema, wavelength)\n",
    "        \n",
    "        # Plot a sample period (first 1000 points or 10% of data, whichever is smaller)\n",
    "        sample_size = min(1000, int(len(data) * 0.1))\n",
    "        if sample_size < len(data):\n",
    "            print(f\"\\nZoomed view of first {sample_size} points:\")\n",
    "            plot_comparison(data, processed_data_ona, processed_data_cma, processed_data_dema, wavelength, (0, sample_size))\n",
    "\n",
    "# Plot source apportionment comparisons\n",
    "print(\"\\nSource apportionment comparison plots:\")\n",
    "plot_source_apportionment_comparison(processed_data_raw_sa, processed_data_ona_sa, processed_data_cma_sa, processed_data_dema_sa)\n",
    "\n",
    "# Plot a sample period\n",
    "sample_size = min(1000, int(len(data) * 0.1))\n",
    "if sample_size < len(data):\n",
    "    print(f\"\\nZoomed view of first {sample_size} points:\")\n",
    "    plot_source_apportionment_comparison(processed_data_raw_sa, processed_data_ona_sa, processed_data_cma_sa, processed_data_dema_sa, (0, sample_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c6b78",
   "metadata": {},
   "source": [
    "## 11. Side-by-Side Visualization Comparison\n",
    "  \n",
    "Now let's create a side-by-side comparison of all methods for easier visual comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_side_by_side_comparison(data, data_ona, data_cma, data_dema, wavelength='Blue', sample_period=None, timebase=60):\n",
    "    \"\"\"\n",
    "    Plot raw, ONA, CMA, and DEMA processed BC data in a side-by-side grid layout\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame with raw data\n",
    "    data_ona : pandas.DataFrame\n",
    "        DataFrame with ONA processed data\n",
    "    data_cma : pandas.DataFrame\n",
    "        DataFrame with CMA processed data\n",
    "    data_dema : pandas.DataFrame\n",
    "        DataFrame with DEMA processed data\n",
    "    wavelength : str\n",
    "        Which wavelength to plot\n",
    "    sample_period : tuple, optional\n",
    "        Start and end indices for a subset of the data to plot\n",
    "    timebase : int\n",
    "        The timebase in seconds (5, 10, 30, 60, etc.)\n",
    "    \"\"\"\n",
    "    # Identify columns\n",
    "    bc_col = f\"{wavelength} BC1\"\n",
    "    ona_col = f\"{wavelength}_BC_ONA\"\n",
    "    cma_col = f\"{wavelength}_BC_CMA\"\n",
    "    dema_col = f\"{wavelength}_BC_DEMA\"\n",
    "    \n",
    "    # Determine which methods are available\n",
    "    methods = []\n",
    "    if bc_col in data.columns:\n",
    "        methods.append(('Raw', data, bc_col))\n",
    "    if ona_col in data_ona.columns:\n",
    "        methods.append(('ONA', data_ona, ona_col))\n",
    "    if cma_col in data_cma.columns:\n",
    "        methods.append(('CMA', data_cma, cma_col))\n",
    "    if dema_col in data_dema.columns:\n",
    "        methods.append(('DEMA', data_dema, dema_col))\n",
    "    \n",
    "    # Select a subset of data if specified\n",
    "    if sample_period is not None:\n",
    "        start_idx, end_idx = sample_period\n",
    "        plot_methods = []\n",
    "        for name, df, col in methods:\n",
    "            plot_methods.append((name, df.iloc[start_idx:end_idx].copy(), col))\n",
    "    else:\n",
    "        plot_methods = methods\n",
    "    \n",
    "    # Determine number of panels needed (number of methods + 1 for comparison)\n",
    "    n_methods = len(plot_methods)\n",
    "    if n_methods < 2:\n",
    "        print(\"Not enough methods to compare\")\n",
    "        return\n",
    "    \n",
    "    # Calculate grid dimensions (approximately square)\n",
    "    n_rows = int(np.ceil(np.sqrt(n_methods + 1)))\n",
    "    n_cols = int(np.ceil((n_methods + 1) / n_rows))\n",
    "    \n",
    "    # Create a figure with a grid of subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*5, n_rows*4), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()  # Flatten for easier indexing\n",
    "    \n",
    "    # Create x-axis values\n",
    "    if 'Time (UTC)' in plot_methods[0][1].columns:\n",
    "        try:\n",
    "            x = pd.to_datetime(plot_methods[0][1]['Time (UTC)'])\n",
    "            x_formatter = mdates.DateFormatter('%H:%M')\n",
    "            x_label = 'Time (UTC)'\n",
    "            for ax in axes:\n",
    "                ax.xaxis.set_major_formatter(x_formatter)\n",
    "            fig.autofmt_xdate()\n",
    "        except:\n",
    "            x = np.arange(len(plot_methods[0][1]))\n",
    "            x_label = 'Data Point'\n",
    "    else:\n",
    "        x = np.arange(len(plot_methods[0][1]))\n",
    "        x_label = 'Data Point'\n",
    "    \n",
    "    # Set y-limits for consistent comparison\n",
    "    all_y_values = []\n",
    "    for name, plot_data, col in plot_methods:\n",
    "        values = plot_data[col].dropna()\n",
    "        if len(values) > 0:\n",
    "            all_y_values.extend(values)\n",
    "    \n",
    "    if all_y_values:\n",
    "        ymin = np.percentile(all_y_values, 1)  # 1st percentile to avoid extreme outliers\n",
    "        ymax = np.percentile(all_y_values, 99)  # 99th percentile to avoid extreme outliers\n",
    "        # Add a small buffer to the y-limits for visual clarity\n",
    "        y_buffer = (ymax - ymin) * 0.1\n",
    "        ylim = (ymin - y_buffer, ymax + y_buffer)\n",
    "    else:\n",
    "        ylim = (0, 1)  # Default if no valid values\n",
    "    \n",
    "    # Plot titles and data for individual methods\n",
    "    for i, (name, plot_data, col) in enumerate(plot_methods):\n",
    "        title = f'{name} processed ({timebase}s)'\n",
    "        if name == 'Raw':\n",
    "            title = f'Raw data ({timebase}s)'\n",
    "            axes[i].plot(x, plot_data[col], 'k-', label=name)\n",
    "        elif name == 'ONA':\n",
    "            axes[i].plot(x, plot_data[col], 'b-', label=name)\n",
    "        elif name == 'CMA':\n",
    "            axes[i].plot(x, plot_data[col], 'r-', label=name)\n",
    "        elif name == 'DEMA':\n",
    "            axes[i].plot(x, plot_data[col], 'g-', label=name)\n",
    "        \n",
    "        axes[i].set_title(title)\n",
    "        axes[i].set_ylabel(f'{wavelength} BC (ng/m³)')\n",
    "        axes[i].set_ylim(ylim)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot all methods for comparison in the last panel\n",
    "    for name, plot_data, col in plot_methods:\n",
    "        if name == 'Raw':\n",
    "            axes[-1].plot(x, plot_data[col], 'k-', alpha=0.5, label=name)\n",
    "        elif name == 'ONA':\n",
    "            axes[-1].plot(x, plot_data[col], 'b-', label=name)\n",
    "        elif name == 'CMA':\n",
    "            axes[-1].plot(x, plot_data[col], 'r-', label=name)\n",
    "        elif name == 'DEMA':\n",
    "            axes[-1].plot(x, plot_data[col], 'g-', label=name)\n",
    "    \n",
    "    axes[-1].set_title('All methods comparison')\n",
    "    axes[-1].set_ylabel(f'{wavelength} BC (ng/m³)')\n",
    "    axes[-1].set_xlabel(x_label)\n",
    "    axes[-1].set_ylim(ylim)\n",
    "    axes[-1].grid(True, alpha=0.3)\n",
    "    axes[-1].legend()\n",
    "    \n",
    "    # Hide any extra subplots\n",
    "    for i in range(n_methods + 1, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'Side-by-Side Comparison of Processing Methods ({wavelength} Wavelength)', y=1.02, fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121e2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_source_apportionment_side_by_side(data_raw, data_ona, data_cma, data_dema, sample_period=None, timebase=60):\n",
    "    \"\"\"\n",
    "    Plot source apportionment results in a side-by-side grid layout\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_raw : pandas.DataFrame\n",
    "        DataFrame with raw source apportionment data\n",
    "    data_ona : pandas.DataFrame\n",
    "        DataFrame with ONA processed source apportionment data\n",
    "    data_cma : pandas.DataFrame\n",
    "        DataFrame with CMA processed source apportionment data\n",
    "    data_dema : pandas.DataFrame\n",
    "        DataFrame with DEMA processed source apportionment data\n",
    "    sample_period : tuple, optional\n",
    "        Start and end indices for a subset of the data to plot\n",
    "    timebase : int\n",
    "        The timebase in seconds (5, 10, 30, 60, etc.)\n",
    "    \"\"\"\n",
    "    # Determine which methods have source apportionment data\n",
    "    methods = []\n",
    "    if 'BB_Percent' in data_raw.columns:\n",
    "        methods.append(('Raw', data_raw))\n",
    "    if 'BB_Percent' in data_ona.columns:\n",
    "        methods.append(('ONA', data_ona))\n",
    "    if 'BB_Percent' in data_cma.columns:\n",
    "        methods.append(('CMA', data_cma))\n",
    "    if 'BB_Percent' in data_dema.columns:\n",
    "        methods.append(('DEMA', data_dema))\n",
    "    \n",
    "    # Select a subset of data if specified\n",
    "    if sample_period is not None:\n",
    "        start_idx, end_idx = sample_period\n",
    "        plot_methods = []\n",
    "        for name, df in methods:\n",
    "            plot_methods.append((name, df.iloc[start_idx:end_idx].copy()))\n",
    "    else:\n",
    "        plot_methods = methods\n",
    "    \n",
    "    # Determine number of panels needed (number of methods + 1 for comparison)\n",
    "    n_methods = len(plot_methods)\n",
    "    if n_methods < 2:\n",
    "        print(\"Not enough methods to compare\")\n",
    "        return\n",
    "    \n",
    "    # Calculate grid dimensions (approximately square)\n",
    "    n_rows = int(np.ceil(np.sqrt(n_methods + 1)))\n",
    "    n_cols = int(np.ceil((n_methods + 1) / n_rows))\n",
    "    \n",
    "    # Create a figure with a grid of subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*5, n_rows*4), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()  # Flatten for easier indexing\n",
    "    \n",
    "    # Create x-axis values\n",
    "    if 'Time (UTC)' in plot_methods[0][1].columns:\n",
    "        try:\n",
    "            x = pd.to_datetime(plot_methods[0][1]['Time (UTC)'])\n",
    "            x_formatter = mdates.DateFormatter('%H:%M')\n",
    "            x_label = 'Time (UTC)'\n",
    "            for ax in axes:\n",
    "                ax.xaxis.set_major_formatter(x_formatter)\n",
    "            fig.autofmt_xdate()\n",
    "        except:\n",
    "            x = np.arange(len(plot_methods[0][1]))\n",
    "            x_label = 'Data Point'\n",
    "    else:\n",
    "        x = np.arange(len(plot_methods[0][1]))\n",
    "        x_label = 'Data Point'\n",
    "    \n",
    "    # Set y-limits for BB percentage for consistent comparison\n",
    "    all_bb_values = []\n",
    "    for name, plot_data in plot_methods:\n",
    "        values = plot_data['BB_Percent'].dropna()\n",
    "        if len(values) > 0:\n",
    "            all_bb_values.extend(values)\n",
    "    \n",
    "    if all_bb_values:\n",
    "        ymin_bb = max(0, np.percentile(all_bb_values, 1))  # 1st percentile to avoid extreme outliers, but not below 0\n",
    "        ymax_bb = min(100, np.percentile(all_bb_values, 99))  # 99th percentile to avoid extreme outliers, but not above 100\n",
    "        # Add a small buffer to the y-limits for visual clarity\n",
    "        y_buffer_bb = (ymax_bb - ymin_bb) * 0.1\n",
    "        ylim_bb = (max(0, ymin_bb - y_buffer_bb), min(100, ymax_bb + y_buffer_bb))\n",
    "    else:\n",
    "        ylim_bb = (0, 100)  # Default range for BB%\n",
    "    \n",
    "    # Plot titles and data for individual methods\n",
    "    for i, (name, plot_data) in enumerate(plot_methods):\n",
    "        title = f'{name} processed ({timebase}s)'\n",
    "        if name == 'Raw':\n",
    "            title = f'Raw data ({timebase}s)'\n",
    "            axes[i].plot(x, plot_data['BB_Percent'], 'k-', label=name)\n",
    "        elif name == 'ONA':\n",
    "            axes[i].plot(x, plot_data['BB_Percent'], 'b-', label=name)\n",
    "        elif name == 'CMA':\n",
    "            axes[i].plot(x, plot_data['BB_Percent'], 'r-', label=name)\n",
    "        elif name == 'DEMA':\n",
    "            axes[i].plot(x, plot_data['BB_Percent'], 'g-', label=name)\n",
    "        \n",
    "        axes[i].set_title(title)\n",
    "        axes[i].set_ylabel('Biomass Burning %')\n",
    "        axes[i].set_ylim(ylim_bb)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot all methods for comparison in the last panel\n",
    "    for name, plot_data in plot_methods:\n",
    "        if name == 'Raw':\n",
    "            axes[-1].plot(x, plot_data['BB_Percent'], 'k-', alpha=0.5, label=name)\n",
    "        elif name == 'ONA':\n",
    "            axes[-1].plot(x, plot_data['BB_Percent'], 'b-', label=name)\n",
    "        elif name == 'CMA':\n",
    "            axes[-1].plot(x, plot_data['BB_Percent'], 'r-', label=name)\n",
    "        elif name == 'DEMA':\n",
    "            axes[-1].plot(x, plot_data['BB_Percent'], 'g-', label=name)\n",
    "    \n",
    "    axes[-1].set_title('All methods comparison')\n",
    "    axes[-1].set_ylabel('Biomass Burning %')\n",
    "    axes[-1].set_xlabel(x_label)\n",
    "    axes[-1].set_ylim(ylim_bb)\n",
    "    axes[-1].grid(True, alpha=0.3)\n",
    "    axes[-1].legend()\n",
    "    \n",
    "    # Hide any extra subplots\n",
    "    for i in range(n_methods + 1, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    if x_label == 'Time (UTC)':\n",
    "        fig.autofmt_xdate()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Side-by-Side Comparison of Source Apportionment Results', y=1.02, fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167cc0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the timebase from the data\n",
    "if 'Timebase (s)' in data.columns:\n",
    "    timebase = data['Timebase (s)'].iloc[0]\n",
    "else:\n",
    "    timebase = 60  # default assumption\n",
    "\n",
    "# Plot side-by-side comparison for each wavelength\n",
    "for wavelength in ['Blue', 'IR']:\n",
    "    bc_col = f\"{wavelength} BC1\"\n",
    "    \n",
    "    if bc_col in data.columns:\n",
    "        print(f\"\\nSide-by-side comparison for {wavelength} wavelength:\")\n",
    "        \n",
    "        # Plot full dataset\n",
    "        plot_side_by_side_comparison(data, processed_data_ona, processed_data_cma, processed_data_dema, \n",
    "                                  wavelength, timebase=timebase)\n",
    "        \n",
    "        # Plot a sample period (first 1000 points or 10% of data, whichever is smaller)\n",
    "        sample_size = min(1000, int(len(data) * 0.1))\n",
    "        if sample_size < len(data):\n",
    "            print(f\"\\nZoomed view of first {sample_size} points:\")\n",
    "            plot_side_by_side_comparison(data, processed_data_ona, processed_data_cma, processed_data_dema, \n",
    "                                      wavelength, (0, sample_size), timebase=timebase)\n",
    "\n",
    "# Plot source apportionment comparisons\n",
    "print(\"\\nSide-by-side source apportionment comparison:\")\n",
    "plot_source_apportionment_side_by_side(processed_data_raw_sa, processed_data_ona_sa, processed_data_cma_sa, \n",
    "                                     processed_data_dema_sa, timebase=timebase)\n",
    "\n",
    "# Plot a sample period for source apportionment\n",
    "sample_size = min(1000, int(len(data) * 0.1))\n",
    "if sample_size < len(data):\n",
    "    print(f\"\\nZoomed view of first {sample_size} points for source apportionment:\")\n",
    "    plot_source_apportionment_side_by_side(processed_data_raw_sa, processed_data_ona_sa, processed_data_cma_sa, \n",
    "                                        processed_data_dema_sa, (0, sample_size), timebase=timebase)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaf5fdc",
   "metadata": {},
   "source": [
    "## 12. Stacked Temporal Comparison\n",
    "  \n",
    "Let's also create a visualization that stacks the temporal plots vertically for each processing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368bc580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_temporal_comparison(data, data_ona, data_cma, data_dema, wavelength='Blue', sample_period=None):\n",
    "    \"\"\"\n",
    "    Plot stacked temporal comparison of raw, ONA, CMA, and DEMA processed BC data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame with raw data\n",
    "    data_ona : pandas.DataFrame\n",
    "        DataFrame with ONA processed data\n",
    "    data_cma : pandas.DataFrame\n",
    "        DataFrame with CMA processed data\n",
    "    data_dema : pandas.DataFrame\n",
    "        DataFrame with DEMA processed data\n",
    "    wavelength : str\n",
    "        Which wavelength to plot\n",
    "    sample_period : tuple, optional\n",
    "        Start and end indices for a subset of the data to plot\n",
    "    \"\"\"\n",
    "    # Identify columns\n",
    "    bc_col = f\"{wavelength} BC1\"\n",
    "    ona_col = f\"{wavelength}_BC_ONA\"\n",
    "    cma_col = f\"{wavelength}_BC_CMA\"\n",
    "    dema_col = f\"{wavelength}_BC_DEMA\"\n",
    "    \n",
    "    # Determine which methods are available\n",
    "    methods = []\n",
    "    if bc_col in data.columns:\n",
    "        methods.append(('Raw', data, bc_col))\n",
    "    if ona_col in data_ona.columns:\n",
    "        methods.append(('ONA', data_ona, ona_col))\n",
    "    if cma_col in data_cma.columns:\n",
    "        methods.append(('CMA', data_cma, cma_col))\n",
    "    if dema_col in data_dema.columns:\n",
    "        methods.append(('DEMA', data_dema, dema_col))\n",
    "    \n",
    "    # Select a subset of data if specified\n",
    "    if sample_period is not None:\n",
    "        start_idx, end_idx = sample_period\n",
    "        plot_methods = []\n",
    "        for name, df, col in methods:\n",
    "            plot_methods.append((name, df.iloc[start_idx:end_idx].copy(), col))\n",
    "    else:\n",
    "        plot_methods = methods\n",
    "    \n",
    "    # Determine number of panels needed\n",
    "    n_methods = len(plot_methods)\n",
    "    if n_methods < 2:\n",
    "        print(\"Not enough methods to compare\")\n",
    "        return\n",
    "    \n",
    "    # Create a figure with vertically stacked subplots\n",
    "    fig, axes = plt.subplots(n_methods, 1, figsize=(12, n_methods*3), sharex=True)\n",
    "    if n_methods == 1:\n",
    "        axes = [axes]  # Make it a list for consistent indexing\n",
    "    \n",
    "    # Determine the timebase\n",
    "    if 'Timebase (s)' in plot_methods[0][1].columns:\n",
    "        timebase = plot_methods[0][1]['Timebase (s)'].iloc[0]\n",
    "    else:\n",
    "        timebase = 60  # default\n",
    "    \n",
    "    # Create x-axis values\n",
    "    if 'Time (UTC)' in plot_methods[0][1].columns:\n",
    "        try:\n",
    "            x = pd.to_datetime(plot_methods[0][1]['Time (UTC)'])\n",
    "            x_formatter = mdates.DateFormatter('%H:%M')\n",
    "            x_label = 'Time (UTC)'\n",
    "            for ax in axes:\n",
    "                ax.xaxis.set_major_formatter(x_formatter)\n",
    "            fig.autofmt_xdate()\n",
    "        except:\n",
    "            x = np.arange(len(plot_methods[0][1]))\n",
    "            x_label = 'Data Point'\n",
    "    else:\n",
    "        x = np.arange(len(plot_methods[0][1]))\n",
    "        x_label = 'Data Point'\n",
    "    \n",
    "    # Set y-limits for consistent comparison\n",
    "    all_y_values = []\n",
    "    for name, plot_data, col in plot_methods:\n",
    "        values = plot_data[col].dropna()\n",
    "        if len(values) > 0:\n",
    "            all_y_values.extend(values)\n",
    "    \n",
    "    if all_y_values:\n",
    "        ymin = np.percentile(all_y_values, 1)  # 1st percentile to avoid extreme outliers\n",
    "        ymax = np.percentile(all_y_values, 99)  # 99th percentile to avoid extreme outliers\n",
    "        # Ensure min and max are different to prevent division by zero\n",
    "        if ymin == ymax:\n",
    "            ymin -= 10\n",
    "            ymax += 10\n",
    "            \n",
    "        y_buffer = (ymax - ymin) * 0.1\n",
    "        ylim = (ymin - y_buffer, ymax + y_buffer)\n",
    "    else:\n",
    "        ylim = (0, 1)  # Default if no valid values\n",
    "    \n",
    "    # Plot data for each method\n",
    "    for i, (name, plot_data, col) in enumerate(plot_methods):\n",
    "        if name == 'Raw':\n",
    "            axes[i].plot(x, plot_data[col], 'k-', label=f'Raw ({timebase}s)')\n",
    "        elif name == 'ONA':\n",
    "            axes[i].plot(x, plot_data[col], 'b-', label=f'ONA ({timebase}s)')\n",
    "        elif name == 'CMA':\n",
    "            axes[i].plot(x, plot_data[col], 'r-', label=f'CMA ({timebase}s)')\n",
    "        elif name == 'DEMA':\n",
    "            axes[i].plot(x, plot_data[col], 'g-', label=f'DEMA ({timebase}s)')\n",
    "        \n",
    "        axes[i].set_ylabel(f'{wavelength} BC (ng/m³)')\n",
    "        axes[i].legend(loc='upper right')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        axes[i].set_ylim(ylim)\n",
    "    \n",
    "    axes[-1].set_xlabel(x_label)\n",
    "    plt.suptitle(f'Stacked Temporal Comparison ({wavelength} Wavelength)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)  # Adjust for suptitle\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45460f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_source_apportionment(data_raw, data_ona, data_cma, data_dema, sample_period=None):\n",
    "    \"\"\"\n",
    "    Plot stacked temporal comparison of source apportionment results\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_raw : pandas.DataFrame\n",
    "        DataFrame with raw source apportionment data\n",
    "    data_ona : pandas.DataFrame\n",
    "        DataFrame with ONA processed source apportionment data\n",
    "    data_cma : pandas.DataFrame\n",
    "        DataFrame with CMA processed source apportionment data\n",
    "    data_dema : pandas.DataFrame\n",
    "        DataFrame with DEMA processed source apportionment data\n",
    "    sample_period : tuple, optional\n",
    "        Start and end indices for a subset of the data to plot\n",
    "    \"\"\"\n",
    "    # Determine which methods have source apportionment data\n",
    "    methods = []\n",
    "    if 'BB_Percent' in data_raw.columns:\n",
    "        methods.append(('Raw', data_raw))\n",
    "    if 'BB_Percent' in data_ona.columns:\n",
    "        methods.append(('ONA', data_ona))\n",
    "    if 'BB_Percent' in data_cma.columns:\n",
    "        methods.append(('CMA', data_cma))\n",
    "    if 'BB_Percent' in data_dema.columns:\n",
    "        methods.append(('DEMA', data_dema))\n",
    "    \n",
    "    # Select a subset of data if specified\n",
    "    if sample_period is not None:\n",
    "        start_idx, end_idx = sample_period\n",
    "        plot_methods = []\n",
    "        for name, df in methods:\n",
    "            plot_methods.append((name, df.iloc[start_idx:end_idx].copy()))\n",
    "    else:\n",
    "        plot_methods = methods\n",
    "    \n",
    "    # Determine number of panels needed\n",
    "    n_methods = len(plot_methods)\n",
    "    if n_methods < 2:\n",
    "        print(\"Not enough methods to compare\")\n",
    "        return\n",
    "    \n",
    "    # Create a figure with vertically stacked subplots\n",
    "    fig, axes = plt.subplots(n_methods, 1, figsize=(12, n_methods*3), sharex=True)\n",
    "    if n_methods == 1:\n",
    "        axes = [axes]  # Make it a list for consistent indexing\n",
    "    \n",
    "    # Determine the timebase\n",
    "    if 'Timebase (s)' in plot_methods[0][1].columns:\n",
    "        timebase = plot_methods[0][1]['Timebase (s)'].iloc[0]\n",
    "    else:\n",
    "        timebase = 60  # default\n",
    "    \n",
    "    # Create x-axis values\n",
    "    if 'Time (UTC)' in plot_methods[0][1].columns:\n",
    "        try:\n",
    "            x = pd.to_datetime(plot_methods[0][1]['Time (UTC)'])\n",
    "            x_formatter = mdates.DateFormatter('%H:%M')\n",
    "            x_label = 'Time (UTC)'\n",
    "            for ax in axes:\n",
    "                ax.xaxis.set_major_formatter(x_formatter)\n",
    "            fig.autofmt_xdate()\n",
    "        except:\n",
    "            x = np.arange(len(plot_methods[0][1]))\n",
    "            x_label = 'Data Point'\n",
    "    else:\n",
    "        x = np.arange(len(plot_methods[0][1]))\n",
    "        x_label = 'Data Point'\n",
    "    \n",
    "    # Set y-limits for BB percentage for consistent comparison\n",
    "    all_y_values = []\n",
    "    for name, plot_data in plot_methods:\n",
    "        values = plot_data['BB_Percent'].dropna()\n",
    "        if len(values) > 0:\n",
    "            all_y_values.extend(values)\n",
    "    \n",
    "    if all_y_values:\n",
    "        ymin = max(0, np.percentile(all_y_values, 1))  # 1st percentile but not below 0\n",
    "        ymax = min(100, np.percentile(all_y_values, 99))  # 99th percentile but not above 100\n",
    "        \n",
    "        # Ensure min and max are different to prevent division by zero\n",
    "        if ymin == ymax:\n",
    "            if ymin == 0:\n",
    "                ymax = 10  # If all zeros, set max to 10%\n",
    "            elif ymax == 100:\n",
    "                ymin = 90  # If all 100s, set min to 90%\n",
    "            else:\n",
    "                # Otherwise add/subtract 5 percentage points\n",
    "                ymin = max(0, ymin - 5)\n",
    "                ymax = min(100, ymax + 5)\n",
    "            \n",
    "        y_buffer = (ymax - ymin) * 0.1\n",
    "        ylim = (max(0, ymin - y_buffer), min(100, ymax + y_buffer))\n",
    "    else:\n",
    "        ylim = (0, 100)  # Default range for BB%\n",
    "    \n",
    "    # Plot data for each method\n",
    "    for i, (name, plot_data) in enumerate(plot_methods):\n",
    "        if name == 'Raw':\n",
    "            axes[i].plot(x, plot_data['BB_Percent'], 'k-', label=f'Raw ({timebase}s)')\n",
    "        elif name == 'ONA':\n",
    "            axes[i].plot(x, plot_data['BB_Percent'], 'b-', label=f'ONA ({timebase}s)')\n",
    "        elif name == 'CMA':\n",
    "            axes[i].plot(x, plot_data['BB_Percent'], 'r-', label=f'CMA ({timebase}s)')\n",
    "        elif name == 'DEMA':\n",
    "            axes[i].plot(x, plot_data['BB_Percent'], 'g-', label=f'DEMA ({timebase}s)')\n",
    "        \n",
    "        axes[i].set_ylabel('Biomass Burning %')\n",
    "        axes[i].legend(loc='upper right')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        axes[i].set_ylim(ylim)\n",
    "    \n",
    "    axes[-1].set_xlabel(x_label)\n",
    "    plt.suptitle('Stacked Temporal Comparison of Source Apportionment Results', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)  # Adjust for suptitle\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455481de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stacked temporal comparison for each wavelength\n",
    "for wavelength in ['Blue', 'IR']:\n",
    "    bc_col = f\"{wavelength} BC1\"\n",
    "    ona_col = f\"{wavelength}_BC_ONA\"\n",
    "    cma_col = f\"{wavelength}_BC_CMA\"\n",
    "    dema_col = f\"{wavelength}_BC_DEMA\"\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    methods_available = []\n",
    "    if bc_col in data.columns:\n",
    "        methods_available.append('Raw')\n",
    "    if ona_col in processed_data_ona.columns:\n",
    "        methods_available.append('ONA')\n",
    "    if cma_col in processed_data_cma.columns:\n",
    "        methods_available.append('CMA')\n",
    "    if dema_col in processed_data_dema.columns:\n",
    "        methods_available.append('DEMA')\n",
    "    \n",
    "    # Only proceed if at least two methods are available\n",
    "    if len(methods_available) >= 2:\n",
    "        print(f\"\\nStacked temporal comparison for {wavelength} wavelength:\")\n",
    "        \n",
    "        # Plot full dataset\n",
    "        plot_stacked_temporal_comparison(data, processed_data_ona, processed_data_cma, processed_data_dema, wavelength)\n",
    "        \n",
    "        # Plot a sample period (first 1000 points or 10% of data, whichever is smaller)\n",
    "        sample_size = min(1000, int(len(data) * 0.1))\n",
    "        if sample_size < len(data):\n",
    "            print(f\"\\nZoomed view of first {sample_size} points:\")\n",
    "            plot_stacked_temporal_comparison(data, processed_data_ona, processed_data_cma, processed_data_dema, \n",
    "                                          wavelength, (0, sample_size))\n",
    "\n",
    "# Plot stacked source apportionment comparisons\n",
    "# Check if source apportionment data is available for at least two methods\n",
    "sa_methods_available = []\n",
    "if 'BB_Percent' in processed_data_raw_sa.columns:\n",
    "    sa_methods_available.append('Raw')\n",
    "if 'BB_Percent' in processed_data_ona_sa.columns:\n",
    "    sa_methods_available.append('ONA')\n",
    "if 'BB_Percent' in processed_data_cma_sa.columns:\n",
    "    sa_methods_available.append('CMA')\n",
    "if 'BB_Percent' in processed_data_dema_sa.columns:\n",
    "    sa_methods_available.append('DEMA')\n",
    "\n",
    "if len(sa_methods_available) >= 2:\n",
    "    print(\"\\nStacked source apportionment comparison:\")\n",
    "    plot_stacked_source_apportionment(processed_data_raw_sa, processed_data_ona_sa, processed_data_cma_sa, processed_data_dema_sa)\n",
    "\n",
    "    # Plot a sample period for source apportionment\n",
    "    sample_size = min(1000, int(len(data) * 0.1))\n",
    "    if sample_size < len(data):\n",
    "        print(f\"\\nZoomed view of first {sample_size} points for source apportionment:\")\n",
    "        plot_stacked_source_apportionment(processed_data_raw_sa, processed_data_ona_sa, processed_data_cma_sa, \n",
    "                                       processed_data_dema_sa, (0, sample_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ed3568",
   "metadata": {},
   "source": [
    "## 13. Time Averaging Analysis\n",
    " \n",
    "Let's analyze the time averaging behavior of the ONA method and compare it to the effective averaging window of the CMA and DEMA methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b5c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_time_averaging(data_ona, data_cma, data_dema, wavelength='Blue'):\n",
    "    \"\"\"\n",
    "    Analyze and compare the time averaging behavior of each method\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_ona : pandas.DataFrame\n",
    "        DataFrame with ONA processed data\n",
    "    data_cma : pandas.DataFrame\n",
    "        DataFrame with CMA processed data\n",
    "    data_dema : pandas.DataFrame\n",
    "        DataFrame with DEMA processed data\n",
    "    wavelength : str\n",
    "        Which wavelength to analyze\n",
    "    \"\"\"\n",
    "    # Check which methods are available\n",
    "    methods = []\n",
    "    \n",
    "    # For ONA, check if points_averaged column exists\n",
    "    points_averaged_col = f\"{wavelength}_points_averaged\"\n",
    "    if points_averaged_col in data_ona.columns:\n",
    "        # ONA explicit averaging window\n",
    "        methods.append(('ONA', data_ona[points_averaged_col]))\n",
    "    \n",
    "    # For CMA, we know the window size\n",
    "    if f\"{wavelength}_BC_CMA\" in data_cma.columns:\n",
    "        # Get the fixed window size for CMA\n",
    "        if 'Timebase (s)' in data_cma.columns:\n",
    "            timebase = data_cma['Timebase (s)'].iloc[0]\n",
    "            if timebase == 1:\n",
    "                cma_window = 11  # 11 seconds for 1-second data\n",
    "            elif timebase == 5:\n",
    "                cma_window = 5   # 25 seconds for 5-second data\n",
    "            elif timebase == 60:\n",
    "                cma_window = 3   # 3 minutes for 1-minute data\n",
    "            else:\n",
    "                cma_window = 5   # Default for other timebases\n",
    "        else:\n",
    "            cma_window = 5       # Default if timebase is unknown\n",
    "        \n",
    "        # Make sure window_size is odd\n",
    "        if cma_window % 2 == 0:\n",
    "            cma_window += 1\n",
    "            \n",
    "        # Create a Series with the fixed window size\n",
    "        cma_points = pd.Series([cma_window] * len(data_cma))\n",
    "        methods.append(('CMA', cma_points))\n",
    "    \n",
    "    # For DEMA, calculate the equivalent window size based on alpha\n",
    "    if f\"{wavelength}_BC_DEMA\" in data_dema.columns:\n",
    "        # Calculate equivalent window size from alpha\n",
    "        # For DEMA with alpha, N = 2/alpha - 1\n",
    "        if 'Timebase (s)' in data_dema.columns:\n",
    "            timebase = data_dema['Timebase (s)'].iloc[0]\n",
    "            \n",
    "            # Default alphas based on timebase\n",
    "            if timebase == 1:\n",
    "                alpha = 2 / (300 / timebase + 1)  # ~5-minute window for 1-second data\n",
    "            elif timebase == 5:\n",
    "                alpha = 2 / (300 / timebase + 1)  # ~5-minute window for 5-second data\n",
    "            elif timebase == 60:\n",
    "                alpha = 2 / (900 / timebase + 1)  # ~15-minute window for 60-second data\n",
    "            else:\n",
    "                alpha = 0.125  # Default\n",
    "            \n",
    "            # Equivalent window size for DEMA\n",
    "            dema_equiv_window = int(2/alpha - 1)\n",
    "            dema_points = pd.Series([dema_equiv_window] * len(data_dema))\n",
    "            methods.append(('DEMA', dema_points))\n",
    "    \n",
    "    if len(methods) == 0:\n",
    "        print(\"No time averaging data available for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot histograms for each method on the same plot\n",
    "    for name, points in methods:\n",
    "        if name == 'ONA':\n",
    "            plt.hist(points, bins=30, alpha=0.7, label=f'ONA (adaptive, mean={points.mean():.1f})')\n",
    "        elif name == 'CMA':\n",
    "            plt.hist(points, bins=30, alpha=0.7, label=f'CMA (fixed, window={cma_window})')\n",
    "        elif name == 'DEMA':\n",
    "            plt.hist(points, bins=30, alpha=0.7, label=f'DEMA (equiv. window={dema_equiv_window})')\n",
    "    \n",
    "    plt.xlabel('Number of Points Averaged')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of Averaging Window Size - {wavelength} Wavelength')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a table with summary statistics\n",
    "    summary_stats = {}\n",
    "    for name, points in methods:\n",
    "        summary_stats[name] = {\n",
    "            'Mean': points.mean(),\n",
    "            'Median': points.median(),\n",
    "            'Min': points.min(),\n",
    "            'Max': points.max(),\n",
    "            'Std Dev': points.std()\n",
    "        }\n",
    "    \n",
    "    # Convert to DataFrame for display\n",
    "    summary_df = pd.DataFrame.from_dict(summary_stats, orient='index')\n",
    "    print(f\"\\nSummary statistics of window sizes for {wavelength} wavelength:\")\n",
    "    display(summary_df)\n",
    "    \n",
    "    # If ONA is available, plot ECDF\n",
    "    ona_points = None\n",
    "    for name, points in methods:\n",
    "        if name == 'ONA':\n",
    "            ona_points = points\n",
    "            break\n",
    "    \n",
    "    if ona_points is not None:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Calculate ECDF\n",
    "        x = np.sort(ona_points)\n",
    "        y = np.arange(1, len(x) + 1) / len(x)\n",
    "        \n",
    "        # Plot ECDF\n",
    "        plt.semilogx(x, y)\n",
    "        plt.xlabel('Number of Points Averaged')\n",
    "        plt.ylabel('Fraction of Time Series ≤ Points')\n",
    "        plt.title(f'ECDF of ONA Adaptive Window Size - {wavelength} Wavelength')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d423267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze time averaging for each wavelength\n",
    "for wavelength in ['Blue', 'IR']:\n",
    "    print(f\"\\nTime averaging analysis for {wavelength} wavelength:\")\n",
    "    analyze_time_averaging(processed_data_ona, processed_data_cma, processed_data_dema, wavelength)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d1f112",
   "metadata": {},
   "source": [
    "## 14. Comparing Signal Preservation\n",
    "\n",
    "Let's examine how well each method preserves important signal features by looking at cross-correlation and lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf3591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_signal_preservation(data_raw, data_ona, data_cma, data_dema, wavelength='Blue'):\n",
    "    \"\"\"\n",
    "    Analyze how well each method preserves important signal features\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_raw : pandas.DataFrame\n",
    "        DataFrame with raw data\n",
    "    data_ona : pandas.DataFrame\n",
    "        DataFrame with ONA processed data\n",
    "    data_cma : pandas.DataFrame\n",
    "        DataFrame with CMA processed data\n",
    "    data_dema : pandas.DataFrame\n",
    "        DataFrame with DEMA processed data\n",
    "    wavelength : str\n",
    "        Which wavelength to analyze\n",
    "    \"\"\"\n",
    "    # Identify columns\n",
    "    bc_col = f\"{wavelength} BC1\"\n",
    "    ona_col = f\"{wavelength}_BC_ONA\"\n",
    "    cma_col = f\"{wavelength}_BC_CMA\"\n",
    "    dema_col = f\"{wavelength}_BC_DEMA\"\n",
    "    \n",
    "    # Check which methods are available\n",
    "    methods = []\n",
    "    if bc_col in data_raw.columns:\n",
    "        raw_data = data_raw[bc_col].copy()\n",
    "        if ona_col in data_ona.columns:\n",
    "            methods.append(('ONA', data_ona[ona_col]))\n",
    "        if cma_col in data_cma.columns:\n",
    "            methods.append(('CMA', data_cma[cma_col]))\n",
    "        if dema_col in data_dema.columns:\n",
    "            methods.append(('DEMA', data_dema[dema_col]))\n",
    "    else:\n",
    "        print(f\"Raw data for {wavelength} wavelength not available\")\n",
    "        return\n",
    "    \n",
    "    if len(methods) == 0:\n",
    "        print(\"No processed data available for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Calculate cross-correlation and find peak for each method\n",
    "    results = {}\n",
    "    lags = {}\n",
    "    peak_corrs = {}\n",
    "    \n",
    "    max_lag = 20  # Maximum lag to consider (in data points)\n",
    "    \n",
    "    for name, processed_data in methods:\n",
    "        # Calculate cross-correlation\n",
    "        # First, standardize the data\n",
    "        raw_std = (raw_data - raw_data.mean()) / raw_data.std()\n",
    "        processed_std = (processed_data - processed_data.mean()) / processed_data.std()\n",
    "        \n",
    "        # Calculate cross-correlation with different lags\n",
    "        xcorr = np.correlate(raw_std.fillna(0), processed_std.fillna(0), mode='full')\n",
    "        \n",
    "        # Calculate the midpoint\n",
    "        mid = len(xcorr) // 2\n",
    "        \n",
    "        # Extract the central portion of the cross-correlation\n",
    "        lag_range = max_lag * 2 + 1\n",
    "        central_xcorr = xcorr[mid - max_lag:mid + max_lag + 1]\n",
    "        lags_array = np.arange(-max_lag, max_lag + 1)\n",
    "        \n",
    "        # Find the peak correlation and its lag\n",
    "        peak_idx = np.argmax(central_xcorr)\n",
    "        peak_lag = lags_array[peak_idx]\n",
    "        peak_corr = central_xcorr[peak_idx]\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'xcorr': central_xcorr,\n",
    "            'lags': lags_array\n",
    "        }\n",
    "        lags[name] = peak_lag\n",
    "        peak_corrs[name] = peak_corr\n",
    "    \n",
    "    # Plot cross-correlation for each method\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for name, result in results.items():\n",
    "        if name == 'ONA':\n",
    "            plt.plot(result['lags'], result['xcorr'], 'b-', label=f'ONA (lag={lags[name]})')\n",
    "        elif name == 'CMA':\n",
    "            plt.plot(result['lags'], result['xcorr'], 'r-', label=f'CMA (lag={lags[name]})')\n",
    "        elif name == 'DEMA':\n",
    "            plt.plot(result['lags'], result['xcorr'], 'g-', label=f'DEMA (lag={lags[name]})')\n",
    "    \n",
    "    plt.axvline(x=0, color='k', linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Lag (data points)')\n",
    "    plt.ylabel('Cross-Correlation')\n",
    "    plt.title(f'Cross-Correlation with Raw Data - {wavelength} Wavelength')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display results in a table\n",
    "    summary = {}\n",
    "    for name in results.keys():\n",
    "        summary[name] = {\n",
    "            'Lag (data points)': lags[name],\n",
    "            'Peak Correlation': peak_corrs[name]\n",
    "        }\n",
    "    \n",
    "    # Convert to DataFrame for display\n",
    "    summary_df = pd.DataFrame.from_dict(summary, orient='index')\n",
    "    print(f\"\\nSignal preservation metrics for {wavelength} wavelength:\")\n",
    "    display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c1042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze signal preservation for each wavelength\n",
    "for wavelength in ['Blue', 'IR']:\n",
    "    print(f\"\\nSignal preservation analysis for {wavelength} wavelength:\")\n",
    "    analyze_signal_preservation(data, processed_data_ona, processed_data_cma, processed_data_dema, wavelength)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea62ea5e",
   "metadata": {},
   "source": [
    "## 15. Comparative Analysis Summary\n",
    " \n",
    "Now let's summarize the performance of all three methods across key metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad8b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_method_comparison_table():\n",
    "    \"\"\"\n",
    "    Create a comprehensive comparison table for all three methods\n",
    "    \"\"\"\n",
    "    # Gather all metrics for comparison\n",
    "    comparison = {\n",
    "        'Metric': [\n",
    "            'Negative Value Reduction', \n",
    "            'Noise Reduction Factor', \n",
    "            'Correlation with Raw Data',\n",
    "            'Signal Preservation (Lag)',\n",
    "            'Time Averaging Behavior',\n",
    "            'Source Apportionment Stability',\n",
    "            'Computational Complexity'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Add columns for each method\n",
    "    methods = ['ONA', 'CMA', 'DEMA']\n",
    "    for method in methods:\n",
    "        comparison[method] = [\n",
    "            # To be filled with actual values where available\n",
    "            'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A'\n",
    "        ]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    comparison_df = pd.DataFrame(comparison)\n",
    "    comparison_df.set_index('Metric', inplace=True)\n",
    "    \n",
    "    # Fill in values from summary_table where available\n",
    "    if 'summary_table' in globals():\n",
    "        # Negative Value Reduction\n",
    "        for method in methods:\n",
    "            for wavelength in ['Blue', 'IR']:\n",
    "                key = f\"{wavelength}_{method}\"\n",
    "                if key in summary_table.index:\n",
    "                    if comparison_df.loc['Negative Value Reduction', method] == 'N/A':\n",
    "                        comparison_df.loc['Negative Value Reduction', method] = f\"{summary_table.loc[key, 'Negative reduction']:.2f}\"\n",
    "                    else:\n",
    "                        current = float(comparison_df.loc['Negative Value Reduction', method])\n",
    "                        new_value = (current + summary_table.loc[key, 'Negative reduction']) / 2\n",
    "                        comparison_df.loc['Negative Value Reduction', method] = f\"{new_value:.2f}\"\n",
    "                    \n",
    "                    # Noise Reduction\n",
    "                    if comparison_df.loc['Noise Reduction Factor', method] == 'N/A':\n",
    "                        comparison_df.loc['Noise Reduction Factor', method] = f\"{summary_table.loc[key, 'Noise reduction factor']:.1f}x\"\n",
    "                    else:\n",
    "                        current = float(comparison_df.loc['Noise Reduction Factor', method].replace('x', ''))\n",
    "                        new_value = (current + summary_table.loc[key, 'Noise reduction factor']) / 2\n",
    "                        comparison_df.loc['Noise Reduction Factor', method] = f\"{new_value:.1f}x\"\n",
    "                    \n",
    "                    # Correlation\n",
    "                    if comparison_df.loc['Correlation with Raw Data', method] == 'N/A':\n",
    "                        comparison_df.loc['Correlation with Raw Data', method] = f\"{summary_table.loc[key, 'Correlation with raw']:.3f}\"\n",
    "                    else:\n",
    "                        current = float(comparison_df.loc['Correlation with Raw Data', method])\n",
    "                        new_value = (current + summary_table.loc[key, 'Correlation with raw']) / 2\n",
    "                        comparison_df.loc['Correlation with Raw Data', method] = f\"{new_value:.3f}\"\n",
    "    \n",
    "    # Fill in qualitative assessments \n",
    "    # Signal Preservation (Lag)\n",
    "    comparison_df.loc['Signal Preservation (Lag)', 'ONA'] = \"No lag\"\n",
    "    comparison_df.loc['Signal Preservation (Lag)', 'CMA'] = \"Minimal lag\"\n",
    "    comparison_df.loc['Signal Preservation (Lag)', 'DEMA'] = \"Some lag possible\"\n",
    "    \n",
    "    # Time Averaging Behavior\n",
    "    comparison_df.loc['Time Averaging Behavior', 'ONA'] = \"Adaptive based on ΔATN\"\n",
    "    comparison_df.loc['Time Averaging Behavior', 'CMA'] = \"Fixed window\"\n",
    "    comparison_df.loc['Time Averaging Behavior', 'DEMA'] = \"Exponential weighting\"\n",
    "    \n",
    "    # Source Apportionment Stability\n",
    "    comparison_df.loc['Source Apportionment Stability', 'ONA'] = \"Good\"\n",
    "    comparison_df.loc['Source Apportionment Stability', 'CMA'] = \"Better\"\n",
    "    comparison_df.loc['Source Apportionment Stability', 'DEMA'] = \"Best\"\n",
    "    \n",
    "    # Computational Complexity\n",
    "    comparison_df.loc['Computational Complexity', 'ONA'] = \"High (adaptive)\"\n",
    "    comparison_df.loc['Computational Complexity', 'CMA'] = \"Low (simple)\"\n",
    "    comparison_df.loc['Computational Complexity', 'DEMA'] = \"Medium\"\n",
    "    \n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad35abe",
   "metadata": {},
   "source": [
    "## 16. Conclusions and Method Recommendations\n",
    " \n",
    "This notebook implemented and compared three post-processing algorithms for aethalometer data: ONA, CMA, and DEMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display the overall comparison table\n",
    "print(\"\\n===== Overall Method Comparison =====\")\n",
    "comparison_table = create_method_comparison_table()\n",
    "display(comparison_table)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
